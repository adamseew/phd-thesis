
%%%%%%%%%%%%%%
%            %
% Guidance   %
%            %
\chapter{Coverage Planning and Scheduling}
\label{cp:dyn}

\lettrine{I}{n the previous chapter}, we introduced progressively the research questions we are interested in addressing. We then provided some preliminaries with basic terminology, formulated the problem formally, detailed the available literature, and derived various energy models. Once we detailed all these basic constructs, we are ready to describe their interaction to solve \fref{pb:cov-pb}{Problem} and \fref{pb}{Problem} and thus provide an energy-aware coverage planning and scheduling for autonomous aerial robots.

This chapter describes the main contribution of our work. Here we generate the coverage plan $\Gamma$ that we defined in \fref{def:plan}{Definition} solving \fref{pb:cov-pb}{Problem}, replan $\Gamma$ energy-wise with the models from \fref{cp:model}{Chapter} solving \fref{pb}{Problem} in case of, e.g., sudden battery drops, and guide the aerial robot on $\Gamma$. In particular, we first detail how we guide the aerial robot on the plan in \fref{sec:gvf}{Section}, recalling some constructs in \fref{cp:pb}{Chapter}. These include path functions\findex{path functions}, stages\findex{stage}, triggering points\findex{triggering points}, and primitive paths\findex{primitive paths}. In \fref{sec:cov-path-plan}{Section}, we discuss the generation of the coverage plan with a union of path functions and triggering points in \fref{sec:path-functions}{Sections}\fref{sec:defs-stages-triggs}{--\hspace*{-.8ex}} (it is on this coverage that we are interested in guiding the aerial robot). In \fref{sec:mpc}{Section}, we then discuss how to replan the coverage energy-wise. Although we already described most of the concepts in preliminaries in \fref{cp:opt}{Chapter} and literature in \fref{cp:soa}{Chapter}, we still need some additional notions. To guide the aerial robot, we use the theory of vector fields that point to the path functions. To generate the coverage path, a class of methods under the name of cellular decomposition, generating a coverage motion that respects the nonholonomic\findex{nonholonomic constraints} and other constraints of a fixed-wing aerial robot (such as the Opterra craft\findex{Opterra fixed-wing aerial robot} in \fref{fig:opterra}{Figure} that we have discussed extensively in this work), including requirements on the turning radius\findex{turning radius}. To replan the coverage path, we use an optimal control\findex{optimal control} approach termed model predictive control (\Gls{acr:mpc})\findex{model predictive control} along with the periodic model in \fref{cp:model}{Chapter} (which we proved formally and motivated empirically in \fref{sec:periodic-model}{Section}). We describe all these concepts and contextualize them in the solution to the problems in this chapter. 

This chapter connects to the remainder of this work as follows. Here we provide the solution to the problems in \fref{cp:pb}{Chapter}. To this end, we use the available literature on planning in \fref{cp:soa}{Chapter} and the energy models in \fref{cp:model}{Chapter}. We provided the motivation and discussed why it is important to solve these problems in \fref{cp:intro}{Chapter}. We use the model in the cost and constraints of an optimal control problem (\Gls{acr:ocp})\findex{optimal control problem} using the preliminaries in \fref{cp:opt}{Chapter}. Although we provide an algorithm for energy-aware coverage planning and scheduling for autonomous aerial robots, some research questions remain open. We discuss these questions in \fref{cp:conc}{Chapter}.


\section{Guidance on the coverage}\findex{guidance}\label{sec:gvf}

In this section, we describe how we guide the aerial robot in space $\mathcal{Q}_v\subseteq\mathbb{R}^2$ for an inertial navigation frame $\mathcal{O}_W$ (we will see what we mean by $v$ in \fref{sec:cell-deco}{Section}). For this purpose, we briefly recall some concepts we introduced in \fref{cp:soa}{Chapter}. We describe the path the aerial robot flies in \fref{sec:path-functions}{Section} with a mathematical function $\varphi_i:\mathbb{R}^2\times\mathbb{R}^\rho\rightarrow\mathbb{R}$ that maps a point in 2D space and the path parameters to a given value on the $z$-axis in \fref{def:paths}{Definition}. We saw two examples of such functions. In the first example, we proposed a line at an altitude $h\in\mathbb{R}$ in \fref{fig:plot1}{Figure}. The value on the $z$-axis given a point $\mathbf{p}(t)$ at the time $t$ is then the length, let's call it $d$, of a vertical segment parallel to the $z$-axis that goes from the plane $\varphi(x,y)=h$ and intersects the plane in \frefeq{eq:pathf-line}. In the second example, we proposed a circle (at the same altitude $h$) in \fref{fig:plot11}{Figure}. The value on the $z$-axis is the length $d$ of a similar segment, going from the plane $\varphi(x,y)=h$ to the intersection of the paraboloid in \frefeq{eq:pathf-circle}. We further recall from \fref{cp:soa}{Chapter} that we store path functions in stages in \fref{def:stage}{Definition}. The set of stages form the plan $\Gamma$ in \fref{def:plan}{Definition}. The aerial robot flies the $i$th a stage $\Gamma_i$ traveling the $i$th path function $\varphi_i$ up until it encounters the triggering point $\mathbf{p}_{\Gamma_i}$ in \fref{def:trigs}{Definition}; at the occurrence, the action depends on how we defined $\Gamma$. We can define $\Gamma$ with all the stages explicitly so that the aerial robot switches to $\Gamma_{i+1}$ up to reaching the final point $\mathbf{p}_{\Gamma_l}$ in $\Gamma_l$, the final stage. Alternatively, we can define $\Gamma$ with $n$ stages and a shift $\mathbf{d}$. When the aerial robot reaches the $kn$th triggering point $\mathbf{p}_{\Gamma_{kn}}$ for some $k\in\mathbb{Z}_{>0}$, it advances the $n$ stages of $\mathbf{d}$. It iterates the process up to reaching the final point $\mathbf{p}_{\Gamma_l}$.

In the remainder of this section, we detail how we guide the aerial robot on a path function $\varphi_i$ from the stage $\Gamma_i,\,\forall i\in[l]_{>0}$ (or $\forall i\in[n]_{>0}$ with a consequent shift of $\mathbf{d}$ when we reach $\mathbf{p}_{\Gamma_{kn}}$ for a $k$) up to reaching $\mathbf{p}_{\Gamma_l}$. The path function can be, e.g., the circle and line in \fref{fig:plot1}{Figures}\fref{fig:plot11}{--\hspace*{-.8ex}}. By guidance, we mean where to fly next with the aerial robot starting from an initial point in space $\mathbf{p}(t_0)$ at the first time instant $t_0$ up to the final triggering point $\mathbf{p}_{\Gamma_l}$ at $t_l>t_0$.

---

\subsection{Vector fields for guidance}\findex{vector field}

Let us briefly discuss the intuition behind vector fields for guidance with the concept of potential functions\findex{potential functions}. These are differentiable real-valued functions $\varphi:\mathbb{R}^d\rightarrow\mathbb{R}$, of which the value we can consider as energy\findex{energy}, and hence their gradient as force\findex{force}~\citep{choset2005principles}. There are several pseudonyms for potential functions for different fields; e.g., the electrostatic potential\findex{electrostatic potential} for electrostatics\findex{electrostatics}, velocity potential\findex{velocity potential} for hydrodynamics\findex{hydrodynamics}, and temperature\findex{temperature} for flowing heat\findex{flowing heat}~\citep{needham1998visual}. We use the concept for exemplification; we don't deal with aerial robots' dynamics directly in our model, and we see gradients as velocity and not force vectors, being $\mathbf{p}$ the position. We note that the gradient of the potential function points where it maximally (locally) increases~\citep{choset2005principles}. We define the gradient\findex{gradient} of $\varphi$
\begin{equation}\label{eq:grady}
  \nabla\varphi_i(\mathbf{p}(t),c^\rho_i):=\begin{bmatrix}\partial\varphi_i(\mathbf{p}(t),c^\rho_i)/\partial\mathbf{p}_1(t)\\\partial\varphi_i(\mathbf{p}(t),c^\rho_i)/\partial\mathbf{p}_2(t)\\\vdots\\\partial\varphi_i(\mathbf{p}(t),c^\rho_i)/\partial\mathbf{p}_d(t)\end{bmatrix},
\end{equation}
where $\partial\varphi/\partial\mathbf{p}_k$ for $k\in[d]_{>0}$ indicates the differential and $\mathbf{p}_1,\mathbf{p}_2,\dots$ are 
\begin{equation}
  \mathbf{p}(t)=\begin{bmatrix}
    \mathbf{p}_1(t) & \mathbf{p}_2(t) & \cdots & \mathbf{p}_d(t)
  \end{bmatrix}',
\end{equation}
simply the components of the vector $\mathbf{p}$ (i.e., when we are dealing with 2D space, $d$ is two, and the components $x$ and $y$). 

We can then use the gradient in \frefeq{eq:grady} to define a vector field--a function that assigns a vector at each $\mathbf{p}$ in $\mathcal{Q}^v$~\citep{lavalle2006planning}, which will then point in the direction of the gradient
\begin{equation}\label{eq:vec-field-def}
  \varPhi(t,\varphi_i,c_i^\rho):=\bigcup\limits_{\mathbf{p}(t)\in\mathcal{Q}^v}{\nabla\varphi_i(\mathbf{p}(t),c_i^\rho)}.
\end{equation}

We note some analogies in the physical theory of potential functions with our path functions; indeed vector field is a well known concept in physics, with applications such as electrostatic\findex{electrostatic field}, gravitational\findex{gravitational field} and magnetic fields\findex{magnetic field}~\citep{feynman2015feynman}. Imagine the aerial robot is a positively charged particle in an electrostatics analysis for an instant. The particle is attracted by the a negative goal; via the gradient we can then direct the particle (the aerial robot) to the goal (where the function maximally locally increases)~\citep{choset2005principles}. In the setting of \frefeq{eq:pathf-line} and \frefeq{eq:pathf-circle}, i.e., 
\begin{equation}\label{eq:two-paths}
  2y-x=h,\,\,\,\ (x-3)^2+(y-3)^2-2=h,
\end{equation}
their gradient then points away from the base of the plane in \frefeq{eq:pathf-line}, and from the center of the circle in \frefeq{eq:pathf-circle} in \fref{fig:grad}{Figure}. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/grad.tikz}
  \caption[.]{.}
  \label{fig:grad}
\end{figure}
Immagine for an instant that our goal is not to fly over the circle in \fref{fig:plot11}{Figure}, but to its center $(x_c,y_c)$ in \frefeq{eq:pathf-circle}. The vector field $\varPhi$ in \frefeq{eq:vec-field-def} direct us in the opposite direction; we can then use $-\nabla\varphi_i$ to direct to robot to the goal.

Vector fields are common used in the motion planning literature for navigation of different mobile robots~\citep{lindemann2005smoothly,gonccalves2010vector,panagou2014motion,zhou2014vector,kapitanyuk2017guiding,de2017guidance}, and are also threated in some robots planning textbooks~\citep{choset2005principles,lavalle2006planning}. A well-known intuitive method brought from optimization is the gradient descent algorithm\findex{gradient descent algorithm}~\citep{choset2005principles,bryson1975applied}, where an intuitive choice of the search direction is the negative gradient $\Delta \varphi_i:=-\nabla\varphi_i$~\citep{boyd2004convex}. We illustrate the gradient descent algorithm in \fref{algo:grad-desc}{Algorithm} where we iterate at discrete time steps (i.e., at instant $n$, $\mathcal{K}$ contains $t_0,t_0+h,\dots,t_0+nh$; we discuss further the time step $h$ ($h$ is not to be confused with the altitude when used in the path functions) later in this chapter in \fref{sec:algo}{Section}), $\mathbf{p}(t_0)$ is given (e.g., from sensors data), $\theta(i)$ is a scalar step size at time instant $i$~\citep{choset2005principles}--there can be indeed different step sizes at different instants--and $\varepsilon\in\mathbb{R}_{>0}$ is chosen based on the task requirements (it is unrealistic to assume we will reach $\nabla\varphi_i=0$).

\begin{algorithm}[h!] %this is an example
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwFunction{FMain}{\small\tt zamboni-like\_motion}
  \SetKwProg{Fn}{Function}{:}{}
  \SetKwProg{Pn}{Function}{:}{\KwRet}

  \DontPrintSemicolon
  \Input{$t_0${ \otherfont initial time step}\newline
         $c^\rho_i${ \otherfont value of the path parameters}\newline
         $j${ \otherfont current stage}
  }
  \Output{$\mathbf{p}(\mathcal{K})${ \otherfont trajectory}
  }
  \vspace{.8ex}

  \ForEach{\normalsize $i\in\mathcal{K}:=\{t_0,t_0+h,t_0+2h,\dots\}$}{
    \If{\normalsize $\norm{\nabla\varphi_j(\mathbf{p}(t),c^\rho_i)}\leq \varepsilon$}{
      \vspace{.8ex}
      \Return{\normalsize $\mathbf{p}(\mathcal{K})$}\;
    }
    {\normalsize $\mathbf{p}(i+h)\gets \mathbf{p}(i)+\theta(i)\Delta\varphi_j(\mathbf{p}(t),c^\rho_i)$}\;
  }
  \vspace{.8ex}

  \caption{Gradient descent}\findex{gradient descent}
  \label{algo:grad-desc}
\end{algorithm}

\fref{algo:grad-desc}{Algorithm} that we illustrate in \fref{fig:grad_desc}{Figure} directs us to the center of the circle in case we have a circle as a path function.
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/grad_desc.tikz}
  \caption[.]{.}
  \label{fig:grad_desc}
\end{figure}
However, we are interested into following these paths at an assigned altitude, i.e., we want to track the functions in \frefeq{eq:two-paths}. Concretely, in the path sub-plan that we proposed in \frefeqM{eq:line-gene}{eq:circ-gene} in \fref{sec:path-wise}{Section}, we want to track, e.g., the path function $\varphi_{i+1}$ by flying over the function rather that heading the center of the circle it describes; we started tracking the function after reaching $\mathbf{p}_{\Gamma_i}$ while tracking $\varphi_i$ and so on. To this end, we use a vector field-based approach proposed in the literature specifically for aerial robots~\citep{de2017guidance}, which points to the contours of the functions in \fref{fig:plot1}{Figures}\fref{fig:plot11}{--\hspace{-.8ex}} and thus to \frefeq{eq:two-paths}.

The expression for the search direction $\Delta\varphi_i$ in~\citep{de2017guidance} becomes
\begin{equation}\label{eq:pd}
  \Delta_d\varphi_i(\mathbf{p}(t),c_i^\rho):=E_i\nabla\varphi_i(\mathbf{p}(t),c_i^\rho)-k_e\varphi_i(\mathbf{p}(t),c_i^\rho)\nabla\varphi_i(\mathbf{p}(t),c_i^\rho),
\end{equation}
where $E_i\nabla\varphi_i(\mathbf{p}(t),c_i^\rho)$ is a vector pointing perpendicularly to the gradient $\nabla\varphi_i(\mathbf{p}(t),c_i^\rho)$, $E_i$ is the $i$th stage direction
\begin{equation}
  E_i=\begin{bmatrix}
    0&1\\-1&0
  \end{bmatrix},
\end{equation}
with $E_i$ being the counter clockwise, $-E_i$ the clockwise direction. 
The contribution of the component $-k_e\varphi_i(\mathbf{p}(t),c_i^\rho)\nabla\varphi_i(\mathbf{p}(t),c_i^\rho)$ in \frefeq{eq:pd} points then in the direction of the path function. It depends on the coefficient $k_e\in\mathbb{R}_{>0}$--indicating the speed of convergence~\citep{de2017guidance}--and on the value of $\varphi_i$ at the current point (of course also on the path parameters and the value of the gradient). We illustrate $\Delta_d\varphi_i$ in \fref{}{Figure}. When we take a point within the circle, let's call it $\mathbf{p}_{-}$, the value of $\varphi_i$ is negative; $-k_e\varphi_i(\mathbf{p}_{-},c_i^\rho)\nabla\varphi_i(\mathbf{p}_{-},c_i^\rho)$ points outwards of the circle center, in the direction of the path function. $E_i\nabla\varphi_i(\mathbf{p}_{-},c_i^\rho)$ points perpendicularly to the gradient $\nabla\varphi_i$ and to the path function itself. The resulting vector $\Delta_d\varphi_i(\mathbf{p}_{-},c_i^\rho)$ then points the direction of the path function.

Now we take a point $\mathbf{p}_{+}$ out of the circle, and not exactly over the path function. The value of $\varphi_i$ is positive; $-k_e\varphi_i(\mathbf{p}_{+},c_i^\rho)\nabla\varphi_i(\mathbf{p}_{+},c_i^\rho)$ points inwards of the circle center and the resulting vector $\Delta_d\varphi_i(\mathbf{p}_{-},c_i^\rho)$ in the direction of the path function. If we finally take a point $\mathbf{p}_{0}$ exactly over the path function, $\varphi_i$ is zero; $-k_e\varphi_i(\mathbf{p}_{0},c_i^\rho)\nabla\varphi_i(\mathbf{p}_{0},c_i^\rho)$ is thus also zero and $\Delta_d\varphi_i(\mathbf{p}_{0},c_i^\rho)$ points perpendicularly to the path functions. Let us thus define the vector fields
\begin{equation}
  \varPhi_d(t,\varphi_i,c_i^\rho):=\bigcup\limits_{\mathbf{p}(t)\in\mathcal{Q}^v}{\Delta_d\varphi_i{\mathbf{p}(t),c_i^\rho}}.
\end{equation}

This vector fields points to the path function such as the line and the circle in \frefeq{eq:two-paths} for every point in space $\mathcal{Q}^v$ as we illustrate in \fref{}{Figure} for the line $2y-x=h$ and in \fref{}{Figure} for the circle $(x-3)^2+(y-3)^2-2=h$.

\begin{algorithm}[h!] %this is an example
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwFunction{FMain}{\small\tt zamboni-like\_motion}
  \SetKwProg{Fn}{Function}{:}{}
  \SetKwProg{Pn}{Function}{:}{\KwRet}

  \DontPrintSemicolon
  \Input{$t_0${ \otherfont initial time step}\newline
         $c^\rho_i${ \otherfont value of the path parameters}\newline
         $j${ \otherfont current stage}
  }
  \Output{$\mathbf{p}(\mathcal{K})${ \otherfont trajectory}
  }
  \vspace{.8ex}

  \ForEach{\normalsize $i\in\mathcal{K}:=\{t_0,t_0+h,t_0+2h,\dots\}$}{\label{algo:track:foreach}
    \If{\normalsize $\norm{\mathbf{p}(i)-\mathbf{p}_{\Gamma_j}}\leq \varepsilon$}{\label{algo:track:eucly}
      \vspace{.8ex}
      \Return{\normalsize $\mathbf{p}(\mathcal{K})$}\;
    }
    {\normalsize $\mathbf{p}(i+h)\gets \mathbf{p}(i)+\theta(i)\Delta_d\varphi_j(\mathbf{p}(i),c_j^\rho)$}\;\label{algo:track:gvf}
  }
  \vspace{.8ex}

  \caption{Path function tracking}\findex{tracking}
  \label{algo:track}
\end{algorithm}


Finally, let's reconsider \fref{algo:grad-desc}{Algorith} with the vector field $\varPhi_d$ and guide the aerial robot in space to track a specific path function $\varphi_i$ in \fref{algo:track}{Algorithm}. The algorithm iterates at discrete time steps on \fref{algo:track:foreach}{Line} as \fref{algo:grad-desc}{Algorith}. It stops tracking the $j$th path function at occurrence of the triggering point $\mathbf{p}_{\Gamma_j}$ on \fref{algo:track:eucly}{Line} using the Euclidean distance with a small enough $\varepsilon\in\mathbb{R}_{>0}$ rather than evaluating if the function reached a local minimum with $\nabla\varphi_j=0$ in \fref{algo:grad-desc}{Algorithm}. The algorithm then computes a simplified version of the next position  on \fref{algo:track:gvf}{Line} using the current position $\mathbf{p}(i)$ and the gradient $\Delta_d\varphi_i$ without considering vehicles' velocity $v(i)$ and other parameters (such as external interferences, e.g., wind speed and direction). For simplicity, we can use the same value for the time step $h$ that we used for the step size $\theta$ for all the time instants in $\mathcal{K}$.



\subsection{\color{red}Derivation of the guidance action}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Coverage Path Planning}
\label{sec:cov-path-plan}\findex{coverage path planning}

In this section, we solve \fref{pb:cov-pb}{Problem}. Let us recall briefly our objective of providing a set of paths (a tour) in the plan from \fref{def:plan}{Definition} to cover each point in a given space. We summarize such space with a set of vertices $v:=\{v_1,v_2,\dots\}$ that form a polygon. The robot is free to move within the polygon except for some obstacles described by other sets of vertices, one per each obstacle $o_1:=\{o_{1,1},o_{1,2},\dots\},o_2:=\{o_{2,1},o_{2,2},\dots\},\dots$. There are several different approaches in the literature to solve this problem. We have detailed the approaches in the literature in \fref{sec:soa-cov-path-plan}{Sections}\fref{sec:opti-cov}{--\hspace{-.8ex}} for mobile robots and in \fref{sec:cov-plan-aero}{Sections}\fref{sec:opti-aero-cov}{--\hspace{-.8ex}} for aerial robots specifically. In summary, the sub-class of motion planning that finds the coverage tour of a given space is called coverage path planning (CPP)~\citep{choset1998coverage}. The algorithms for the coverage tour are NP-hard\findex{NP-hard}~\citep{arkin2000approximation} and use either implicitly or explicitly the cellular decomposition that divides the robot's free space into sub-regions that can be easily covered~\citep{choset2001coverage,galceran2013survey}.

There are numerous methodologies for cellular decomposition itself. Some decompose the polygon into equally sized sub-regions that form a grid and then visits only the sub-regions where the robot is free to move~\citep{galceran2013survey}. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/gride.tikz}
  \caption[Grid decomposition]{A polygonal space where we want to find a coverage tour and visit all the points delimited by $v:=\{v_1,\dots,v_4\}$ except for the obstacle $o_1:=\{o_{1,1},\dots,o_{1,6}\}$. A way to cover the space is the grid decomposition that divides the polygon into equally sized cells and visits each cell except the obstacle.}
  \label{fig:gride}
\end{figure}
This methodology is termed grid decomposition\findex{grid decomposition} in~\fref{fig:gride}{Figure}. Another way is to sweep the polygon and divide it into sub-regions\findex{sub-regions} when the sweep line\findex{sweep line} encounters a change in connectivity. We implement this latter class in \fref{sec:cell-deco}{Section}.
Once the algorithm divides the free space into sub-region, it builds an adjacency graph\findex{adjacency graph}. The vertices contain the sub-regions and edges connect adjacent sub-regions~\citep{choset2005principles}. A covering order between the sub-region to derive the sequence of the coverage is then an exhaustive walkthrough of the adjacency graph with, e.g., depth-first search\findex{depth-first search} algorithm~\citep{choset2005principles}. Once divided the space and the order of the coverage, we need to cover each sub-region. We recall that a method is the boustrophedon motion that we discussed in \fref{cp:soa}{Chapter}. However, a generic nonholonomic mobile robot, such as the Opterra fixed-wing craft in the precision agriculture scenario in \fref{sec:motivation}{Section}, has limited maneuverability~\citep{mannadiar2010optimal,xu2011optimal,xu2014efficient}. For a generic aerial robot, it is preferred to have a large turning radius~\citep{wang2017curvature}; to this end, we propose a Zamboni-like motion. We introduced both the Zamboni- and boustrophedon-like motions in \fref{sec:path-wise}{Section}, whereas we implement them later in this chapter in \fref{sec:cov-motion}{Section}.

\subsection{Cellular decomposition of the space}
\label{sec:cell-deco}\findex{cellular decomposition}

In detail, a cellular decomposition decomposes the coverage space into non-overlapping sub-regions called cell\findex{cells}s. Let us define the robot's free space\findex{free space} or the coverage space\findex{coverage space} as $\mathcal{Q}^v$ for an inertial navigation frame $\mathcal{O}_W$. Physically, the free space is where the robot is free to move without intersecting an obstacle~\citep{choset2005principles}. Let $\mathcal{Q}^{o_i}\subset\mathbb{R}^2$ be the space delimited by the obstacle $o_i$. $\mathcal{Q}^v\subseteq\mathbb{R}^2$ contains all the points delimited by the vertices of the polygon $v$ except for $i$ obstacles delimited by the vertices of $i$ polygons $o_i$. The entire space in the polygon $v$, including all the obstacles $o_i$, is then $\mathcal{Q}:=(\bigcup_{i\in|o|}\mathcal{Q}^{o_i})\cup\mathcal{Q}^v$. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/bcd_1.tikz}
  \caption[Initial step of the boustrophedon decomposition]{The boustrophedon decomposition for coverage path planning sweeps the space and adds cells in case the sweeping line encounters a change in connectivity. Figure shows an initial step with $c_1$ the first cell formed.}
  \label{fig:bcd2}
\end{figure}
In \fref{fig:bcd2}{Figure}, the polygon is delimited by $v:=\{v_1,\dots,v_4\}$ and forms $\mathcal{Q}^v$, whereas the obstacle by $o_1:=\{o_{1,1},\dots,o_{1,6}\}$ and forms $\mathcal{Q}^{o_1}$. The union of these two is then $\mathcal{Q}$.

An important approach in the polygonal environment is the boustrophedon decomposition\findex{boustrophedon decomposition}~\citep{choset2000coverage}. For non-polygonal environments where $v$ and $o_i$ are, e.g., elliptical functions, a significant result is the decomposition in terms of critical points of Morse functions\findex{Morse functions}~\citep{choset2000exact}. Both the boustrophedon decomposition and decomposition in terms of critical points of Morse functions sweep $\mathcal{Q}$ with a line and decompose $\mathcal{Q}^v$ adding a cell in case of a change in connectivity or when they encounter a critical point~\citep{choset2000coverage,choset2001coverage,choset2005principles}. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/bcd_2.tikz}
  \caption[Intermediate step of the boustrophedon decomposition]{An intermediate step of the boustrophedon decomposition, with $c_2,c_3$ formed at the first encounter of the obstacle $o_1$. The black points indicate the critical points or changes in connectivity.
  }
  \label{fig:bcd3}
\end{figure}
In \fref{fig:bcd3}{Figure}, the change in connectivity happens when the sweeping line encounters the obstacle $o_1$. This approach optimizes the neighboring cells that can be thus aggregated as opposed to, e.g., trapezoidal decomposition\findex{trapezoidal decomposition}~\citep{galceran2013survey} in \fref{fig:trap}{Figure}, which splits the space into cells when it encounters a vertex~\citep{lavalle2006planning}.
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/trap.tikz}
  \caption[Trapezoidal decomposition]{In the trapezoidal decomposition a lot of small cells are created (i.e., the cells $c_2,c_3,c_7$) that can be otherwise merged resulting in disconnected coverage. Boustrophedon decomposition solves the problem by splitting/merging the cells at critical points rather than at vertices. The resulting tour has eight cells as opposed to four cells with boustrophedon decomposition in \fref{fig:bcd4}{Figure}.}
  \label{fig:trap}
\end{figure}
For the decomposition in terms of critical points of Morse functions, the intuition of using critical points\findex{critical points}~\citep{choset2000exact} comes from some early studies on roadmaps\findex{roadmaps}~\citep{canny1988complexity,canny1988constructing,canny1993opportunistic}. Notably, these studies show that topology\findex{topology} (i.e., connectivity) changes only at critical points of a sweeping function restricted to the boundaries of obstacles. We briefly summarize some findings~\citep{choset2000exact} for this latter method before discussing the coverage motion for the cells.

Let us define $\mathcal{S}_\lambda$ as the vertical sweeping function that sweeps $\mathcal{Q}$. A change in the value of $\lambda$ moves the function in $\mathcal{Q}$. Let further $\overline{x}_v,\underline{x}_v$ be the highest and lowest coordinate $x$ of all the vertices in $v$, i.e., $\lambda\in[\underline{x}_v,\overline{x}_v]$. If we refer to the sweeping function with at a specific point in space as a slice, we can express the entire space as the union of all the slices, i.e., $\mathcal{Q}=\cup_{\lambda}\mathcal{S}_\lambda$. Let us further define the slice contained in the free space $\mathcal{S}^v_\lambda:=\mathcal{S}_\lambda\cap\mathcal{Q}^{v}$.
At this point, a change in connectivity of $\mathcal{S}^v$ means that the original cell has to be closed and two more opened, or that two cells are closed and one is opened respectively when the connectivity increases or decreases~\citep{choset2000exact}. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/bcd_3.tikz}
  \caption[Result of the boustrophedon decomposition]{The final step of the boustrophedon decomposition, where the sweeping line $\mathcal{S}_{\lambda}$ encounters the final point of its domain $\overline{x}_v$. The decomposition results in four cells. To determine the order of the coverage tour, the methodology is to  visit the adjacency graph.}
  \label{fig:bcd4}
\end{figure}
In \fref{fig:bcd3}{Figure}, $\mathcal{S}_\lambda$ sweeps the space from $\lambda=\underline{x}_v$ in \fref{fig:bcd2}{Figure} up to $\lambda=x_{o_{1,1}}$. At this latter lambda, $\mathcal{S}_{x_{o_{1,1}}}$ encounters a change in connectivity ($\mathcal{S}^v_{x_{o_{1,1}}}$ forms two disconnected slices). The decomposition methodology builds two new cells $c_2,c_3$, and adds these cells to the adjacency graph. $\mathcal{S}_\lambda$ encounters another change in connectivity at $\lambda=x_{o_{1,4}}$ ($\mathcal{S}^v_{x_{o_{1,4}}}$ is again one connected slice). This latter is different from the previous: the cells are merged with forming a new cell $c_4$. The coverage tour is then a visit through the adjacency graph, resulting in the coverage order $c_1,c_2,c_4$, and finally $c_3$. 

In summary, the methodology iterates through the environment with $\mathcal{S}^v_{\lambda}$ in \fref{fig:bcd2}{Figure}. When the connectivity of $\mathcal{S}^v_{\lambda}$ increases in \fref{fig:bcd3}{Figure}, it closes a cell and opens two new cells--the literature~\citep{choset2000exact,choset2005principles} refers to these cells as ceiling and floor cells (for $c_2$ and $c_3$ in~\fref{fig:bcd4}{Figure} respectively). When the connectivity decreases back in \fref{fig:bcd4}{Figure}, the two opened cells are closed, and a new one is opened. The overall complexity is $O(n\log{n})$ with $n:=|v|+\sum_{i=1}^{|o|}|o_i|$ the total number of vertices~\citep{choset2000exact}. Indeed, for polygonal environments, it is enough to verify the change in connectivity by iterating the vertices and visit the constructed adjacency graph to find the coverage order.

%\begin{algorithm}[h!] %this is an example
%  \SetKwInOut{Input}{Input}
%  \SetKwInOut{Output}{Output}
%  \SetKwFunction{FMain}{\small\tt build\_cells}
%  \SetKwProg{Fn}{Function}{:}{}
%  \SetKwProg{Pn}{Function}{:}{\KwRet}

%  \DontPrintSemicolon
%  \Input{$v\,${\otherfont the list of vertices},\newline
%         $o\,${\otherfont the list of vertices of obstacles}
%  }
%  \Output{$c\,${\otherfont the list of vertices of cells}}

%  {\normalsize $c\gets\, ${\small\tt build\_cells(}$v,o${\small\tt )}}\;

%  \Pn{\FMain{\normalsize $v,o,\mathcal{S}^v_\lambda$}}{  
%  {\normalsize $l_s\gets l(v_1,v_{|v|})$}\;% builds coverage motion parallel to the edge of the polygon
    
%    \eIf{\normalsize $o\neq\emptyset,\,o_1\in v$}{ % split in 2 cells in proximity of obstacle
    
%      {\normalsize $c_{c}\gets (x_{\underline{o}_1},\mathcal{S}_{x_{\underline{o}_1}}^c)\cup\{w\mid w\in v, \underline{o}_1< w< \overline{o}_1\}\cup(x_{\overline{o}_1},\mathcal{S}_{x_{\overline{o}_1}}^c)$}\;
%      {\normalsize $c_{c}\gets c_{c}\curvearrowright \{w\mid w\in o_1, w\geq \underline{o}_1\}$}\; % ceiling

%      {\normalsize $c_{f}\gets (x_{\underline{o}_1},\mathcal{S}_{x_{\underline{o}_1}}^c)\cup\{w\mid w\in v, \underline{o}_1< w< \overline{o}_1\}\cup(x_{\overline{o}_1},\mathcal{S}_{x_{\overline{o}_1}}^c)$}\;
%      {\normalsize $c_{c}\gets c_{c}\curvearrowright \{w\mid w\in o_1, w\geq \underline{o}_1\}$}\; % floor

%      {\normalsize $c_{f}\gets c_{c}$}\;
%      {\normalsize $c_{f}\curvearrowright   \{w\mid w\in o_1, w\leq \underline{o}_1\}\cup (\overline{x}_{o_{1}},l_f(\overline{x}_{o_{1}}))$}\; % floor

%      {\normalsize $c_{2}\curvearrowright \{w\mid w\in c_{1}, w\geq \underline{x}_{o_{1}}\}\cup (\underline{x}_{o_{1}},l_c(\underline{x}_{o_{1}}))\cup(\underline{x}_{o_{1}},l_f(\underline{x}_{o_{1}}))$}\;

%      {\normalsize $c_{1}\curvearrowright \{w\mid w\in c_{1}, w\leq \underline{x}_{o_{1}}\}\cup (\underline{x}_{o_{1}},l_c(\underline{x}_{o_{1}}))\cup(\underline{x}_{o_{1}},l_f(\underline{x}_{o_{1}}))$}\;

%      {\normalsize $o\gets o\setminus\{o_1\}$}\;
%      \Return{\normalsize $c_{1}\,\,\cup\,\,${\small\tt build\_cells(}$c_{c},o${\small\tt )}$\,\,\cup\,\,${\small\tt build\_cells(}$c_{2},o${\small\tt )}$\,\,\cup\,\,${\small\tt build\_cells(}$c_{f},o${\small\tt )}}\;
%    }{
%      \Return{\normalsize $c_{1}$}\;
%    }
%  }
%  \vspace{.8ex}

%  \caption{A simplified algorithm for cellular decomposition}
%\end{algorithm}
 
  
%ALGO: the algo has some events -- vertex of a polygon
%EVENTS:
%IN event connectivity of the slice increases, current cell is closed %and two new are opened

%OUT event the two current cells are closed  and one new is opened

%MIDDLE do not open nor close
% in Choset
% FLOOR vertices that are on the top of the polygon
% CEILING vertices that are on the bottom

%INPUT: list of polygon with vertices in counter-clockwise order
% ASSUMPTION: No two IN nor two OUT events have the same x-coordinate


\subsection{Coverage motion generation}\findex{coverage motion}
\label{sec:cov-motion}

Once we delimited the coverage and obstacles spaces into appropriate cells, we need to define the tour that travels through all the points in the cells--the coverage motion. A classical approach for the coverage motion in the literature is to travel back and forth. We saw in~\fref{cp:soa}{Chapter} and discussed briefly at the beginning of~\fref{sec:cov-path-plan}{Section} that this is termed the boustrophedon motion. We propose a slight variation of this motion for our problem, which we introduced with the intuitive path in~\fref{sec:path-wise}{Section} in~\fref{fig:plot3}{Figure}. The variation called the boustrophedon-like motion optimizes the turns of the aerial robot flying. The past literature analyzes broadly turns optimizations in the coverage for both mobile~\citep{huang2001optimal} and aerial robots~\citep{artemenko2016energy,li2011coverage}. The problem is that mobile robots are often subject to various constraints, including the turning radius. The original boustrophedon motion has edges parallel to the polygon where a mobile robot might have to slow to perform the turn. For instance, a lawnmower mobile robot would have to drive outside the path to turn efficiently~\citep{huang2001optimal}. An aerial robot traveling the boustrophedon motion might have to follow a greedy path planning algorithm instead or travel an additional turning maneuver such as a curlicue orbit~\citep{xu2011optimal,xu2014efficient}. To this end, the boustrophedon-like motion in~\fref{sec:path-wise}{Section} considerably smooths the turns. Given two following back and forth parallel lines in the original version, ours connects these lines using a semi-circle of a given radius rather than connecting them with additional lines. We illustrate how we cover the cell $c_1$ in~\fref{fig:bcd4}{Figure} using the boustrophedon-like motion in~\fref{fig:bm}{Figure}. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/bm.tikz}
  \caption[Boustrophedon-like motion covering a cell]{The boustrophedon-like motion covering the cell $c_1$, composed of back and forth parallel lines and circles connecting them of radius half the ideal coverage distance.}
  \label{fig:bm}
\end{figure}
The remaining cells are covered in the same manner. The overall coverage is achieved by visiting the cells in the appropriate order derived in the previous section ($c_1,c_2,c_4,$ and $c_3$).

Let us assume for an instant that the turning radius in~\fref{pb:cov-pb}{Problem} is not given. Let us further assume that the aerial robot can overfly the boundaries of the polygons $v$ and $o_i$ for the turns. The methodology that outputs the plan $\Gamma$ that covers $\mathcal{Q}^v$ with boustrophedon-like motion is to build four paths:
\begin{enumerate*}[label={(\alph*)},font={\textit}]
  \item the line $\varphi_1$ from \fref{fig:plot3}{Figure} parallel to the edge formed by vertices $v_1$ and $v_4$,
  \item the circle $\varphi_2$ with the center laying on the edge formed by vertices $v_4$ and $v_3$,
  \item the line $\varphi_3$ parallel to $\varphi_1$ that connects the right side of $\varphi_2$ and extends up to the left side of $\varphi_4$, and
  \item the circle $\varphi_4$ whose center is on the edge formed by vertices $v_1$ and $v_2$.
\end{enumerate*}
The remaining paths $\varphi_5,\varphi_6,\dots$ are formed similarly. To evaluate the radius of the circles, let us assume the ideal distance between the vertical lines in the motion (the lines $\varphi_1,\varphi_3,\varphi_5,\dots$) is a given constant. Then the radius in the plan (the circles $\varphi_2,\varphi_4,\varphi_6,\dots$) is half the ideal distance. We can change the radius of the circles and thus alter the quality of the coverage accordingly. Indeed our planning approach consists of generating an initial plan that can be changed in a replanning phase using an optimal control technique in \fref{sec:output-mpc}{Section} with the aerial robot being subject to uncertainty and external interferences in flight.

Although the turns are considerably smoothed with the plan containing the boustrophedon-like motion, they are still impractical for fixed-wing aerial robots with the turning radius exceeding the radius of these turns~\citep{dille2013efficient,xu2011optimal,xu2014efficient}. For this latter class of robots, we utilize the Zamboni-like motion. The Zamboni motion is often in the literature for fixed-wing aerial robots~\citep{ablavsky2000optimal,araujo2013multiple,majeed2019new}, and its name comes from the hockey arenas' ice maintenance machines~\citep{araujo2013multiple,dille2013efficient,ablavsky2000optimal}. They have a large turning radius like the aerial robots we study; hence they resurface the ice by sweeping distant lines first instead of adjacent lines in a back and forth motion (the boustrophedon or boustrophedon-like motions). 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/zambo1.tikz}
  \caption[Zamboni-like motion covering a cell]{The Zamboni-like motion to cover the cell $c_1$. It is similar to the boustrophedon-like motion in~\fref{fig:bm}{Figure} but travels distant lines first, respecting the large turning radius constraint of the aerial robots we analyze in this work.}
  \label{fig:zambo1}
\end{figure}
The Zamboni-like motion is similar to the original Zamboni motion in the literature but applied to our scenario. We illustrate the Zamboni-like motion for $c_1$ in \fref{fig:zambo1}{Figure} (whereas the boustrophedon-like motion in \fref{fig:bm}{Figure}).

Let us assume that the aerial robot can completely overfly the obstacles; we discuss this assumption in \fref{sec:output-mpc}{Section}. The intuition is that although the robot moves over the obstacle, it has a further computations constraint specifying that it cannot perform any computation (similarly to the turns which we constrained in \fref{sec:computation-wise}{Section}). Let us further adopt the notation ${}^{v_1}|_{v_{|v|}}$ for an edge connecting vertices $v_1$ and $v_{|v|}$ (in this latter case, the first and last vertex). To generate the plan $\Gamma$ that covers $\mathcal{Q}^v$ with the Zamboni-like motion we build four paths:
\begin{enumerate*}[label={(\alph*)},font={\textit}]
  \item the line $\varphi_1$ parallel to ${}^{v_1}|_{v_{|v|}}$ that extends from ${}^{v_{|v|}}|_{v_{|v-1|}}$ to ${}^{v_{1}}|_{v_{2}}$ (similarly to the boustrophedon-like motion),
  \item the circle $\varphi_2$ of which the left side intersects the line that we just created and the right ${}^{v_x}|_{v_y}$ with $v_x,v_y\in v$ being two vertices of the polygon $v$ at a point $x_{\Gamma_2}$ (the name of the point is relative to the nomenclature in \fref{fig:plot4}{Figure}). This latter point depends on the radius of the circle $r_1$. For the following path, let us call ${}^{v_x}|_{v_y}$ the floor edge\findex{floor edge} and ${}^{v_w}|_{v_z}$ the corresponding ceiling edge\findex{ceiling edge} constructed with the sweeping function $\mathcal{S}_{\lambda}$ intersecting  ${}^{v_w}|_{v_z}$ at $\lambda=x_{\Gamma_2}$. 
  \item the line $\varphi_3$ parallel to $\varphi_1$ that intersects the right side of $\varphi_2$ and extends from the ceiling to the floor edge at $x_{\Gamma_2}$, and
  \item the circle $\varphi_4$ of a given radius and a parameter introduced in \fref{sec:path-wise}{Section}. The left edge of the circle lays on $\varphi_3$, whereas the right intersects another edge of the polygon. 
\end{enumerate*}
In \fref{fig:zambo1}{Figure}, the circle intersects ${}^{v_1}|_{v_2}$. Once we built these four paths, let us assume the polygon is regular and composed of four edges. It is then enough to generate the coverage tour from the primitive paths $\varphi_1,\dots,\varphi_4$ with a shift $\mathbf{d}$ in the same way as we did in \fref{sec:path-wise}{Section}. The corresponding plan $\Gamma$ contains the stages and some additional obstacles dependent constraints: to perform the computations only in $\mathcal{Q}^v$, or analogously, cells $c_1,c_2,\dots$ coming from the cellular decomposition in \fref{sec:cell-deco}{Section}. We discuss the actual implementation of the aerial robot flying the plan $\Gamma$ in the next section, where we execute the plan according to the constraints (of the plan and the cellular decomposition) and replan the original plan in case of unexpected and uncertainty-driven events. For the plan $\Gamma$, we thus use the \frefeqM{eq:line-gene}{eq:circ-gene} for the paths, and \frefeq{eq:trigs-gene} for the triggering points (i.e., the points in \fref{def:trigs}{Definition} where happens the change of the path).

If the polygon is not regular and composed of four edges, we still build the remaining paths in the plan $\Gamma$ $\varphi_5,\varphi_6,\dots$ starting from the primitive paths with slight variations. If, for example, the ceiling edge points higher than the floor edge, the line segments $\varphi_5,\varphi_9,\varphi_{13},\dots$ and $\varphi_7,\varphi_{11},\varphi_{15},\dots$ are longer than $\varphi_{1}$ and $\varphi_3$ of a given rate. If, on the contrary, the ceiling edge points lower than the floor edge, the line segments are shorter. Complex shapes are equally possible by, e.g., generating the plan online at each period (i.e., the time needed to fly primitive paths in \fref{def:period}{Definition}). 

The complexity of the coverage motion generation algorithm for a cell that returns $\Gamma$ with the primitive paths is simply the complexity of building then the four primitive paths $\varphi_1,\dots,\varphi_4$. We saw that this is enough to cover both a complex polygon or a regular one with four edges in \fref{fig:zambo1}{Figure}, and thus the running time is constant $O(1)$. The overall complexity of cellular decomposition of a polygon and the plan generation is thus $O(n\log{n})$, where $n$ is the number of vertices v and the vertices of $i$ obstacles $o_i$~\citep{choset2000exact}.

%\begin{algorithm}[h!] %this is an example
%  \SetKwInOut{Input}{Input}
%  \SetKwInOut{Output}{Output}
%  \SetKwFunction{FMain}{\small\tt zamboni-like\_motion}
%  \SetKwProg{Fn}{Function}{:}{}
%  \SetKwProg{Pn}{Function}{:}{\KwRet}

%  \DontPrintSemicolon
%  \Input{$v\subset\mathbb{R}${ \otherfont the list of vertices}\newline
%         $x_\mathbf{d}\in\mathbb{R}${ \otherfont shift on the $x$-axis (distance between the coverage lines)}
%    }
%  \Output{$\Gamma${\otherfont plan that covers the polygon }$v$}

%  {\normalsize $c\gets\, ${\small\tt build\_cells(}$v,o${\small\tt )}}\;

%  \Pn{\FMain{\normalsize $v$}}{  
%  }
%  \vspace{.8ex}
%
%  \caption{A simplified algorithm that generates the plan $\Gamma$ that covers a polygon $v$}
%\end{algorithm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy-Aware Coverage Replanning}
\label{sec:mpc}

We have discussed various techniques for controlling a system optimally in \fref{cp:opt}{Chapter}. In this section, we use these techniques on the aerial robot. We recall briefly that the control in our model in \fref{sec:periodic-model}{Section} is the configuration of path and computations parameters in \fref{sec:defs-stages-triggs}{Section} specified in a given plan $\Gamma$; thus, the optimal control is the optimal configuration of both of the paths the aerial robot is flying and the computations it is computing. In our precision agriculture example, the configuration is relative to the coverage (we built the paths for a coverage tour in \fref{sec:cov-path-plan}{Section}) and the hazard detection (we discussed the computations running on the robot in \fref{sec:computation-wise}{Section}). To derive the optimal configuration, we derive the optimal control on a finite horizon rather than the entire time frame with MPC or receding horizon predictive control (RHPC)\findex{receding horizon predictive control}, an optimal control technique on a finite horizon~\citep{camacho2007model}. A problem of the generic optimal control is its difficulty and computational complexity. MPC overcomes this difficulty by optimizing for a bit of the time frame at each optimization step~\citep{camacho2007model}. MPC forecasts the system behavior and optimizes the forecast\findex{forecast} to derive a control action~\citep{rawlings2017model}. There have been many MPC developments in optimal control literature~\citep{rawlings2017model}. These range from robust\findex{robust model predictive control} (where the model is subject to uncertainty), output\findex{output model predictive control} (where noisy sensors' data estimates a model state), to distributed MPC\findex{distributed model predictive control} (that splits the original MPC into sub-problems)~\citep{camacho2007model,rawlings2017model,kwon2006receding,rossiter2004model,wang2009model}.

The models in \fref{sec:periodic-model}{Section} model the energy of computations and the overall energy evolution as a differential equation controlled with the configuration. We use the model in the cost and constraints of the MPC, which is then a convenient technique to derive a configuration that is energy-aware: we only have an empirical approximation of the time needed to cover a given space; instead of considering this approximation, with MPC, we optimize a given horizon. As further motivation, numerous recent studies apply MPC to aerial robots, such as studies for path following~\citep{gavilan2015iterative}, trajectory tracking~\citep{torrente2021data}, and involving fixed~\citep{kang2009linear,stastny2018nonlinear,chao2011collision,cavanini2021model} and rotary-wings~\citep{kostadinov2020online,song2020learning,bicego2020nonlinear}. More closely related to ours, some literature use optimization techniques on a finite horizon to plan the motion and schedule the computations energy-wise~\citep{zhang2007low,ondruska2015scheduled}, and others use different optimization techniques in this regard~\citep{lahijanian2018resource,brateman2006energy}. Our contribution extends some of these studies deriving further an energy-aware coverage path along with a power-saving schedule. In \fref{sec:soa-comp-motion-pl}{Section}, we broadly discuss the available literature for simultaneous planning and scheduling of mobile robots. Here, in \fref{sec:output-mpc}{Section}, we discuss output MPC that we use for replanning of $\Gamma$: a technique that uses estimates to refine the state of a model and thus to derive a control action robust to noise~\citep{rawlings2017model}. We then provide a further construct to include the battery model from \fref{cp:model}{Chapter}. In Section \fref{sec:opt-cont-gener}{Section}, we dig further into the implementation of output MPC, and finally, in \fref{sec:algo}{Section}, we discuss an algorithm for the coverage replanning and scheduling. This algorithm is central to our approach: it uses the model from \fref{cp:model}{Chapter} for energy-aware coverage planning and scheduling of the aerial robot flying under tight battery constraints and uncertainty.

\subsection{Definition of replanning via optimal control}
\label{sec:output-mpc}

In this section, we derive the optimal control (the configuration of the path and computations parameters) over a finite time horizon $N$ for an estimated state $\hat{\mathbf{q}}$ of the plan $\Gamma$. We use the estimated state $\hat{\mathbf{q}}$ in \fref{cp:est}{Section}, opposed to the ideal state in \fref{cp:model}{Chapter} due to the uncertainty. The literature commonly refers to this latter problem as output MPC\findex{output model predictive control}; a variation where estimates refine the state of a perfect model for a system of which the state is not fully known (indeed, the name refers to the notion that some available outputs estimate the state)~\citep{rawlings2017model}. For a differential model, such as the periodic model in \frefeq{eq:state-perf} in \fref{sec:periodic-model}{Section}, state estimation uses filtering techniques that include the Kalman filter in \fref{sec:kalmy}{Section}.

In our work, we do not know the state of our model (the coefficients of $\mathbf{q}$ that we presented in \fref{sec:nom-cont}{Section}), which we estimate in this section from the energy sensors measurements. Furthermore, the control differs from the nominal control in the model; in the observation in \fref{sec:nom-cont}{Section}, we presented a motivation for such control based on empirical data. The nominal control that we use inside the model maps the change in path and computations parameter to the change in time and power consumption. We use the latter to see how computations affect instantaneous energy (what happens to the power if we increase/decrease computations?), and the former to estimate the time needed to cover a given space and thus to the overall energy consumption (what happens to the energy if we travel more/fewer paths?). To this end, the algorithm that we propose in \fref{sec:algo}{Section} uses the change in path parameters to verify whenever a given path configuration can be done with the current state of charge (\Gls{acr:soc}) of the battery, whereas it uses the change in computations parameters to check that the computations configuration is within the battery maximum instantaneous energy consumption. While the former constraint is critical (having less battery SoC than needed would result in an abrupt termination of the flight), the latter does not necessarily imply a plan failure. Indeed the maximum instantaneous energy consumption is an approximated value derived from the battery model in \fref{sec:battery-model}{Section}. However, exceeding such value might degrade battery performance since the capacity fade of Li-ion batteries is related to different discharging (and charging) strategies\findex{discharging strategies}\findex{charging strategies}~\citep{lv2020analysis,tian2019quantifying}. Including this information allows future analysis on different energy-aware methodologies by, e.g., analyzing the cost of sudden spikes on the battery life as opposed to constant energy drain. We have done some earlier analysis in this direction~\citep{seewald2019coarse}, concluding that the spikes that our scheduler generates are not enough to show a visible effect on the battery life. Nonetheless, there are multiple optimizations possible within battery energy awareness, most of which depend on different battery chemistries\findex{battery chemistry}~\citep{tian2019quantifying} that are not the scope of this work. We discuss different future directions including accurate battery optimizations in \fref{cp:conc}{Chapter}.

For the sole purpose of exemplification, we provide a detailed visual example of the observation in \fref{sec:nom-cont}{Section} relative to the coverage path, showing how a change in the coverage affects the energy. We already discussed the energy effect of the change of computations on instantaneous energy consumption in \fref{sec:nom-cont}{Section}. It is due to different schedules on the computing hardware carried by the aerial robot. We observe a decrement in the power consumption intuitively by running at lower frames per second (\Gls{acr:fps}) rate. The energy effect of the change of path is due to the length of the coverage path. We elucidate what we mean by this latter statement in \fref{fig:zambo1}{Figures}\fref{fig:zambo2}{--\hspace*{-.8ex}}, where each figure represents the same coverage but different radiuses $r_2$ of the fourth circle $\varphi_4$ in the primitive paths $\varphi_1,\dots,\varphi_4$ in \fref{sec:path-wise}{Section}. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/zambo2.tikz}
  \caption[The Zamboni-like motion with the lowest parameter configuration.]{The Zamboni-like motion to cover the cell $c_1$ with the lowest configuration of parameter $c_{4,1}$ relative to the radius of the circle $\varphi_4$ in the primitive paths that form the coverage that we introduced in \fref{sec:path-wise}{Section}.}
  \label{fig:zambo2}
\end{figure}
\fref{fig:zambo1}{Figure} showed the coverage of the cell $c_1$ with the highest configuration of parameter $c_{4,1}$. If we assume that the time needed to perform the circle $\varphi_4(\overline{c}_{4,1})$ is $t_3$, the vertical lines $\varphi_1,\varphi_3$ is $2t_1$, and the circle $\varphi_2$ is $t_2$, then the overall time to cover $c_1$ with configuration ${c}_{4,1}=\overline{c}_{4,1}$ is $t_{\overline{c}_{4,1}}=7(2t_1+t_2+t_3)+t_1$. Conversely, in \fref{fig:zambo2}{Figure} we assume that the time needed to perform $\varphi_4(\underline{c}_{4,1})$ is $t_4$; then the time needed to cover $c_1$ with configuration ${c}_{4,1}=\underline{c}_{4,1}$ is $t_{\underline{c}_{4,1}}=3(2t_1+t_2+t_4)+t_1$. It is clear that $t_4<t_3$ (for how the parameter $c_{4,1}$ is constructed in \fref{sec:path-wise}{Section}) and thus $t_{\underline{c}_{4,1}}<t_{\overline{c}_{4,1}}$. If we further assume that traveling all the paths take a similar time $t_1\approx t_2\approx t_3\approx t_4$, then we can observe a 45\% time reduction in flying \fref{fig:zambo2}{Figure} compared to flying \fref{fig:zambo1}{Figure}. Analogously, in the energy domain, we can expect a considerable reduction in the battery drain with ${c}_{4,1}=\underline{c}_{4,1}$ compared to ${c}_{4,1}=\overline{c}_{4,1}$. Our purpose in the remaining of this section is to find the configuration of the path (in the latter case of $c_{4,1}$) along with the computations parameters to maximize the coverage with SoC higher than zero--to find the optimal control on $N$ w.r.t. a given energy cost.

The derivation of such optimal control involves the definition of an OCP\findex{optimal control problem} and its transformation into a nonlinear program (\Gls{acr:nlp})\findex{nonlinear program}~\citep{rawlings2017model,grune2017nonlinear}. Before, however, we re-evaluate the output constraints to include the battery model in \fref{sec:battery-model}{Section}. 
%\subsubsubsection{Output constraint set}
The output of the model in \frefeq{eq:state-perf} is the instantaneous energy consumption $y$ that we stated earlier evolves in $\mathbb{R}$. Nevertheless, there is a limit to the instantaneous energy consumption drainable from a battery at a given time instant. Moreover, aerial robots are bounded by strict energy budgets due to battery limitations, as we motivated in \fref{sec:motivation}{Section}. Hence, we redefine the original output constraint ($\mathbb{R}$) to include the battery model in \fref{sec:battery-model}{Section}. We consider SoC $b$ of the mobile robot's battery with the simplistic differential model in \frefeqM{eq:battery-model-1}{eq:battery-model-2}
\begin{equation}\label{eq:bat}
  \dot{b}(y(t),t)=-k_b\left(V-
  \sqrt{
    V^2-
    4R_ry(t)}
  \right)/(2R_rQ_c),
\end{equation}
where $k_b$ is the battery coefficient determined experimentally,  $V\in\mathbb{R}$ is the internal battery voltage measured in volts, $R_r\in\mathbb{R}$ the resistance measured in ohms, and $Q_c\in\mathbb{R}$ the constant nominal capacity measured in amperes per hour. 

From the literature on the battery SoC~\citep{sunden2019thermal,kurzweil2018state,kurzweil2021state,deng2017maximum}, we know that this latter can be calculated as $b(y(t),t)=Q(y(t),t)/Q_c$ where $Q(y(t),t)$ is the available capacity at a given time $t$. For simplicity, we omit further details that interfere in the calculation, such as battery state of health\findex{state of health}, temperature, and C-rate\findex{C-rate}. Indeed that are other methods in the literature~\citep{lu2013review,zhang2018state,espedal2021current} to estimate more accurately the SoC together with other battery parameters (these are, however, beyond the scopes of our work of coverage planning and scheduling). From the previous expression and the estimated SoC in \frefeq{eq:bat}, we can calculate the maximum instantaneous energy consumption by multiplying the constant nominal capacity, the SoC, and the internal battery voltage. We assume the maximum energy consumption cannot be negative
\begin{equation}
  0\leq y(t)\leq b(y(t),t)Q_cV,
\end{equation}
and therefore, we define a time-varying constraint for the output in \fref{def:const}{Definition}, being the maximum instantaneous energy consumption dependent on the SoC $b$ from \frefeq{eq:bat}, which is dependent on time and the instantaneous energy consumption (at the previous time step).
\begin{highlight}
\begin{defn}[Output constraint]\label{def:const}
\begin{equation*}
  \mathcal{Y}(t):=\{y\mid y\in[0,b(y(t),t)Q_cV]\subseteq{\mathbb{R}_{\geq 0}}\},
\end{equation*}
is the \emph{output constraint}\findex{output constraint}, where $b(y(t),t)Q_cV$ is the maximum instantaneous energy consumption.
\end{defn}
\end{highlight}
We assume the mobile robot carries a battery energy sensor and obtain the initial SoC $b(y(t_0),t_0)$ in the output constraint using the output of such sensor. This is a realistic assumption: aerial robots are often equipped with a flight controller, which returns various metrics, including the battery SoC. Evaluating the constraint requires numerical simulation: the battery model in \frefeq{eq:bat} is differential, similarly to the energy dynamics of the periodic model in \frefeq{eq:state-perf}. We can compute the numerical simulation using the Euler method in \fref{sec:euler}{Section} or the Runge-Kutta method in \fref{sec:rk4}{Section}. 

%\subsubsubsection{Optimal control problem for coverage (re)planning and scheduling}

To state the OCP on a finite horizon, we use a similar expression to \fref{sec:opt-constrained}{Section} with
\begin{subequations}\label{eq:ocp-output-mpc}\begin{align}
  \max_{\mathbf{q}(t),c_i(t)}&{l_f(\mathbf{q}(T),T)+\int_{t_0}^T{l(\mathbf{q}(t),c_i(t),t)\,dt}},\\
  \text{s.t. }\dot{\mathbf{q}}&=f(\mathbf{q}(t),c_i(t),t),\label{eq:dyn-evol}\\
  c_i(t)&\in\mathcal{U}_i,\mathbf{q}(t)\in\mathbb{R}^m,\label{eq:state-cont-const-mpc}\\
  y(t)&\in\mathcal{Y}(t),\label{eq:batt-const-mpc}\\
  \mathcal{S}_{i,j}&:=\{0\},\,\forall j \in [\sigma]\text{ when }\mathbf{p}(t)\notin\mathcal{Q}^v,\label{eq:polyg-const}\\
  \mathbf{q}(t_0)&=\hat{\mathbf{q}}_0\,\,\,\text{given (last estimate state)},\text{ and}\\
  b(y(t_0),t_0)&=b_0\,\,\,\text{given},
\end{align}\end{subequations}
where constraints in \frefeqM{eq:dyn-evol}{eq:polyg-const} are evaluated on $t\in[t_0,T]$. $\mathbf{q}(t)$ and $c_i(t)$ are the state and control trajectories and $\mathbf{p}(t)$ is the aerial robot's position w.r.t. an inertial navigation frame $\mathcal{O}_W$. The sizes of the state and control ($m$ and $n$) are defined in \fref{sec:periodic-model}{Section} and \fref{sec:nom-cont}{Section}. By solving the OCP in \frefeq{eq:ocp-output-mpc}, we want to derive the trajectory $c_i^*(t)=\{c^*_{i,1},\dots,c^*_{i,\rho},c^*_{i,\rho+1},\dots,c^*_{i,\rho+\sigma}\}$ in \fref{sec:defs-stages-triggs}{Section} for a given stage $i$ in \fref{def:stage}{Definition}. In the $\max$ term in \frefeq{eq:ocp-output-mpc}, we further derive the trajectory of the ideal state $\mathbf{q}(t)$, which we can use to evaluate the model's fidelity against future measured data. Indeed the solution to the OCP has to  evolve the model from trained data using state estimation up to the initial time instant $t_0$. At the very beginning of the optimization (when $t_0=0$), we will see that the perfect model evolution in \frefeq{eq:dyn-evol} does not correspond to the data despite converging later on: for successive horizons, there $\exists k\text{ s.t. }t_0=kN$ and the model in \frefeq{eq:dyn-evol} converges for $\mathbf{q}(kN)=\hat{\mathbf{q}}_{kN}$. Our constraints contain the control and state constraint in \frefeq{eq:constraint-set}, the output constraint in \fref{def:const}{Definition}, and the dynamics with the ideal state evolution in \frefeq{eq:state-perf} in \frefeqM{eq:dyn-evol}{eq:batt-const-mpc}. The OCP further contains the coverage constraint from \fref{sec:path-wise}{Section} and \fref{sec:cov-motion}{Section} in \frefeq{eq:polyg-const}. Although the aerial robot can overfly the obstacles and the edges of the polygon, it cannot compute any computation. Formally, we inhibit the computations setting their constraint to $\{0\}$ when the aerial robot is flying over the $i$th obstacle $o_i$ and out of the polygon $v$ (it is thus out of the space $\mathcal{Q}^v$). We have similarly inhibited the computations out of the polygon $v$ in \fref{sec:path-wise}{Section}.

The dynamic evolution in \frefeq{eq:dyn-evol} is then the periodic model in \frefeq{eq:state-perf} together with the scale transformation from \fref{sec:merging}{Section}
\begin{equation}\label{eq:perf-model-in-mpc}
  f(\mathbf{q}(t),c_i(t),t)=A\mathbf{q}(t)+B\mathrm{diag}(\nu_i)(c_i(t)-c_i(t-\Delta t)),
\end{equation}
where $c_i(t-\Delta t)$ is the control at the time instant preceding $t$, $A$ is the state transition matrix in \frefeq{eq:mat_A}, $B$ the input matrix in \frefeq{eq:mat_B}, and $\nu_i$ is the scale transformation in \frefeq{eq:scaling} with the scaling factors that for the first $\rho$ path parameters are given in \frefeq{eq:scale-traj} and for the remaining computations parameters in \frefeq{eq:scale-comp}.

The instantaneous cost function is the quadratic expression
\begin{equation}\label{eq:insta-cost-mpc}
  l(\mathbf{q}(t),c_i(t),t)=\mathbf{q}'(t)Q\mathbf{q}(t)+c_i'(t)Rc_i(t),
\end{equation}
where $Q\in\mathbb{R}^{m\times m},R\in\mathbb{R}^{n\times n}$ are given positive semidefinite matrices, resulting in the convexity of the cost $l$~\citep{nocedal2006numerical} with some guarantees on the solution~\citep{beck2014introduction}.

The final cost function is alike a quadratic expression but with no control
\begin{equation}\label{eq:final-cost-mpc}
  l_f(\mathbf{q}(T),T)=\mathbf{q}'(T)Q_f\mathbf{q}(T),
\end{equation}
where $Q_f\in\mathbb{R}^{m\times m}$ is a given positive semidefinite matrix. %We discuss in \fref{sec:opt-cont-gener}{Section} the items of the matrices $Q,R,$ and $Q_f$ in a concrete implementation of the output model predictive controller. 

The horizon $N$ is in seconds, and the controller selects the optimal control trajectory $c_i^*(t)$ over $[t_0,T]$, with $T=t_0+N$. At each instant, the controller refines the control trajectory (replans the coverage and schedule) that respects the constraints. To evaluate the state trajectory--needed for the instantaneous cost function $l$ and the final cost function $l_f$--the controller evaluates the battery trajectory $b(y(t),t)$ (it has to verify that the output is in $\mathcal{Y}(t)$). It then maximizes the instantaneous cost function $l$ for all the time instants but $T$ ($t_0\leq t < t_0+N$), and the final cost function $l_f$ in \frefeq{eq:final-cost-mpc} for the time instant $T$ ($t=t_0+N$).
The dynamics constraint satisfaction requires to evolve the perfect model $f$ in \frefeq{eq:perf-model-in-mpc} over horizon $[t_0,t_0+N]$ beginning from the last estimated state $\mathbf{q}_0=\hat{\mathbf{q}}(t_0)$ at time instant $t_0$. Similarly, the output constraint satisfaction requires then to evolve the battery constraint on $[t_0,t_0+N]$, from the last battery measurement $b_0$ from the battery energy sensor at instant $t_0$.

The OCP from \frefeq{eq:ocp-output-mpc} is infinite-dimensional, being the system dynamics in \frefeq{eq:dyn-evol} and the battery dynamics in \frefeq{eq:bat} given in continuous- and not discrete-time. Such an infinite dimensional OCP has an infinite-dimension of constraints and decision variables since there are infinitely many time instants between $t_0$ and $t_0+N$. We discretize the OCP to finite dimensions in \fref{sec:opt-cont-gener}{Section}.

\subsection{Replanning with output model predictive control}
\label{sec:opt-cont-gener}

In this section, we solve the OCP in \frefeq{eq:ocp-output-mpc}, providing a solution to \fref{pb}{Problem} that we introduced along with \fref{pb:cov-pb}{Problem} in \fref{cp:soa}{Chapter}. We use the notions from the previous sections and \fref{cp:model}{Chapters}\fref{cp:opt}{--\hspace*{-.8ex}}: with the solution, we derive the configuration of paths and computations $c_i^*$ for each stage $i$ in an energy-aware fashion to replan the plan $\Gamma$. The solution to \fref{pb:cov-pb}{Problem} is the plan $\Gamma$, which contains the primitive paths for the coverage motion in \fref{sec:cov-motion}{Section} and \fref{sec:path-wise}{Section}, along with the computations in \fref{sec:computation-wise}{Section}. 

We are interested in providing this solution online, with a procedure running onboard the aerial robot subject to various atmospheric interferences. There are different techniques for this purpose~\citep{grune2017nonlinear,rawlings2017model}. In \fref{cp:opt}{Chapter}, we saw some relevant to our approach, which are the direct methods already employed in many MPC-related applications~\citep{rawlings2017model}. In particular, we saw single and multiple shooting methods\findex{single shooting method}\findex{multiple shooting method} in \fref{sec:single-shoot}{Sections}\fref{sec:multi-shoot}{--\hspace*{-.8ex}}. They parametrize the control and state trajectories with a finite-dimensional vector and derive an NLP~\citep{rawlings2017model}. Both the methods perform this latter discretization, but the resulting NLP differs. The multiple shooting method keeps the states as decision variables at the boundary time points, allowing further optimizations~\citep{rawlings2017model}. It combines some of the advantages of the other methods, such as the direct collocation method\findex{collocation method} that we discussed in \fref{sec:colloc}{Section}, together with the direct single shooting method~\citep{diehl2006fast,grune2017nonlinear}. Once we obtain the finite-dimensional NLP, we can solve it numerically, with the numerical solvers available in the literature~\citep{diehl2006fast,grune2017nonlinear,nocedal2006numerical}. 

The NLP derived from the OCP in \frefeq{eq:ocp-output-mpc} is
\begin{subequations}\label{eq:disc-ocp-output-mpc}\begin{align}
  \max_{\mathbf{q}(k),c_i(k)}{l_f(\mathbf{q}(T}&{),T)+\sum_{k\in\mathcal{K}}{l_d(\mathbf{q}(k),c_i(k),k)}},\\
  \text{s.t. }\mathbf{q}(k+h)&=f_d(\mathbf{q}(k),c_i(k),k),\label{eq:disc-dyn-evol}\\
  c_i(k)&\in\mathcal{U}_i,\mathbf{q}(k)\in\mathbb{R}^m,\label{eq:disc-state-cont-const-mpc}\\
  y(k)&\in\mathcal{Y}(k),\label{eq:disc-batt-const-mpc}\\
  \mathcal{S}_{i,j}&:=\{0\},\,\forall j \in [\sigma]\text{ when }\mathbf{p}(k)\notin\mathcal{Q}^v,\label{eq:disc-polyg-const}\\
  \mathbf{q}(t_0)&=\hat{\mathbf{q}}_0\,\,\,\text{given (last estimated state)},\text{ and}\\
  b(y(t_0),t_0)&=b_0\,\,\,\text{given},
\end{align}\end{subequations}
where the constraints in \frefeqM{eq:disc-dyn-evol}{eq:disc-polyg-const} are evaluated now on a finite interval $k\in\mathcal{K}=\{t_0,t_0+h,t_0+2h,\dots,T\}$, and $h$ is a given time step or distance between two  consecutive time instants; the smaller the distance, the more precise the simulation. The other expressions are analogous to \frefeq{eq:ocp-output-mpc}.

We use numerical simulation\findex{numerical simulation} to transform \frefeq{eq:ocp-output-mpc} into \frefeq{eq:disc-ocp-output-mpc}. We can use either the Runge-Kutta methods\findex{Runge-Kutta methods} in \fref{sec:rk4}{Section} or the Euler method\findex{Euler method} in \fref{sec:euler}{Section}. For simplicity, we show the transformation with the Euler method. The instantaneous cost function
\begin{equation}\label{eq:mpc-cost-euler}
  l_d(\mathbf{q}(k),c_i(k),k)=hl(\mathbf{q}(k),c_i(k),k),
\end{equation}
where $l$ is given in \frefeq{eq:insta-cost-mpc}.

The discrete dynamic evolution in \frefeq{eq:disc-dyn-evol}
\begin{equation}
  f_d(\mathbf{q}(k),c_i(k),k)=A_d\mathbf{q}(k)+B\mathrm{diag}(\nu_i)(c_i(k)-c_i(k-h)),
\end{equation}
where $A_d$ is the discretized version of the state transition matrix $A$ in \frefeq{eq:mat_A} and for a small enough interval of $h$
\begin{equation}
A_d=(hA+\mathrm{diag}(1,1,\dots,1)),
\end{equation}
where $\mathrm{diag}(1,1,\dots,1)\in\mathbb{R}^{m\times m}$ is a diagonal matrix of ones. $B$ is then the input matrix in \frefeq{eq:mat_B}, and $\nu_i$ is the scale transformation in \frefeq{eq:scaling} with the scaling factors that for the first $\rho$ path parameters are given in \frefeq{eq:scale-traj} and for the remaining $\sigma$ computations parameters in \frefeq{eq:scale-comp}, similarly to \frefeq{eq:perf-model-in-mpc}.

To discretize the battery dynamics in \frefeq{eq:bat}, we use
\begin{equation}\label{eq:batt-euler}
  b_d(y(k+h),k+h)=b(y(k),k)+hb(y(k+h),k+h),
\end{equation}
where $b$ is given in \frefeq{eq:bat} and $y(k)$ is the output of the model in \frefeq{eq:state-perf-output}. The matrix $C$ is to be found in \frefeq{eq:mat_C}.

In \frefeq{eq:disc-ocp-output-mpc}, we transformed the OCP in \frefeq{eq:ocp-output-mpc} into an NLP by first discretizing and thus effectively implementing the direct multiple shooting method in \fref{sec:multi-shoot}{Section}. We note that we can implement the single shooting method by keeping only the initial state as the decision variable $\hat{\mathbf{q}}_0$, conversely to using the interval boundary time points as a decision variable in the multiple shooting method~\citep{rawlings2017model}.


%For convenience, we replace the constraints in \frefeqM{eq:disc-dyn-evol}{eq:disc-batt-const-mpc} using equality and inequeality constraints such that the problem can be then solved by a numerical optimization algorithm. The \frefeq{eq:disc-dyn-evol} becames

\subsection{Coverage planning and scheduling algorithm}
\label{sec:algo}

\fref{algo:repla}{Algorithm} derives the optimal configuration of path and computations parameters and thus computes the coverage (re)planning and scheduling. It inputs the initial plan $\Gamma$ along with the initial time step and a guess for the energy model that we proposed in \fref{sec:period-est}{Section} and outputs the revised plan $\Gamma$ when the aerial robot reaches the final point $\mathbf{p}_{\Gamma_l}$. It optionally inputs then the initial stage that is within $[n]_{>0}$ when $\Gamma$ compromise primitive stages, $[l]_{>0}$ otherwise. In the remainder of this chapter, we discuss in detail the algorithm.

\begin{algorithm}[h!] %this is an example
  \SetKwInOut{Input}{Input}
  \SetKwInOut{Output}{Output}
  \SetKwFunction{FMain}{\small\tt zamboni-like\_motion}
  \SetKwProg{Fn}{Function}{:}{}
  \SetKwProg{Pn}{Function}{:}{\KwRet}

  \DontPrintSemicolon
  \Input{$\Gamma${ \otherfont initial plan}\newline
         $t_0${ \otherfont initial time step}\newline
         $\mathbf{q}(t_0)${ \otherfont initial guess for the energy model}\newline
         $j${ \otherfont starting stage within the primitive stages }$\in[n]_{>0}${ \otherfont otherwise }$j=1$
  }
  \Output{$\Gamma${ \otherfont revised plan}
  }
  \vspace{.8ex}

  %{\normalsize $j\gets 1$}\;
  
  \ForEach{\normalsize $i\in\{t_0,t_0+h,t_0+2h,\dots\}$}{\label{algo:repla:foreach}
    \If{\normalsize $\mathbf{p}(i)\neq\mathbf{p}_{\Gamma_l}$}{\label{algo:repla:endcheck}
      \Return{\normalfont $\Gamma$}\;\label{algo:repla:return}
    }
    \If{\normalsize $\mathbf{p}(i)=\mathbf{p}_{\Gamma_j}$}{\label{algo:repla:istrig}
      {\normalsize $j\gets j+1$}\;
      \If{\normalsize $j\notin[n]_{>0}$}{
        {\normalsize $j\gets 1$}\;
        {\normalsize $\varphi_1,\varphi_2,\dots,\varphi_n\gets${ \otherfont shift }$\varphi_1,\varphi_2,\dots,\varphi_n${ \otherfont of }$\mathbf{d}$}\;\label{algo:repla:shiftpaths}
        {\normalsize $\mathbf{p}_{\Gamma_1},\mathbf{p}_{\Gamma_2},\dots,\mathbf{p}_{\Gamma_n}\gets${ \otherfont shift also }$\mathbf{p}_{\Gamma_1},\mathbf{p}_{\Gamma_2},\dots,\mathbf{p}_{\Gamma_n}${ \otherfont of }$\mathbf{d}$}\;\label{algo:repla:shifttrigs}
      }
    }
    \vspace{.8ex}
    
    {\normalsize $\mathbf{q}(\mathcal{K}\setminus\{i+N\}),c_j(\mathcal{K})\gets${ \otherfont solve NLP }$\argmax_{\mathbf{q}(k),c_j(k)}{l_f(\mathbf{q}(i+N),i+N)}+$ \hspace*{1em}${\sum_{k\in\mathcal{K}}{l_d(\mathbf{q}(k),c_j(k),k)}}${ \otherfont from \frefeq{eq:disc-ocp-output-mpc} on }$\mathcal{K}=\{i,i+h,\dots,i+N\}$
    }\;\label{algo:repla:mpc}
    \vspace{.8ex}

    {\normalsize $\mathbf{q}(i+h)\gets A_d\mathbf{q}(i)+B\mathrm{diag}{(\nu_j)}(c_j(i)-c_j(i-h))$}\;\label{algo:repla:sysevo}
    {\normalsize $P(i+h)^-\gets A_d P(i)A_d'+S(i)$}\;\label{algo:repla:covesterrorpri}
    {\normalsize $K(i+h)\gets (P(i+h)^-C')/(CP(i+h)^-C'+V(i))$}\;\label{algo:repla:goodoldkalmygains}
    {\normalsize $\hat{\mathbf{q}}(i+h)\gets${ \otherfont compute }$\mathbf{q}(i+h)+K(i+h)(y(i)-C\mathbf{q}(i+h))${ \otherfont from energy sensor }$y(i)$}\;\label{algo:repla:apoststate}
    {\normalsize $\hat{y}(i+h)+C\hat{\mathbf{q}}(i+h)$}\;
    {\normalsize $P(i+h)\gets (I+K(i+h)C)P(i+h)^-$}\;\label{algo:repla:endkalmy}
    \vspace{.8ex}
    
    {\normalsize $k\gets i$}\;\label{algo:repla:initbat}
    \While{\normalsize $b_d(k)>0$}{
      \If{\normalsize $k\notin\mathcal{K}$}{
        {\normalsize $\mathbf{q}(k+h)\gets A_d\mathbf{q}(k)$}\;\label{algo:repla:sysevobatt}
      }
      {\normalsize $b_d(k+h)\gets b_d(k)-hk_b\left(V-\sqrt{V^2-4R_rC\mathbf{q}(k+h)}\right)/(2R_rQ_c)$}\;\label{algo:repla:battevo}
      {\normalsize $k\gets k+h$}\;
    }
    {\normalsize $t_b\gets k-i$}\;\label{algo:repla:endbat}%the maximum estimated battery time
    {\normalsize $t_s\gets(\mathrm{diag}(\nu_j^\rho)c_j^\rho(i)+\tau_j^\rho)[\overbrace{\begin{matrix}1&1&\cdots&1\end{matrix}}^{\rho}]$}\;\label{algo:repla:configtime}%time needed to do the configuration $c_j(i)$
    {\normalsize $t_r\gets(t_s/\overline{t})(\overline{t}-ih)$}\label{algo:repla:loosingmyreligiontime}\;%remaining time
    \If{\normalsize $t_r<t_b$}{
      {\normalsize $c_j^{\rho}(i)\gets${ \otherfont find }$c_j^{\rho}${ \otherfont with }$t_c\in[0,t_b]${\otherfont , otherwise take }$\underline{c}_j^\rho$}\;\label{algo:repla:newpathparam}
    }
    \vspace{.8ex}
    
    {\normalsize $\mathbf{p}(i+h)\gets${ \otherfont compute from position }$\mathbf{p}(i)${\otherfont , velocity }\normalfont $v(i)${ \otherfont with }\normalfont $\Delta_d\varphi_j${ \otherfont in \fref{algo:track}{Algorith}}}\;\label{algo:repla:gvf}
  }
  \vspace{.8ex}

  \caption{Coverage (re)planning and scheduling algorithm}
  \label{algo:repla}
\end{algorithm}

The algorithm iterates at each time step $h\in\mathbb{R}_{>0}$ on \fref{algo:repla:foreach}{Line}, with the size of $h$ related to the accuracy and the time needed for replanning: the higher the step, the lower the accuracy, but the shorter the necessary time to replan $\Gamma$. Nonetheless, there are further constraints on $h$ due to the numerical simulation algorithm: $h$ has to be small enough ($h\rightarrow 0$) so that the numerical simulation (on \fref{algo:repla:mpc}{Line}, \fref{algo:repla:sysevo}{}, \fref{algo:repla:sysevobatt}{}, and \fref{algo:repla:battevo}{}) does not diverge. To this end, a typical value for $h$ that we adopted is 1/100 of a second; there are various techniques to estimate $h$ more accurately, e.g., by running the numerical simulation and analyzing the error of two different guesses~\citep{iserles2009first}; such techniques are, however, beyond the scopes of this work. With a small enough $h$, Euler method\findex{Euler method} that we use in \frefeqM{eq:mpc-cost-euler}{eq:batt-euler} converges to the real solution--see~\citep{iserles2009first,atkinson2009euler} for a formal proof--whereas for problems with higher accuracy we advise the Runge-Kutta methods\findex{Runge-Kutta methods}  in \fref{sec:rk4}{Section} that are among the most popular methods for numerical simulation~\citep{atkinson2009euler}. These methods use quadrature\findex{quadrature}: a procedure that replaces the integral with a finite sum~\citep{iserles2009first}. We use the Runge-Kutta inside \powprof{} in \fref{sec:powprof}{Section} and the Euler method in the algorithm for simplicity.

On  \fref{algo:repla:endcheck}{Lines}\fref{algo:repla:return}{--\hspace*{-.8ex}}, the algorithm verifies whenever the aerial robot reached the final point $\mathbf{p}_{\Gamma_l}$ in \fref{def:trigs}{Definition} and returns the replanned plan $\Gamma$ in this latter eventuality, and on \fref{algo:repla:istrig}{Lines}\fref{algo:repla:shifttrigs}{--\hspace*{-.8ex}}, switches the stages when the aerial robot reaches a triggering point (also in \fref{def:trigs}{Definition}). If $\Gamma$ contains $n$ primitive paths rather than all the stages up to $l$ explicitly, on \fref{algo:repla:shiftpaths}{Lines}\fref{algo:repla:shifttrigs}{--\hspace*{-.8ex}}, it updates the paths and the triggering points with the shift $\mathbf{d}$. It then selects the energy-aware configuration of computations on \fref{algo:repla:mpc}{Line} by solving the NLP in \frefeq{eq:disc-ocp-output-mpc} derived from the OCP in \frefeq{eq:ocp-output-mpc} using the multiple shooting method\findex{multiple shooting method} in \fref{sec:multi-shoot}{Section}. It thus obtains the trajectory of the controls and states for a given horizon $N$ expressed in seconds. In particular, the control trajectory contains $|\mathcal{K}|-1$ items, whereas the state trajectory $|\mathcal{K}|$ items. This discrepancy in the number of sets of the two trajectories is due to the construction of OCP. We provide an initial guess for the state $\mathbf{q}(i)$ at time instant $i$ but derive the first control $c_j(i)$ already from the solution to the OCP. For the horizon $N$, we adopted the value of $N$ equal to ten seconds, meaning the algorithm evolves the model in \frefeq{eq:perf-model-in-mpc} and \frefeq{eq:state-perf} for ten future seconds and selects the control trajectory $c_j^*$ that minimizes the costs in \frefeq{eq:mpc-cost-euler} and \frefeq{eq:final-cost-mpc}. The higher the horizon, the better the accuracy. A typical value in the aerial robotics literature that implements MPC~\citep{gavilan2015iterative,kang2009linear,stastny2018nonlinear,chao2011collision} is of dozens of seconds. For instance, it is fourteen in Gavilan~et~al., ten and forty in Kang~and~Hedrick, two to eight in Stastny~and~Siegwart, and five in Chao~et~al.
To solve the NLP in \frefeq{eq:disc-ocp-output-mpc}, the algorithm evaluates the constraints in \frefeqM{eq:disc-dyn-evol}{eq:disc-polyg-const} ($t_0$ in the latest two constraints is equal to $i$), where it has to numerically simulate both the energy and the battery models from $i$ to $i+N$ with a step size of $h$. A possible optimization that considerably speeds up the derivation of the optimal control is to use different horizons for numerical simulation and the constraints, i.e., $\mathcal{H}={i,i+nh,i+2h,i+N}$, where $n\in[1,1/h]$. When $n$ is equal to $1/h$, the algorithm adds the constraints at each second but numerically simulates the models on $\mathcal{K}$. Another optimization is to move the constraint in \frefeq{eq:disc-polyg-const} out of the NLP and check whenever the aerial robot is flying the obstacle and thus require $c_j^\rho={0}$.

On \fref{algo:repla:sysevo}{Lines}\fref{algo:repla:endkalmy}{--\hspace*{-.8ex}}, the algorithm estimates the state $\mathbf{q}$ of the periodic model in \fref{sec:periodic-model}{Section}, filtering the state with Kalman filter in \fref{sec:kalmy}{Section} from the energy sensor's measurements $y(i)$. The Kalman filter\findex{Kalman filter} has several important properties over other methods for state estimation, and among the others, minimizes the variance of the estimation mean square error (\Gls{acr:mse})~\citep{kalman1960new,simon2006optimal,jwo2007practical}. On \fref{algo:repla:sysevo}{Line}, the algorithm computes the a priori, and on \fref{algo:repla:apoststate}{Line} the a posteriori state estimation. On \fref{algo:repla:covesterrorpri}{Line}, the a priori covariance state error with $P$ the covariance of the state estimation error (we provide an initial guess $P(t_0)\in\mathbb{R}^{m\times m}$, the covariance error of $\mathbf{q}(t_0)$) and $S\in\mathbb{R}^{m\times m}$ the covariance of the state noise, and on \fref{algo:repla:goodoldkalmygains}{Line}, the gain with $V\in\mathbb{R}$ the covariance of the output noise~\citep{simon2006optimal}. To ease the computations, we keep the covariances fixed in our experimental setup.

On \fref{algo:repla:initbat}{Lines}\fref{algo:repla:endbat}{--\hspace*{-.8ex}}, the algorithm estimates the time needed to completely drain the battery with the differential model in \fref{sec:battery-model}{Section}, in \frefeq{eq:bat}, and \frefeq{eq:batt-euler}, using the Euler method for numerical simulation (as on \fref{algo:repla:sysevo}{Line}). A possible optimization in this set of lines is to utilize the state already from MPC on \fref{algo:repla:mpc}{Line} for future energy prediction on the horizon $N$; at further time horizons, we don't have any trajectory for the control available, and thus we keep $c_j(k)=c_j(i+N-h),\,\forall k>i+N-h$. The variable $t_b$ on \fref{algo:repla:endbat}{Line} contains the estimated available battery time. The algorithm then computes the scale transformation from the path parameters domain to the time domain in \fref{sec:merging}{Section} on \fref{algo:repla:configtime}{Line} and the estimated remaining time of the path parameters $c_j^\rho(i)$ on \fref{algo:repla:loosingmyreligiontime}{Line}. It selects a different configuration of path parameters when the battery time is lower than the remaining time on \fref{algo:repla:newpathparam}{Line}. We can further assume that the battery information is incomplete or that the model does not account for all the eventualities and select the best configuration for the current total battery time. Finally, on \fref{algo:repla:gvf}{Line}, the algorithm computes the next position in space using the vector field for guidance in \fref{sec:gvf}{Section}, where $v(i)\in\mathbb{R}_{\geq 0}$ is the velocity and $\mathbf{p}(i)$ the position at the current time step $i$. 

%Furthermore, the periodic model that we provided in \fref{cp:model}{Chapter} requires an amount of time for


\section{\color{red}Results}


\section{\color{red}Summary}

