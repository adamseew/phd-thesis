
%%%%%%%%%%%%%%%%%%%%%%
%                    %
% State estimation   %
%                    %
\chapter{\color{red}State Estimation}
\label{cp:est}

%\begin{highlight}
%    \begin{st}
%        General structure with just some dummy text.
%    \end{st} 
%\end{highlight}

%\lettrine{A}{a}, 


\section{\color{orange}A Brief History of State Estimation}


\section{\color{orange}A Necessary Background on Probability Theory}


\section{\color{red}The Curve Fitting Problem}

\subsection{\color{orange}Least square fitting}

\subsection{\color{red}Levenberg-Marquardt algorithm}


\section{\color{red}Periodic Model Estimation}

\subsection{\color{red}Period estimation}
\label{sec:period-est}

\subsection{\color{orange}Minimization of the estimate error}

\subsection{\color{red}Period and horizon in continuous estimation}


\section{\color{red}Filtering}

\subsection{\color{cyan}Discrete time Kalman filter}


As the environment uncertainty and measurement error evolve in a normal distribution, we use a Kalman filter~\citep{stengel1994optimal, simon2006optimal} for the purpose of state estimation. 

The prediction is done using
\begin{subequations}\label{eq:kalman-pred}\begin{align}
  \hat{\mathbf{q}}_{k+1}^-&=A\hat{\mathbf{q}}_{k}+B\mathbf{u}_k,\label{eq:kalman-pred1}\\
  P_{k+1}^-&=AP_kA'+Q,\label{eq:kalman-pred2}
\end{align}\end{subequations}
where $\hat{\mathbf{q}}_k^-,\hat{\mathbf{q}}_k\in\mathbb{R}^j$ depicts the estimate of the state before and after measurement (or simply estimate), and $P_k,P_k^-\in\mathbb{R}^{j\times j}$ the error covariance matrix (i.e., the variance of the estimate). 

The estimation of the state and the update of the predicted output is done using
\begin{subequations}\label{eq:kalman-est}\begin{align}
  K_k&=(CP_{k+1}^-C'+R)^{-1}(P_{k+1}^-C'),\\
  \hat{\mathbf{q}}_{k+1}&=\hat{\mathbf{q}}_{k+1}^-+K_k(y_k^s+y_k^c-C\hat{\mathbf{q}}_{k+1}^-),\label{eq:kalman-est2}\\
  P_{k+1}&=(I-K_kC)P_{k+1}^-,\\
  \hat{y}_k&=C\hat{\mathbf{q}}_{k+1},\label{eq:kalman-est4}
\end{align}
\end{subequations}
where $K_k\in\mathbb{R}^j$ is the gain of the Kalman filter, and $I$ the identity matrix. $y_k^s,y_k^c$ are the instantaneous energy readings: $y_k^s\in\mathbb{R}_{\geq 0}$ the robot sensor, i.e., the energy due to the trajectory, and $y_k^c$ the energy of a given software configuration described {\color{red}in 
\dots}. The noise covariance matrices $Q\in\mathbb{R}^{j\times j},R\in\mathbb{R}$ indicates the uncertainty and measurement error covariance respectively, and $\hat{y}_k\in\mathbb{R}_{\geq 0}$ is the estimated energy.

\frefeqM{eq:kalman-pred}{eq:kalman-est} converge to the predicted energy evolution as follows. An initial guess of the values $\hat{\mathbf{q}}_0,P_0$ is derived empirically from collected data. It is worth considering that an appropriate guess of these parameters allows the algorithm to converge to the desired energy evolution in a shorter amount of time. The tuning parameters $Q,R$ are also derived from the collected data, and may differ due to i.e., different sensors used to measure the instantaneous energy consumption, or different atmospheric conditions accounting for the process noise.

At time $k=0$, the initial estimate before measurement of the state and of the error covariance matrix is updated in \frefeqM{eq:kalman-pred1}{eq:kalman-pred2} respectively. The value of $\hat{\mathbf{q}}_1^-$ is then used in \frefeq{eq:kalman-est2} to estimate the current state along with the data from the sensor $y_0$ (e.g., the energy sensor of the flight controller of the fixed-wing craft), where the sensor noise covariance matrix $R$ accounts for the amount of uncertainty in the measurement. The estimated output $\hat{y}_0$ is then obtained from \frefeq{eq:kalman-est4}. The algorithm is iterative. At time $k=1$ the values $\hat{\mathbf{q}}_1,P_1$ computed at previous step are used to estimate the values $\hat{\mathbf{q}}_2,P_2,$ and $y_1$.

\subsection{\color{orange}Continuous time Kalman filter}

\subsection{\color{orange}Nonlinear filtering}


\section{\color{red}Results}


\section{\color{red}Summary}

