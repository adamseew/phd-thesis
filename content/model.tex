
%
%%%%%%%%%%%%%%%%%%%
%                 %
% Energy Models   %
%                 %
%%%%%%%%%%%%%%%%%%%
%
% Brief abstract: contains the energy models that are later employed for replanning and scheduling
%
% Completion (1-10): 9
% Missing: some explanations on aperiodic models, summary, results, two figures
%
\chapter{Energy Models}
\label{cp:model}

\begin{chapquote}{\cite{ondruska2015scheduled}}
  ``Robots require energy to operate. Yet they only have access to limited energy storage during missions.''
\end{chapquote}

\vspace*{1em}

\lettrine{E}{nergy is an essential aspect} of many autonomous mobile robotics scenarios~\citep{mei2005case} and often a limiting factor to improving computing performance~\citep{horowitz2014computing}. In the previous chapters, we emphasized the growing importance of both computations and motion energy components. Indeed, limited energy availability against high computing performance requirements of autonomous aerial robots is the motivation for the energy-aware coverage planning and scheduling for autonomous aerial robots in this work. For this purpose, we first need an accurate energy model that predicts future energy consumption. We derive such a model in this chapter, providing different energy models predicting the energy of the motion and computations and the battery state of an aerial robot. For the former two, we first derive a way to accurately predict the energy spent running a given set of computations on the computing hardware. We then merge the resulting computations energy model with a motion energy model using some properties of our autonomous scenario.  The energy output of the motion model is the input of the battery model, which predicts the battery evolution over time.

We saw in \fref{cp:model}{Chapter} some computations energy and battery models, and we discussed some energy-aware approaches for aerial robots (and mobile robots broadly) performing coverage path planning (\Gls{acr:cpp}) or motion planning generally. In this chapter, we then use the previous literature and derive the energy models for our scenario: an autonomous aerial robot employed in coverage planning, monitoring an agricultural field. Although applied to a given use case, the approach is general in terms of the proposed methodology. In \fref{sec:comp-ener-model}{Section}, we derive the model for the energy of computations based on regressional modeling. In \fref{sec:battery-model}{Section}, we provide a battery model based on an equivalent electrical circuit, and in \fref{sec:periodic-model}{Section}, we derive a model for the motion that incorporates the computations energy model. We then use the models in \fref{cp:dyn}{Chapter} to plan and schedule altogether.

This chapter connects to the remainder of this work as follows. We provided some energy implications of autonomous aerial robots in \fref{cp:intro}{Chapter} and formulated the basic constructs in \fref{cp:pb}{Chapter}, including the concepts of computations and motion energy. We discussed the past energy modeling and efficiency studies in \fref{cp:soa}{Chapter}, along with other literature. We then use all the information we discussed in the previous chapters for the energy models in this chapter. In \fref{cp:dyn}{Chapter}, we use the models to replan the coverage and schedule the computations in an energy-aware fashion. The replanning uses some optimal control techniques that we introduce in \fref{cp:opt}{Chapter}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy Model of the Computations}
\label{sec:comp-ener-model}

This section describes the computations energy model to predict the energy consumption of a given configuration of computations. In \fref{sec:definitions}{Section} and the precision agriculture example in \fref{sec:computation-wise}{Section}, we parametrized the computations by a set of $\sigma$ computations parameters $c_{i}^\sigma:=\{c_{i,\rho+1},\dots,c_{i,\rho+\sigma}\}$, where $\rho$ is the number of path parameters. We parametrize the computations that impact the overall energy consumption (as we described in \fref{def:comps}{Definition}). For instance, in the agricultural scenario, we parametrize the computation object detection. We mean by parametrization that we enable the computations to be dynamically replanned with an appropriate choice of the parameters, and run on, e.g., a lower/higher rate requiring lower/higher power. Practically, this means that if our system is composed of $\sigma$ computations, the configuration of computations parameters $c_i^\sigma(\mathcal{T})$ for each stage $i$ over time $\mathcal{T}:=[t_0,t_l]$ (where $t_0,t_l$ are respectively the first time instant and the time instant when the aerial robot reaches the final point $\mathbf{p}_{\Gamma_l}$ in \fref{def:trigs}{Definition}) is a schedule of the computations. In \fref{cp:dyn}{Chapter}, we will derive an energy-aware schedule via the model that we propose in this section.
In the remainder of this section, we derive an energy model that maps any choice of parameters $c_{i}^{\sigma}$ to the power at any $t\in\mathcal{T}$, extending the past work on energy modeling for heterogeneous computing hardware.

In \fref{sec:model-hete-elem}{Section}, we summarize the heterogeneous elements modeling from \fref{sec:soa-ene-hete}{Section} and outline our approach, which consists of two layers. We detail the layers in \fref{sec:measurement-layer}{Sections}\fref{sec:predictive-layer}{--\hspace{-.8ex}} and describe an automated modeling tool we developed in \fref{sec:powprof}{Section} along with its configuration specification in \fref{sec:conf-spec}{Section}. The tool works well for computing hardware equipped with internal power meters, yet, some computing hardware does not provide any. We discuss how to model such hardware also in \fref{sec:powprof}{Section}.


\subsection{Model for the heterogeneous elements}
\label{sec:model-hete-elem}

We saw in \fref{cp:pb}{Chapter} that traditionally, models for computing hardware focus on a specific computing element, such as CPU or GPU, or model the elements heterogeneously. The models provide a regression function (measuring the power consumption over time), analytical (using some architectural parameters), or other expressions to infer future energy consumption. The regression functions, analytical or other expressions might depend on low-level architectural parameters and be employed in an energy-efficient selection of such parameters, including voltage and frequency. Alternatively, they might depend on high-level parameters (such as the computations parameters $c_{i}^\sigma$ in this work) and be employed in an energy-aware configuration of software (and hardware), e.g., the tasks allocation on the CPU cores. An expression depending on a configuration is more common for heterogeneous models, as we summarized in \fref{tab:energy-models}{Table}. We focus on these models; in \fref{cp:intro}{Chapter} and formally in \fref{def:comps}{Definition}, we assumed the aerial robot caries heterogeneous computing hardware for energy-demanding computations. We refer to \fref{sec:comp-ener-model}{Section} for an extensive discussion of some energy modeling approaches in the literature for CPUs and GPUs powered and heterogeneous computing hardware. 

\begin{figure}[h!]
  \sfr
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6224}
  \caption[NVIDIA Jetson Nano heterogeneous computing hardware]{NVIDIA Jetson Nano heterogeneous computing hardware that we model the computations energy on. The hardware in the image includes the Jetson Developer Kit board that the Nano heterogeneous board is mounted on and has a total size of 100x80 millimeters and a weight of approx. 140 grams.}  
  \label{fig:nano}\findex{NVIDIA Jetson!Nano}
  \efr
\end{figure}
\begin{figure}[h!]   
  \sfr
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6220}
  \caption[NVIDIA Jetson TX2 heterogeneous computing hardware]{NVIDIA Jetson TX2 heterogeneous computing hardware mounted on a Jetson Developer Kit\findex{NVIDIA Jetson!Developer Kit} board as Nano in \fref{fig:nano}{Figure} with a total size of 170x170 millimeters and a weight of approx. 512 grams.}   
  \label{fig:tx2}\findex{NVIDIA Jetson!TX2}
  \efr
\end{figure}
\begin{figure}[h!]
  \sfr
  \centering
  \includegraphics[width=.7\textwidth]{pictures/_DSC6222}
  \caption[ODROID XU3 heterogeneous computing hardware]{ODROID XU3 heterogeneous computing hardware with a total size of 94x70 millimeters and a weight of 70 grams.}
  \label{fig:odroid}\findex{ODROID XU3}
  \efr
\end{figure}

Our approach is based on our work~\citep{seewald2019coarse} on heterogeneous computing devices' energy modeling and generic, modeling virtually a wide range of heterogeneous computing hardware energy consumption in real use-cases with little users effort. We use statistical methods to derive a regression-based model segmented into two layers. In the first, the measurement layer\findex{measurement layer}, we map the time to the power, and in the second, the predictive layer\findex{predictive layer}, we map the computations configuration $c_{i}^\sigma(t)$ to the power. To generate a model, our approach inputs a user-defined configuration file, which simply specifies the computations along with the computation parameter constraint sets $\mathcal{S}_{i,k}$ in \fref{def:stage}{Definition}, per each computation $k\in[\sigma]_{>0}$ and stage $i\in[l]_{>0}$ (or $[n]_{>0}$ if the computations are specified along the primitive paths and reiterated when the aerial robot reaches $\mathbf{p}_{\Gamma_n}$ with a shift $\mathbf{d}$ in \fref{fig:state-machine}{Figure}). From the configuration, an automated modeling tool termed \powprof{} measures the energy consumption of a discrete set of configurations $c_{i,\rho+j}\in\mathcal{S}_{i,j}$, per each computation parameter $j\in[\sigma]_{>0}$ and derives the measurement layer. The tool allows merging then a set of measurement layers into a predictive layer via linear regression.
As heterogeneous computing hardware, we use different devices, such as NVIDIA Jetson Nano\findex{NVIDIA Jetson!Nano}, TX2\findex{NVIDIA Jetson!TX2}, and TK1\findex{NVIDIA Jetson!TK1} in \fref{fig:nano}{Figures}\fref{fig:tx2}{--\hspace*{-.8ex}} and \fref{fig:tk1}{} and ODROID XU3\findex{ODROID XU3} in \fref{fig:odroid}{Figure}. 
\begin{table}[h!]
  \sfr
  \footnotesize\fontfamily{phv}\selectfont
    \begin{tabularx}{\textwidth}{|X|*{4}{l|}}\hline
      {\hspace*{-.8ex}Hardware} & \hspace*{-.8ex}{\scriptsize CPU} & \hspace*{-.8ex}{\scriptsize GPU} & Memory & \hspace*{-.8ex}{\scriptsize Sensor}\hspace*{-.8ex} \\
      \hline
      \hspace*{-.8ex}NVIDIA~Jetson~Nano\hspace*{-.8ex} & \hspace*{-.8ex}{\scriptsize -A57} & \hspace*{-.8ex}{\scriptsize NVIDIA Maxwell}\hspace*{-.8ex} & 4 GB LPDDR4 RAM & \cmark\\
      \hspace*{-.8ex}NVIDIA~Jetson~TX2 & \hspace*{-.8ex}{\scriptsize -A57} & \hspace*{-.8ex}{\scriptsize NVIDIA Pascal} & 8 GB LPDDR4 RAM, 32 GB NV\hspace*{-.8ex} & \cmark\\
      \hspace*{-.8ex}NVIDIA~Jetson~TK1 & \hspace*{-.8ex}{\scriptsize -A15} & \hspace*{-.8ex}{\scriptsize NVIDIA Kepler} & 1 GB DDR3L RAM, 16 GB NV & \xmark\\
      \hspace*{-.8ex}ODROID~XU3 & \hspace*{-.8ex}{\scriptsize -A15, -A7}\hspace*{-.8ex} & \hspace*{-.8ex}{\scriptsize MALI} & 2 GB LPDDR3 RAM & \cmark
      \\\hline
    \end{tabularx}
    \footnotesize
    \caption[Mobile computing hardware explicitly analyzed in this work]{Mobile computing hardware explicitly analyzed in this work. All the CPUs are ARM Cortex. The majority of the embedded boards provide random access memory (RAM)\findex{memory!random access}, and some a non-volatile (NV) memory\findex{memory!non-volatile}. All the boards have energy measuring capabilities except NVIDIA Jetson TK1.}
    \label{tab:hws}
    \efr
\end{table}
We summarize the computing hardware that we explicitly consider in this work in \fref{tab:hws}{Table}. These devices are commonly employed in robotics literature to power complex computations. For instance, Jetson TX2 has been employed in path planning\findex{path planning}~\citep{dharmadhikari2020motion,ryou2018applying}, simultaneous localization and mapping\findex{simultaneous localization and mapping} (\Gls{acr:slam})~\citep{aldegheri2019data}, and object detection\findex{object detection} via convolutional neural networks\findex{convolutional neural network} (\Gls{acr:cnn}s)~\citep{william2019aerial}. Jetson Nano in SLAM and CNNs~\citep{peng2019evaluating,wang2020yolo,alexey2021autonomous}, and ODROID XU3~\citep{bhat2019power,papachristos2015aerial,giusti2016machine} and Jetson TK1~\citep{gong2016low,holper2017cyber} in similar applications. Although we report some in this paragraph, heterogeneous embedded boards power computations in many other mobile robots use-cases, thus possibly broadening the applicability of our work, which we further in \fref{cp:conc}{Chapter}. In the remainder of this section, we detail our energy model for the heterogeneous computing hardware.

\subsection{Measurement layer}\findex{measurement layer}
\label{sec:measurement-layer}

The measurement layer is the basic building block of the computations energy model: one or more measurement layers form the predictive layer--the model output--which we describe in \fref{sec:predictive-layer}{Section}. For a specific computations parameters configuration $c_i^\sigma(t)$, the measurement layer maps the time $t\in[t_0,t_f]:=\mathcal{T}\subset\mathbb{R}_{>0}$ (the final and initial time instants $t_0,t_f$ are given) to the power measured in watts\findex{watts}, the energy measured in joules\findex{joules} (watts per unit of time), and the battery state of charge (\Gls{acr:soc})\findex{state of charge} expressed in percentages. The measurement layer thus provides a primitive model for $c_i^\sigma$ of power, energy, and SoC over a given time interval. The derivation of the layer is automated with \powprof{}, the modeling tool that we describe in detail in \fref{sec:powprof}{Section}, which outputs the layer after executing $c_i^\sigma$ on $\mathcal{T}$. Additionally, the model (and the \powprof{} tool) can output the triplet of metrics from the measurement layer per each energy sensor: some computing hardware that we analyze indeed provide different sensors for different computing elements, i.e., NVIDIA Jetson TX2, Nano, and ODROID XU3 boards all provide energy-sensing capabilities for CPU, GPU, overall, and/or memory.

Let us define the measurement layer formally, assuming there are one or more energy sensors or other energy measuring devices (these include, e.g., internal power resistors or shunt resistors, amperometers, and multimeters) in \fref{def:measur-layer}{Definition}.

\begin{highlight}
  \begin{defn}[Measurement layer]\label{def:measur-layer}
    Given a specific energy measuring device, computations parameters configuration $c_i^\sigma(t)$, and an initial and final time instant $t_0,t_f$ such that $t\in\mathcal{T}:=[t_0,t_f]$, the \textit{measurement layer} is the function
    $\mathbf{g}:\mathbb{Z}_{>0}\times\mathbb{Z}^\sigma\times\mathcal{T}\rightarrow\mathbb{R}^3$.
    It returns the power in watts, energy in joules, and SoC in percentages of an energy measuring device, a configuration of computations parameters, and time interval.
  \end{defn}
\end{highlight}

The measurement layer physically samples the computing hardware for $\mathcal{T}$ and returns the metrics, but sampling-to-completion is also possible, where a configuration runs up until it terminates rather than for a given interval. In the latter eventuality, $\mathcal{T}$ is ${\emptyset}$.

As an instance of the measurement layer, let us return briefly to the precision agriculture example in \fref{sec:flight-plan}{Section}, which describes the agricultural use-case (the aerial robot detects ground hazards and communicates the detections to a ground station). The computations parameters in \fref{sec:computation-wise}{Section} are $c_{i,2}$, the frames per second (\Gls{acr:fps})\findex{frames per second} rate, and $c_{i,3}$, encryption or no encryption of the robot---ground station data link. The configurations $c_{i,2}(t)\in\mathcal{S}_{i,2}$, $c_{i,3}(t)\in\mathcal{S}_{i,3}$ have any value within the constraint sets in \frefeqM{eq:encr-comp-const}{eq:cnn-comp-const}. The constraint sets are the same in each stage  $i$ in the plan $\Gamma$ except for the circles where the aerial robot travels the turns out of the boundaries, and the detections are inhibited. To build the measurement layer, we can discretize the configurations with a given $\delta_1,\delta_2$ for parameters $c_{i,2}$ and $c_{i,3}$. The measurement layer is then built by sampling the power for $\mathcal{T}$, one for all the possible configurations
\begin{equation}\label{eq:meas-layer-lin-sampl}
  c_i^\sigma:=\{c_{i,2},c_{i,3}\mid\forall j,k\in\mathbb{Z},\, \underline{c}_{i,2}+j\delta_1\in\mathcal{S}_{i,2},\underline{c}_{i,3}+k\delta_2\in\mathcal{S}_{i,3}\}.
\end{equation}

A value can be, e.g, $\delta_1=\delta_2=2$, so that there are ten configurations and consequently ten measurement layers. The \powprof{} tool automatically builds the layers, storing the results in comma-separated values (\Gls{acr:csv})\findex{comma-separated values} files (we see further the tool in \fref{sec:powprof}{Section}).
\frefeq{eq:meas-layer-lin-sampl} provides a way to sample the search space linearly, but other sampling strategies are equally possible, such as exponential sampling
\begin{equation}\label{eq:meas-layer-exp-sampl}
  c_{i}^\sigma:=\{c_{i,2},c_{i,3}\mid\forall j,k\in\mathbb{Z},\, {\delta_1}^j\in\mathcal{S}_{i,2},{\delta_2}^k\in\mathcal{S}_{i,3}\},
\end{equation}
where $\delta_1,\delta_2$ are now bases, or random sampling with the condition merely $c_{i,j}\in\mathbb{Z}_{>0}$. Currently, the \powprof{} tool supports automated linear and exponential sampling and complex sampling formed by different sampling strategies~\citep{seewald2019coarse}, e.g.,
\begin{equation}
  c_{i}^\sigma:=\{\{c_{i,2}\mid\forall k\in\mathbb{Z},\, \underline{c}_{i,2}+k\delta_1\in\mathcal{S}_{i,2}\},\{c_{i,3}\mid\forall k\in\mathbb{Z},{\delta_2}^k\in\mathcal{S}_{i,3}\}\}.
\end{equation}
Parameter ranges ($\mathcal{S}_{i,2},\mathcal{S}_{i,3}$) choice is dictated by the range at which the computations run at runtime, whereas $\delta$s choice is made so that the modeling terminates in a reasonable amount of time~\citep{seewald2019coarse}.

With the measurement layer described in this section, we know the power and other energy metrics of the (measured) configurations. However, we want to predict the energy consumption for any configuration of parameters in the constraint sets (and not only the sampled ones). We address this latter requirement in the next section, merging the measurement layers with linear regression.

\subsection{Predictive layer}\findex{predictive layer}
\label{sec:predictive-layer}

The predictive layer describes coarse-grained metrics, such as the power over FPS rate, mapping them to the metrics from the measurement layer, thus providing energy data for each configuration of parameters (or for each scheduling policy). To this end, it uses the set of measurement layers, building a two-by-two linear regression between consecutive layers. In the precision agriculture example with ten measurement layers, the predictive layer consists of regression between data points $\{c_{i,2},c_{i,3}\}$ for all the possible computations parameters (recall that a measurement later corresponds to a sampled computations configuration), opposed to the sampled ones in \fref{sec:measurement-layer}{Section}. \fref{def:comp-ener}{Definition} details the resulting model.

\begin{highlight}
  \begin{defn}[Predictive layer]\label{def:comp-ener}
    Given a specific energy measuring device and computations parameters configuration $c_i^\sigma(t)$ \textit{predictive layer} is the function $g:\mathbb{Z}_{\geq 0}\times\mathbb{Z}^\sigma\rightarrow\mathbb{R}^3$. It returns the power in watts, energy in joules, and SoC in percentages of any configuration of parameters within the constraint sets.
  \end{defn}
\end{highlight}

Analogously to the measurement layer, there can be various energy measuring devices, resulting in multiple triples of energy, power, and SoC, one per device. The predictive layer returns the same metrics of the measurement layer in \fref{def:measur-layer}{Definition}, without physically sampling the computing hardware but using the stored measurement layers. Indeed due to a potentially large search space in computational energy modeling, it is critical to infer the energy properties of the entire search space from a subset of all the possible samples~\citep{lee2006statistically,lee2006accurate,bailey2014adaptive}. The linear regression to infer such properties utilizes a method that we term the approximation method\findex{approximation method}~\citep{seewald2019coarse}. It builds a linear regression between two adjacent data points rather than merely for all the data points. Indeed we do not assume an apriori knowledge of the computations energy evolution with explicit models for all the data points such as linear or exponential, but rather model the energy linearly on tuples of data points~\citep{seewald2019coarse}.

Given an (unsampled) configuration $c_i^\sigma$, the predictive layer is approximated with
\begin{equation}
  g(c_i^\sigma)=(\mathbf{g}(\lceil c_i^\sigma\rceil,\mathcal{T}_1)-\mathbf{g}(\lfloor c_i^\sigma\rfloor),\mathcal{T}_2)(c_i^\sigma-\lfloor c_i^\sigma\rfloor)/(\lceil c_i^\sigma\rceil-\lfloor c_i^\sigma\rfloor)+\mathbf{g}(\lfloor c_i^\sigma\rfloor,\mathcal{T}_2),
\end{equation}
where $\lceil c_i^\sigma\rceil,\lfloor c_i^\sigma\rfloor$ are the two adjacent measurement layers of the computations configuration $c_i^\sigma$ (e.g., if we use $\delta_1=2$ in \frefeq{eq:meas-layer-lin-sampl}, $c_i^\sigma$ with just the parameter $c_{i,2}$ has $\lfloor c_i^\sigma\rfloor$ equal to two and $\lceil c_i^\sigma\rceil$ to four), and $\mathcal{T}_1,\mathcal{T}_2$ are the two time intervals in the measurement layer for configurations $\lfloor c_i^\sigma\rfloor,\lceil c_i^\sigma\rceil$ respectively.
We illustrate the principle in \fref{}{Figure}. % todo the figure

\subsection{The {\tt powprofiler} tool}\findex{powprofiler@\texttt{powprofiler}}
\label{sec:powprof}

The \powprof{}\footnote{The tool can be retrieved from \url{https://github.com/adamseew/powprofiler}} tool is an automated profiling and modeling utility that generates the measurement layers for a discrete set of possible computations configurations (automated profiling) and merges these layers later, providing the predictive layer (modeling). We proposed an early version of the tool earlier in our work~\citep{teamplayd43,seewald2019coarse}, which we extended later to support per-component energy modeling in a dataflow computational network~\citep{seewald2019component}, and integrated~\citep{zamanakos2020energy} with Robot Operating System (ROS) middleware~\citep{quigley2009ros}\findex{Robot Operating System}. The tool is written in C++\findex{C++} and distributed under an MIT license\findex{MIT license}. It supports all the computing hardware explicitly mentioned in this work, i.e., NVIDIA Jetson TX2, Nano, and TK1 and ODROID XU3 in \fref{tab:hws}{Table}. It is predisposed further for extensibility supporting possibly any Linux-based\findex{Linux} computing hardware that provides energy measuring devices or that alternatively provide a mechanism to measure the energy with an external device.

The tool uses an object-oriented programming\findex{object-oriented programming} approach~\citep{stroustrup1988what,wegner1990concepts}, where each computing hardware has its own class that inherits from the class {\small\tt sampler}\findex{class!sampler@\texttt{sampler}} the functions {\small\tt get\_sample}\findex{function!getsample@\texttt{get\_sample}} and {\small\tt dryrun}\findex{function!dryrun@\texttt{dryrun}}. The former function returns a power measurement from all the measuring devices on specific computing hardware (power for the measurement layer in \fref{sec:measurement-layer}{Section} for, e.g., CPU, GPU, overall, etc\dots), and the latter simply attempts to read from the measuring devices returning a boolean value indicating if the attempt was successful. The tool contains classes {\small\tt sampler\_tx2}\findex{class!samplertx2@\texttt{sampler\_tx2}}, {\small\tt sampler\_nano}\findex{class!samplernano@\texttt{sampler\_nano}}, and {\small\tt sampler\_odroid}\findex{class!samplerodroid@\texttt{sampler\_odroid}} already implementing the necessary utilities to store the models from the computing hardware that we explicitly analyze.

The function {\small\tt get\_sample} further relies on a specific data type, which we term {\small\tt vectorn}\findex{data type!vectorn@\texttt{vectorn}}. Each value in {\small\tt vectorn} has its flag, indicating the metric and the measuring device. For instance {\small\tt power\_cpu}, {\small\tt soc\_gpu} are two flags indicating that the metric is for the power and the measuring device is of
the CPU and the SoC of the GPU respectively. The enumeration {\small\tt vectorn\_flags} contains all the flags. The tool stores a set of {\small\tt vectorn}s sampled at discrete intervals (\powprof{} is highly personalizable, allowing to change the frequency via the configuration specification in \fref{sec:conf-spec}{Section}) in another structure termed {\small\tt pathn}\findex{data type!pathn@\texttt{pathn}}. Each {\small\tt pathn} corresponds to a measurement layer in \fref{sec:measurement-layer}{Section}. The tool further provides mechanisms, such as the overload of the constructor, to automatically load the layers from a previously stored CSV file. Internally the tool stores {\small\tt pathn}s (the measurement layers) in a wrapper, {\small\tt model\_1layer}\findex{class!model1layer@\texttt{model\_1layer}}, which contains information such as the parameters configuration and the set $\mathcal{T}$; {\small\tt model\_2layer}\findex{class!model2layer@\texttt{model\_2layer}} is then another internal structure that returns the predictive layer in \fref{sec:predictive-layer}{Section}. 
\begin{figure}[h!]
  \sfr
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6228}
  \caption[NVIDIA Jetson TK1 heterogeneous computing hardware]{NVIDIA Jetson TK1 heterogeneous computing hardware mounted on a Toradex Ixora\findex{Toradex Ixora} carrier board with a total size of 125x95 millimeters and a weight of approx. 160 grams.} 
  \label{fig:tk1}\findex{NVIDIA Jetson!TK1}
  \efr
\end{figure}
In this setting, NVIDIA Jetson TK1 computing hardware does not include any energy measuring device. \powprof{} allows an external device in the sense that it can import data in the model directly through the overload of the constructor into a measurement layer (and therefore a set of measurement layers into a predictive layer). An early instance of our work~\citep{seewald2019hlpgpu} consisted of three hardware units for the purpose of this latter energy modeling of the TK1 computing hardware, similarly to another study in the literature~\citep{calore2015energy}. The main hardware unit in the early instance was the computing hardware itself, whereas the others were a multimeter and a workstation that interprets the data from the multimeter for subsequent processing by the tool~\citep{seewald2019coarse}.

The tool further interoperates with ROS middleware, generating a measurement layer for configurations of computations implemented in the middleware. It can be imported in an existing project as a library; in C/C++ by simply adding the preprocessor's directive\findex{preprocessor} {\small\tt \#include} with {\small\tt <powprof/async.h>}. In a setting where an energy-expensive ROS node is a computation (we implement both the CNN detection and encryption in \fref{sec:computation-wise}{Section} as ROS nodes), the user simply instances {\small\tt model\_1layer} with a specific computations configuration and calls function {\small\tt start}\findex{function!start@\texttt{start}} to start profiling, and {\small\tt stop}\findex{function!stop@\texttt{stop}} to stop. The latter then returns a measurement layer. The modeling can, in this fashion, happen online by running different computations configurations and generating an appropriate computations energy model corresponding to a realistic run-time computations load.

Alternatively to ROS middleware, the tool runs from a configuration specification, detailing each computation, the constraints sets, and the $\delta$s, along with some other, model-specific details. We discuss such configuration specification in the next section.

\subsection{Configuration specification}
\label{sec:conf-spec}

The configuration specification is simply a way to communicate the plan $\Gamma$ to the \powprof{} tool, along with some other model-specific details. To run \powprof{} with a configuration specification, the user invokes the command {\small\tt powprofile}, followed by the path of the configuration. If, for instance, the configuration specification is stored in {\small\tt config.cfg} in the current directory, the user invokes {\small\tt powprofile config.cfg}. The tool then parses the configuration specification to reconstruct the computations configurations and the constraints sets, to  automatically generate measurement layers and consequently provide a predictive layer. The configuration specification starts with the line {\small\tt [settings]} that indicates to \powprof{} all the following lines are a configuration specification. In the lines that follow, it contains a set of key-value properties delimited by an equal char. The property {\small\tt frequency}\findex{frequency} indicates the frequency measured hertz the tools samples at (e.g., with ten seconds, the property is set as {\small\tt frequency=10}). The property {\small\tt h} is the integration step\findex{integration step} the battery model\findex{battery model} integrates at (we discuss further the battery model in \fref{sec:battery-model}{Section}). The property {\small\tt directory} indicates the path where the models are stored. Additionally, the tool allows an arbitrary number of commands and white spaces, and the parser does not require a specific indentation. Any data followed by char {\small\tt \#} are ignored up to the next line, allowing to write eventual comments.

The following set of lines specifies the configuration $c_i^\sigma$ for each computation parameter $c_{i,\rho+1},c_{i,\rho+2},\dots,c_{i,\rho+\sigma}$, starting with the line {\small\tt [components]}, followed by {\small\tt [component.computation]} where {\small\tt computation} is a string uniquely identifying each computation (there cannot be two computations with the same string, but the name is arbitrary). Per each computation, the configuration file then contains a set of key-values properties. The property {\small\tt src} indicates the executable source of the computation. If \powprof{} runs with a configuration specification rather than a library, we assume the source accepts as arguments the configurations, e.g., $c_{i,\rho+1},\dots$ along with other eventual arguments. The following properties then specify these arguments, ordered as they appear in the configuration specification. The property {\small\tt range} indicates that the argument is a computation parameter. Let us assume the parameter is $c_{i,\rho+1}$. If it is sampled linearly as in \frefeq{eq:meas-layer-lin-sampl}, the value contains $\underline{c}_{i,\rho+1}$, $\overline{c}_{i,\rho+1}$, and $\delta$ delimited by commas, where $\delta$ is the step to sample $c_{i,\rho+1}$ in a reasonable amount of time in \frefeq{eq:meas-layer-lin-sampl}. If it is sampled exponentially as in \frefeq{eq:meas-layer-exp-sampl}, the value contains the same data as before, but for $\delta$ that is expressed {\small\tt pow(}$\delta${\small\tt )} and $\delta$ is the base.
Additional properties are then: {\small\tt fixed} that indicates another eventual argument the computation might have (that is not a computation parameter), and {\small\tt runtime} the value $t_f-t_0$. If {\small\tt runtime} is not specified, the tool assumes $\mathcal{T}=\emptyset$.


%%%%%%%%%%%%%%%%%%%%%%%
\section{Battery Model}
\label{sec:battery-model}

The battery model is an abstraction that predicts how the draining power at future time instants--due to varying computations and motion load--affects the SoC of an aerial robot's battery. Generally, battery SoC is the most important measure for  battery management, yet, it cannot be directly measured~\citep{xia2015state}. There are numerous approaches to formulate its model, and we discuss the most common ones in the literature in \fref{sec:soa-ene-bat}{Section}, including physical, hybrid, empirical, mixed, and abstract models~\citep{rao2003battery}. In this section, we then use the past literature to derive a battery model of an aerial robot's battery. The model that we derive is an abstract model. Such models do not require detailed information about, e.g., battery chemistry; nonetheless, they accurately predict future SoC at a relatively low computational complexity compared with complex and exhaustive models, such as physical models~\citep{rao2003battery}.

We detail the equivalent electrical circuit in \fref{sec:batmod-circuit}{Section}; it is the building block of our battery model. We then provide some further information on the implementation of the equivalent electrical circuit in the \powprof{} tool in \fref{sec:batmod-circuit}{Section}. We will use the battery model in \fref{sec:output-mpc}{Section} to define the output constraint in \fref{def:const}{Definition}

\subsection{Equivalent electrical circuit}
\label{sec:batmod-circuit}

Equivalent electrical circuits are abstract models, frequently referred to as battery equivalent circuit models (\Gls{acr:ecm}s)\findex{equivalent circuit models}. They are common in the literature for battery SoC estimation~\citep{zhang2018online} and treated in numerous studies relative to Li-ion\findex{Lithium ion batteries} rechargeable battery cells~\citep{hinz2019comparison,hasan2018exogenous}. Although there are more accurate models to predict SoC for these batteries from a given power and time trajectories--namely physical or electrochemical models~\citep{rao2003battery}--for mobile robots and more in general for resource-constrained systems it is usually required to balance the models' complexity and the accuracy~\citep{rao2003battery,hasan2018exogenous}. In these constrained systems, ECMs have relatively good modeling accuracy and easy implementation~\citep{zhang2018online,zhang2012estimation,zhang2009battery,saeed2019electrical,hasan2018exogenous}. ECMs use different constructs to model the battery SoC from several parameters. These constructs include RC (resistor-capacitor)\findex{resistor}\findex{capacitor} circuits for dynamic loads\findex{dynamic loads}, resistors for internal resistances\findex{resistance}, and other components~\citep{hamza2017forecasting}. Their complexity depends on the level of detail required and the parameters involved in modeling. The parameters are usually estimated with empirical data~\citep{zhang2014battery}.
For what concerns the specific battery chemistries to be modeled, we focus on Li-ion batteries. These batteries have broad applications involving electric vehicles, mobile, and aerial robots~\citep{shi2006application,xia2015state,hasan2018exogenous,zhang2014battery}, due to their characteristics such as low self-discharge rate\findex{self-discharge rate}, absence of memory effect\findex{memory effect}, and high power and energy density\findex{power density}\findex{energy density}~\citep{zhang2014battery}.

\begin{figure}[h!]
  \sfr
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/circuit-rint.tikz}
  \caption[Equivalent electrical circuit for battery modeling with an internal resistance]{Equivalent electrical circuit for battery modeling with one resistor, representing the internal battery resistance.}
  \label{fig:rint}
  \efr
\end{figure}
Here, we propose a simplistic battery model to model a Li-ion battery of an aerial robot in flight, focusing on lesser complexity rather than accuracy. The battery SoC changes--when computations and motion generate a current to be drawn from the battery--according to the equation~\citep{zhang2018online,hasan2018exogenous}
\begin{equation}\label{eq:socevol}
  \dot{b}(y(t))=-I(y(t))/Q_c,
\end{equation}
where $Q_c\in\mathbb{R}$ is the battery constant nominal capacity measured in amperes per hour, $I(y(t))\in\mathbb{R}$ is the internal current that we derive later in this section, and $y(t)\in\mathbb{R}_{\geq 0}$ is a power drawn, i.e., the power needed for the computations and the motion. 
If we use the computations energy model in \fref{sec:comp-ener-model}{Section}, it is the power metric in \fref{def:comp-ener}{Definition} or the value of the measurement layer in \fref{def:measur-layer}{Definition} for each time step.

We propose a simplistic ECM with an internal resistance from the literature~\citep{mousavi2014various,hinz2019comparison,he2011evaluation} in \fref{fig:rint}{Figure}, sometimes termed the ``Rint'' model~\citep{hinz2019comparison,he2011evaluation}. The circuit models the battery simply as a perfect voltage source connected with a resistor $R_r\in\mathbb{R}$ measured in ohms, representing the internal battery resistance. The voltage $V\in\mathbb{R}$ measured in volts is the internal battery voltage, which depends on SoC~\citep{hasan2018exogenous} and can be retrieved from a battery data sheet~\citep{hinz2019comparison}, and $I$ is the current running through the circuit that depends on the power requirements of the load.

The voltage on the extremes of the ECM then respects 
\begin{equation}\label{eq:tocomb1}
  V_e=V-R_rI,
\end{equation}
where $V_e\in\mathbb{R}$ is the external battery voltage at the extremes of the circuit in \fref{fig:rint}{Figure}. If we assume that the voltage needed by the computations and motion is stable, let's call it $V_s\in\mathbb{R}$ and is measured in volts, and that the current required by the load (computations and motion) is $I_l$, we can write
\begin{equation}\label{eq:tocomb2}
  V_sI_l=V_eI,
\end{equation}
using simply Kirchhoff's circuit laws (the power into the load should exactly match the power out). Combining the \frefeqM{eq:tocomb1}{eq:tocomb2}, we obtain the quadratic expression $R_rI^2-VI+V_sI_l=0$, which leads to
\begin{equation}\label{eq:internal_curr}
  I(y(t))=\left(V-\sqrt{V^2-4R_ry(t)}\right)/(2R_r),
\end{equation}
where $I_l:=y(t)/V_s$ is the current of the load depending on the computations and motion power $y(t)$ at a given time instant $t$ in \frefeq{eq:socevol}. Furthermore, we take the negative solution of the quadratic expression: when $I_l$ is zero, $I$ should also be zero. With the internal current in \frefeq{eq:internal_curr} combined with the battery SoC in \frefeq{eq:socevol}, we can model how the computations and motion power trajectory $y(t)$ on $t\in\mathcal{T}:=[t_0,t_f]$ for given initial and final time instants ($t_0,t_f$ respectively) affects the battery. In one of our earlier intuitions~\citep{seewald2019coarse}, we expected a constant energy load to result in a better overall SoC compared to, e.g., a spiked one, even if the two have the same overall energy. The model above confirms this intuition. In \fref{fig:}{Figure}, we show the evolution of $I$ in \frefeq{eq:internal_curr} for a given linear load $I_l$ from zero to approximately one-third, assuming $V=V_s=R_r$ all one. The curve in the plot bends upwards for the plotted range: a line between two points will always be above the curve; it implies that a constant load is to be preferred compared to a load that repeatedly changes from high to low.

There are also more complex ECMs in the literature~\citep{hinz2019comparison,hasan2018exogenous}, which add additional elements to, e.g., account for the changes in the load current. One such ECM is the Thevenin model and the Thevenin-based model~\citep{chen2006accurate,hasan2018exogenous,hinz2019comparison,mousavi2014various,zhang2018online,salameh1992mathematical}\findex{Thevenin model}. 
\begin{figure}[h!]
  \sfr
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/circuit-thevenin.tikz}
  \caption[Thevenin-based equivalent electrical circuit for battery modeling]{Thevenin-based equivalent electrical circuit for battery modeling with one resistor and two RC internal elements. The two elements add some complexity, making the model able to account for changes in the load current.}
  \label{fig:thevenin}
  \efr
\end{figure}
Sometimes termed the dual-polarization model~\citep{he2011evaluation}, we illustrate the ECM in \fref{fig:thevenin}{Figure}. It models further details, such as the short-term transient behavior with the first RC element ($R_1,C_1$) and the long-term transient behavior with the second RC element ($R_2,C_2$)~\citep{hinz2019comparison}. It is particularly suitable to model the polarization characteristic of Li-ion battery cells~\citep{he2011evaluation}.

\subsection{Battery model in the {\tt powprofiler} tool}
\label{sec:batmod-circuit}

The \powprof{} tool allows automated battery modeling and directly derives battery SoC for each measurement layer in \fref{sec:measurement-layer}{Section}. Indeed in \fref{def:measur-layer}{Definition}, the function $\mathbf{g}$ returns a triplet of values, including the SoC. For the predictive layer in \fref{def:comp-ener}{Definition} in \fref{sec:predictive-layer}{Section}, the tool similarly outputs the SoC for a given configuration of parameters and energy sensor or other energy measuring device. To this end, it implements the simplistic equivalent electrical circuit in \fref{fig:rint}{Figure} from the literature~\citep{mousavi2014various,hinz2019comparison,he2011evaluation}, with the class {\small\tt soc\_1resistor}, where the constructor accepts in input the parameters $I_l,V,R_r,V_s$ and $Q_c$ that we discussed in \fref{sec:batmod-circuit}{Section}. The current load $I_l$ is expressed via the data type {\small\tt pathn} in \fref{sec:powprof}{Section}. One can implement a similar battery model, e.g., the Thevenin-based ECM in \fref{fig:thevenin}{Figure}, by simply inheriting from class {\small\tt first\_derivative} the function {\small\tt get\_value}. It returns the modeled battery SoC at the next time instant from an independent variable, i.e., time, and a dependent variable represented via the data type {\small\tt soc\_1resistor} in \fref{sec:powprof}{Section}.

Internally, the tool implements a numerical simulator based on the Runge-Kutta methods\findex{Runge-Kutta methods} for numerical integration\findex{numerical integration} in \fref{sec:rk4}{Section}. One can then personalize the size of the integration step $h\in\mathbb{R}_{>0}$ via the property {\small\tt h} in the configuration specification in \fref{sec:conf-spec}{Section} (a typical practical value of such property is, e.g., one hundredth). The tool first derives a model for the power and energy and later numerically simulates the battery model via the equivalent electrical circuit in \fref{fig:rint}{Figure} adjoining the battery SoC.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy Model of the Motion}
\label{sec:mot-ener-model}

In this section, we implement a model for the motion of aerial robots in coverage path planning (\Gls{acr:cpp})\findex{coverage path planning}. We first derive a differential periodic energy model and provide a formal proof in \fref{sec:deriv}{Section}. This model server to model the motion. We enhance the model with the path and computations parameters in \fref{sec:nom-cont}{Section}, to predict the energy consumption of a given configuration of parameters. We explain how we convert the parameters into actual energy consumption in \fref{sec:merging}{Section}, and discuss the model's behavior for aperiodic power evolutions in \fref{sec:non-perio}{Section}.

Let us suppose the aerial robot is operating in an autonomous scenario, planning the coverage and scheduling some computations for detections and encryption in \fref{sec:flight-plan}{Section}. 
\begin{figure}[h!]
  \sfr
  \centering
  \footnotesize
  \fontfamily{phv}\selectfont
  \input{figures/energy_1.tikz}
  \caption[Power evolution data of an aerial robot in coverage planning]{Empirical energy data of the aerial robot in \fref{fig:plot2}{Figure} in coverage planning. The data shows that the energy signal is periodic over time as the fixed-wing aerial robot reiterates a set of paths.}
  \label{fig:energy-1}
  \efr
\end{figure}
It expectedly iterates some paths (the primitive paths) for CPP and schedules the computations periodically, as we outlined in \fref{sec:outline}{Section}, and further backed with the concept of primitive paths in \fref{def:primitive}{Definition}. Since the paths and tasks are periodically iterated over time, we expect the energy to evolve similarly. This assumption is further supported by our previous contribution on the topic~\citep{seewald2020mechanical}, showing that a Fourier series of a given order can model the energy of the aerial robot (in the contribution, we used the order three). We will ease the assumption of the periodic evolution in practice to periodic with disturbance or aperiodic evolutions in \fref{sec:non-perio}{Section}. 
\begin{figure}[h!]
  \sfr
  \centering
  \footnotesize
  \fontfamily{phv}\selectfont
  \input{figures/spectrum_1.tikz}
  \caption[Power evolution frequency spectrum of an aerial robot in coverage planning]{Frequency spectrum of the empirical energy data in \fref{fig:energy-1}{Figure} where the aerial robot does the coverage planning.}
  \label{fig:spectrum-1}
  \efr
\end{figure}
We motivate the choice of a periodic energy model further with some empirical energy data of the Opterra fixed-wing aerial robot\findex{Opterra fixed-wing aerial robot} flying the agricultural scenario in \fref{fig:energy-1}{Figures}\fref{fig:spectrum-1}{--\hspace*{-.8ex}}. The data shows the robot's energy along its frequency spectrum. The latter is centered at zero frequency, and peaks at four hundred kilo decibels. The peak visually depicts the shift on the power axis in  \fref{fig:energy-1}{Figure} (and further backs the choice of the Fourier series of third order in our earlier work, illustrating that the power evolution needs approximately three frequencies to be modeled). To obtain the spectrum in frequency space, we computed the Fourier transform.

\subsection{Derivation of the differential periodic model}
\label{sec:deriv}

In the remainder of this section, we refer to the power (or instantaneous energy consumption) evolution simply as the energy signal. We model the signal using energy coefficients vector $\mathbf{q}\in\mathbb{R}^m$ that characterize the energy signal. We derive the coefficients from Fourier analysis: the size of the vector $m$ is then related to the order of the series. We prove a relation between the energy signal and the energy coefficients in \fref{lem:eqv}{Lemma}.
  
First, let us consider a periodic energy signal of period $T\in\mathbb{R}_{> 0}$, and a Fourier series of an arbitrary order $r\in\mathbb{Z}_{\geq 0}$ for the purpose of modeling the signal
\begin{equation}\label{eq:fourier}
  h(t)=a_0/T+(2/T)\sum_{j=1}^{r}{\left(a_j\cos{\omega jt}+b_j\sin{\omega jt}\right)},
\end{equation}
where $h:\mathbb{R}_{\geq 0}\rightarrow\mathbb{R}$ maps time to the power, $\omega:=2\pi/T$ is the angular frequency, and $a_0,a_j,b_j\in\mathbb{R}$ the Fourier series coefficients $\forall j\in[r]_{>0}$.

The energy signal can be modeled by \frefeq{eq:fourier} and by the output of a linear model
\begin{subequations}\label{eq:state-perf}\begin{align}
  \dot{\mathbf{q}}(t)&=A\mathbf{q}(t)+B\mathbf{u}(t),\\
  y(t)&=C\mathbf{q}(t)\label{eq:state-perf-output},
\end{align}\end{subequations}
where $y(t)\in\mathbb{R}$ is the power at time instant $t$. We discuss matrices $A,C,$ and $B$ in \frefeq{eq:mat_A}, \frefeq{eq:mat_C}, and \frefeq{eq:mat_B} respectively (we discuss the nominal control $\mathbf{u}$ in \fref{sec:nom-cont}{Section}).

The state $\mathbf{q}(t)$ contains the energy coefficients
\begin{equation}\label{eq:state-details}
  \mathbf{q}(t):=\left[\begin{array}{cccccc}
    \alpha_0(t) & \alpha_1(t) & \beta_1(t) & \cdots & \alpha_r(t) & \beta_r(t)
  \end{array}\right]',\\
\end{equation}
where $\mathbf{q}(t)\in\mathbb{R}^m$ with $m=2r+1$. We will estimate the value of $\mathbf{q}$ with a state estimator in \fref{cp:est}{Chapter}.

The state transition matrix
\begin{equation}\label{eq:mat_A}
  A=\left[\begin{array}{ccccc}
    0            & 0^{1\times 2}& 0^{1\times 2}& \dots& 0^{1\times 2} \\
    0^{2\times 1}& A_1          & 0^{2\times 2}& \dots& 0^{2\times 2} \\
    0^{2\times 1}& 0^{2\times 2}& A_2          & \dots& 0^{2\times 2} \\
    \vdots       & \vdots       & \vdots       &\ddots& \vdots        \\
    0^{2\times 1}& 0^{2\times 2}& 0^{2\times 2}& \dots& A_r 
  \end{array}\right],
\end{equation}
where $A\in\mathbb{R}^{m\times m}$. In matrix $A$, the top left entry is zero, the diagonal entries are $A_1,\dots,A_r$, the remaining entries are zeros. Matrix $0^{i\times j}$ is a zero matrix of $i$ rows and $j$ columns. The submatrices $A_1,A_2,\dots,A_r$ or generically
\begin{equation}\label{eq:aj}
  A_j:=\begin{bmatrix}0 & \omega j \\ -\omega j & 0\end{bmatrix},
\end{equation}
$\forall j\in[r]_{>0}$. The output matrix
\begin{equation}\label{eq:mat_C}
  C=(1/T)\left[\begin{array}{cccccc}
    1 & 1 & 0 &\cdots & 1 & 0
  \end{array}\right],
\end{equation}
where $C\in\mathbb{R}^m$.

The linear model in \frefeq{eq:state-perf} allows us to include the control in the model of \frefeq{eq:fourier}, a concept that we build upon further in \fref{sec:nom-cont}{Section} where we merge the computations and motion energies. 
In the remainder, we formally prove an important concept in our work: we can use \frefeq{eq:state-perf} to model the energy signal of an aerial robot, assuming the robot iterates periodically a set of paths and computations to achieve a given space coverage. 
We already know that we can model a periodic energy signal with \frefeq{eq:fourier}, so we prove the equivalence and equality of the models in \frefeq{eq:fourier} and \frefeq{eq:state-perf}.

\begin{highlight}
\begin{lem}[Signal, output equality]\label{lem:eqv}Suppose control $\mathbf{u}$ is a zero vector, matrices $A,C$ are described by \frefeqM{eq:mat_A}{eq:mat_C}, and the initial guess at a given time instant $t_0\in\mathbb{R}_{>0}$ $\mathbf{q}(t_0)$ is 
  \begin{equation*}
  \mathbf{q}(t_0)=\begin{bmatrix}a_0 & a_1/2 & b_1/2 & \cdots & a_r/2 & b_r/2\end{bmatrix}'.
  \end{equation*} 
  Then, the signal $h$ in \frefeq{eq:fourier} is equal to the output $y$ in \frefeq{eq:state-perf}.
\end{lem}
\end{highlight}

\begin{proof}
The proof justifies the choice of the items of the matrices $A,C$ and the initial guess $\mathbf{q}(t_0)$ in \frefeqM{eq:state-details}{eq:mat_C}. We write these elements such that the coefficients of the series $a_0,\dots,b_r$ are the same as the coefficients of the state $\alpha_0,\dots,\beta_r$.

Let us re-write the Fourier series expression in \frefeq{eq:fourier} in its complex form with the well-known Euler's formula 
\begin{equation}
  e^{it}=\cos{t}+i\sin{t},
\end{equation} 
where $i$ is the imaginary unit. 
With $t=\omega jt$, we find the expression for 
\begin{subequations}\begin{align}
  \cos{\omega jt}&=(e^{i\omega jt}+e^{-i\omega jt})/2,\\  
  \sin{\omega jt}&=(e^{i\omega jt}-e^{-i\omega jt})/(2i),
\end{align}\end{subequations}
by substitution of $\sin{\omega jt}$ and $\cos{\omega jt}$ respectively. This leads to~\citep{kuo1967automatic}
\begin{equation}\begin{split}\label{eq:proof-complex}
  h(t)=a_0/T+&(1/T)\sum_{j=1}^{r}{e^{i\omega jt}(a_j-ib_j)}+\\&(1/T)\sum_{j=1}^{r}{e^{-i\omega jt}(a_j+ib_j)}.
 \end{split}\end{equation} 

The solution at time $t$ of the model in \frefeq{eq:state-perf} under the assumptions in the lemma (the control is a zero vector) can be expressed
\begin{equation}\label{eq:proof-sol}
  \mathbf{q}(t)=e^{At}\mathbf{q}_0.
\end{equation}

Both the solution in \frefeq{eq:proof-sol} and the system in \frefeq{eq:state-perf} are well-established expressions derived using standard textbooks~\citep{kuo1967automatic, ogata2002modern}. 
To solve the matrix exponential $e^{At}$ in \frefeq{eq:proof-sol}, we use the eigenvectors matrix decomposition method~\citep{moler2003nineteen}.
The method works on the similarity transformation of the form
\begin{equation}\label{eq:proof-toreorder}
  A=VDV^{-1}.
\end{equation}
The power series definition of $e^{At}$ implies then that~\citep{moler2003nineteen}
\begin{equation}
  e^{At}=Ve^{Dt}V^{-1}.
\end{equation} 
In this latter expression, let us consider the non-singular matrix $V$, whose columns are eigenvectors of $A$. Notation-wise, we can write that  
\begin{equation}
  V:=\begin{bmatrix}v_0 & v_1^0 & v_1^1 & \dots & v_r^0 & v_r^1\end{bmatrix}.
\end{equation}
and that the diagonal matrix of eigenvalues 
\begin{equation}
  D=\mathrm{diag}{(\lambda_0,\lambda_1^0,\lambda_1^1,\dots,\lambda_r^0,\lambda_r^1)},
\end{equation}
where $\lambda_0$ is the eigenvalue associated with the first item of $A$. $\lambda_j^0,\lambda_j^1$ are the two eigenvalues associated with the block $A_j$. We can then write 
\begin{equation}
AV=VD,
\end{equation}
by simply reordering \frefeq{eq:proof-toreorder}.

We apply the approach in terms of \frefeq{eq:state-perf} and under the assumptions that we made in the \fref{lem:eqv}{Lemma}
\begin{equation}
  \dot{\mathbf{q}}(t)=A\mathbf{q}(t).
\end{equation}
The linear combination of the initial guess $\mathbf{q}(t_0)$ and the generic solution can be then expressed
\begin{subequations}\begin{align}
  F\mathbf{q}(t_0)&=\gamma_0 v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j v_j^k}},\\
  F\mathbf{q}(t)&=\gamma_0 e^{\lambda_0 t} v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j e^{\lambda_j t} v_j^k}},\label{eq:proof-comb}
\end{align}\end{subequations}
where $t$ is a generic time instant and
\begin{equation}
  F=\begin{bmatrix}1 & \cdots & 1\end{bmatrix},
\end{equation} 
$F\in\mathbb{R}^m$ is a column vector of ones. 

Let us consider the expression in \frefeq{eq:proof-comb}. It represents the linear combination of all the coefficients of the state at time $t$. It can also be expressed in the following form
\begin{equation}\label{eq:proof-output}\begin{split}
  F\mathbf{q}(t)/T=\gamma_0 e^{\lambda_0t}v_0/T+&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^0t}v_j^0}+\\&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^1t}v_j^1},
\end{split}\end{equation}
where we split the sum and divided each item by the period $T$.

We prove that the eigenvalues $\mathbf{\lambda}$ and eigenvectors $V$ are such that \frefeq{eq:proof-output} is equivalent to \frefeq{eq:proof-complex}.
To this purpose, we note that matrix $A$ is a block diagonal matrix, and we can express its determinant as the multiplication of the determinants of its blocks
\begin{equation}
  \det{(A)}=\det{(0)}\det{(A_1)}\det{(A_2)}\cdots\det{(A_r)}.
\end{equation}

We now conclude the proof by computing the first determinant and the others separately.
By computing the first determinant, we prove that the first terms in \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. We find the eigenvalue from $\det(0)=0$, which is $\lambda_0=0$. The corresponding eigenvector can be chosen arbitrarily
\begin{equation}\label{eq:proof-first-det}
  (0-\lambda_0)v_0=\begin{bmatrix} 0 & \cdots & 0 \end{bmatrix},
\end{equation}
$\forall v_0$, thus we choose
\begin{equation}\label{eq:proof-v0}
  v_0=\begin{bmatrix}1 & 0 & \cdots & 0\end{bmatrix}.
\end{equation}
The sizes of the zero vector and of $v_0$ in \frefeqM{eq:proof-first-det}{eq:proof-v0} are both $\mathbb{R}^m$.

We find the value $\gamma_0$ in \frefeq{eq:proof-output} so that the terms are equal 
\begin{equation}
  \gamma_0=\begin{bmatrix}a_0 & 0 & \cdots & 0\end{bmatrix},
\end{equation} 
where $\gamma_0\in\mathbb{R}^m$.

Then, we prove the other determinants. In this way, we prove that all the terms in the sum of both \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. 
By computing the second determinant, we prove that the first terms in both summaries in \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. We thus focus on the first block $A_1$ and find the eigenvalues from 
\begin{equation}\label{eq:det-aj}
  \det(A_1-\lambda I)=0.
\end{equation}
The polynomial $\lambda^2+\omega^2$, gives two complex roots--the two eigenvalues
\begin{subequations}\begin{align}
  \lambda_1^0&=i\omega,\\
  \lambda_1^1&=-i\omega.
\end{align}
\end{subequations}
The eigenvector associated with the eigenvalue $\lambda_1^0$ is 
\begin{equation}
  v_1^0=\begin{bmatrix}0 & -i&1&0&\cdots&0\end{bmatrix}'.  
\end{equation}
The eigenvector associated with the eigenvalue $\lambda_1^1$ is 
\begin{equation}
  v_1^1=\begin{bmatrix}0&i&1&0&\cdots&0\end{bmatrix}'. 
\end{equation}
Both eigenvectors are equally sized $v_1^0,v_1^1\in\mathbb{R}^m$.

Again, we find the values $\gamma_1$ in \frefeq{eq:proof-output} such that the equivalences 
\begin{equation}\begin{cases}    
  e^{i\omega t}(a_1-ib_1)&=\gamma_1 e^{i\omega t}v_1^0\\
  e^{-i\omega t}(a_1+ib_1)&=\gamma_1 e^{i\omega t}v_1^1
\end{cases},\end{equation}
hold. They hold for 
\begin{equation}
  \gamma_1=\begin{bmatrix}0&b_1&a_1&0&\cdots&0\end{bmatrix}.
\end{equation} 

The proof for the remaining $r-1$ blocks is equivalent.

The initial guess $\mathbf{q}_0$ is built such that the sum of the coefficients is the same in both the signals. In the output matrix, the frequency $1/T$ accounts for the period in \frefeq{eq:proof-complex}, \frefeq{eq:proof-output}, and~\frefeq{eq:fourier}. At time instant zero, the coefficients $b_j$ are not present and the coefficients $a_j$ are doubled for each $j=1,2,\dots,r$ (thus we multiply by half the corresponding coefficients in $\mathbf{q}_0$). To match the outputs $h(t)=y(t)$, or equivalently 
\begin{equation}
  F\mathbf{q}(t)/T=C\mathbf{q}(t), 
\end{equation}
we have 
\begin{equation}
  C=(1/T)\begin{bmatrix}1 & 1 & 0 & \cdots & 1 & 0\end{bmatrix}.
\end{equation}

We thus conclude that the signal and the output are equal and that the lemma holds.

\end{proof}

We note for practical reasons that the signal would still be periodic with another linear combination of coefficients. For instance
\begin{equation}\label{eq:mat_C_generic}
  C=d\begin{bmatrix}1 & 1 & 0 & \cdots & 1 & 0\end{bmatrix},
\end{equation} 
equivalent to
\begin{equation}
  C=d\begin{bmatrix}1 & 0 & 1 & \cdots & 0 & 1\end{bmatrix},
\end{equation} 
or 
\begin{equation}
  C=d\begin{bmatrix}1 & \cdots & 1\end{bmatrix},
\end{equation} 
for a given constant value $d\in\mathbb{R}$.

\subsection{Nominal control of the energy signal}
\label{sec:nom-cont}\findex{nominal control}

Let us suppose that at time instant $t$ the plan in \fref{def:plan}{Definition} reached the $i$th stage $\Gamma_i$ and the control contains the configuration of path and computations parameters 
\begin{equation}\label{eq:state-control2}\begin{split}
  c_i(t):&=\Big[\overbrace{\begin{matrix}c_{i,1}(t)&\cdots&c_{i,\rho}(t)\end{matrix}}^{\rho} \,\,\, \overbrace{\begin{matrix}c_{i,\rho+1}(t)&\cdots&c_{i,\rho+\sigma}(t)\end{matrix}}^{\sigma}\Big]'\\
  &=\begin{bmatrix}c_i^\rho(t) & c_i^\sigma(t)\end{bmatrix}',
\end{split}\end{equation}
where $c_i(t)\in\mathbb{R}^n$ with $n=\rho+\sigma$ differs from the nominal control $\mathbf{u}(t)$ in \frefeq{eq:state-perf}. We include the control in the nominal control exploiting the following observation. 

\begin{highlight}
  \begin{obs}[Relation between the control and energy]
    We observe that:
    \begin{enumerate*}[label={(\alph*)},font={\textit}]
      \item a change in path parameters affects the energy indirectly. It alters the time when the aerial robot reaches the final point $\mathbf{p}_{\Gamma_l}$ and enters the final stage $\Gamma_l$,
      \item a change in computation parameters affects the energy directly. It alters the power as more computations require more power (and vice versa).
    \end{enumerate*}
  \end{obs}
\end{highlight}

The second point in the observation is easily verified. The \powprof{} profiling tool models the energy consumption of the heterogeneous computing hardware the mobile robot is carrying. A variation in the computations parameters affects the schedule (as the schedule is parametrized by the parameters in \fref{def:comp-mot-energy}{Definition}), and hence results in more/less power required by the computing hardware.

The first point in the observation can be verified by inspection of the example in \fref{sec:flight-plan}{Section}. It is clear that if we decrease the parameter $c_{4,1}$ relative to the circle radius, the flying time decreases. This is shown in \fref{fig:zambo1}{Figure} and \fref{fig:zambo2}{Figure}. \fref{fig:zambo1}{Figure} illustrates the trajectory of the aerial robot (composed of all the paths $\varphi_1,\varphi_2\,\dots$) flying at the highest configuration of the path parameter $c_{i,1}=\overline{c}_{4,1}$. \fref{fig:zambo2}{Figure} then illustrate the trajectory flying at the lowest configuration $c_{i,1}=\underline{c}_{4,1}$. The flying time differs significantly, along with the quality of the coverage of the polygon (the agricultural field in \fref{fig:plot2}{Figure}). In \fref{fig:zambo2}{Figure}, the parameter $c_{4,1}$ that alters the radius and center of the upper circle (defined originally in \fref{sec:flight-plan}{Section}) is replanned as, e.g., averse atmospheric conditions do not allow to terminate the original plan in \fref{fig:zambo1}{Figure}.

We use the observation later in \fref{sec:opt-cont-gener}{Section} to check that the time to completely discharge the battery is greater than the flight time and replan the path parameters accordingly.  We replan the computation parameters to maximize the instantaneous energy consumption against the maximum battery discharge rate.

The nominal control is
\begin{equation}\label{eq:state-control}
  \mathbf{u}(t):=\hat{\mathbf{u}}(t)-\hat{\mathbf{u}}(t-\Delta t),
\end{equation}
where $\hat{\mathbf{u}}(t)$ is defined as the energy estimate of a given control sequence at time instant $t$, $\hat{\mathbf{u}}(t-\Delta t)$ at the previous time instant $t-\Delta t$
\begin{equation}\label{eq:estimate-control}
  \hat{\mathbf{u}}(t):=\mathrm{diag}(\nu_i)c_i(t)+\tau_i,
\end{equation}
where $\mathrm{diag}(\nu_i)$ is a diagonal matrix with the parameters
$\nu_{i,j}\in\nu_i,\,\forall j\in[n]_{>0}$.

The input matrix is then
\[
  \hspace*{1.6ex}\begin{matrix} \hspace*{1ex} &
    \overbrace{\begin{matrix}
      \hspace*{1ex} & \hspace*{3ex} & \hspace*{1ex}
    \end{matrix}}^{\sigma}\end{matrix}
\]\vspace*{-2em}
\begin{equation}\label{eq:mat_B}
  B=\left.\begin{bmatrix}
      0^{1\times\rho} & 1      & \cdots & 1      \\
      0^{1\times\rho} & 0      & \cdots & 0      \\ 
      \vdots          & \vdots & \ddots & \vdots \\
      0^{1\times\rho} & 0      & \cdots & 0   
  \end{bmatrix}\right\}{\text{\scriptsize $2r+1$}}
\end{equation}
where $B\in\mathbb{R}^{m\times n}$ contains zeros except the first row where the first $\rho$ columns are still zeros and the remaining $\sigma$ are ones. 

$\hat{\mathbf{u}}(t)$ is a stage-dependent scale transformation with 
\begin{subequations}\label{eq:scaling}\begin{align}
\nu_i&=\Big[\overbrace{\begin{matrix}\nu_{i,1}&\cdots&\nu_{i,\rho}\end{matrix}}^{\rho} \,\,\, \overbrace{\begin{matrix}\nu_{i,\rho+1}&\cdots&\nu_{i,\rho+\sigma}\end{matrix}}^{\sigma}\Big]'=\begin{bmatrix}\nu_i^\rho & \nu_i^\sigma\end{bmatrix}',\\ 
\tau_i&=\Big[\begin{matrix}\,\tau_{i,1}&\cdots&\tau_{i,\rho}\end{matrix} \,\,\,\, \begin{matrix}\tau_{i,\rho+1}&\,\cdots&\tau_{i,\rho+\sigma}\,\,\end{matrix}\Big]'=\begin{bmatrix}\tau_i^\rho & \tau_i^\sigma\end{bmatrix}',
\end{align}\end{subequations}
scaling factors. They quantify the contribution to the plan of a given parameter in terms of time for the first $\rho$ parameters, and instantaneous energy consumption for the remaining $\sigma$ (we use the same notation for the path and computation scaling factors as for the parameters). 

The nominal control $\mathbf{u}(t)$ is then the difference of these contributions of two consecutive controls $c_i(t-\Delta t),c_i(t)$ applied to the system. 
$B\mathbf{u}(t)$ merely includes the difference in the instantaneous energy consumption into the model in \frefeq{eq:state-perf}. Matrix $B$ ignores the time contribution of the path parameters in $c_i$. We use them to verify that the flying time is lower than the battery time in \fref{sec:algo}{Section}.

\subsection{Control scale transformation}
\label{sec:merging}

To transform the control $c_i(t)$ at $i$th stage and time instant $t$, we use different approaches for the path and computation scaling factors.
The scaling factors for the path parameters from \frefeq{eq:scaling} are derived empirically. For example, we can obtain the scaling factor $\nu_{4,1}$ relative to the alteration $c_{4,1}$ of the upper circle $\varphi_4$ from \fref{sec:flight-plan}{Section} by measuring the time needed to compute the path with the lowest configuration $\underline{c}_{4,1}$, $\underline{t}$ in \fref{fig:zambo2}{Figure}, and the highest $\overline{t}$ in \fref{fig:zambo1}{Figure}. 

The variation of the control hence results in an approximate measure of the plan's time variation with factors
\begin{subequations}\label{eq:scale-traj}\begin{align}
  \nu_{i,j}&=\left((\overline{t}-\underline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})\right)/\rho,\\
  \tau_{i,j}&=\left(\underline{c}_{i,j}(\underline{t}-\overline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})+\underline{t}\right)/\rho,
\end{align}\end{subequations} 
$\forall j\in[\rho]^+$. Moreover, let the factors be zero when the parameters $c_i^\rho=\emptyset$. We use the latter to initialize the algorithm in \fref{sec:algo}{Section}.

\begin{figure}[h!]
  \sfr
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/plot6.tikz}
  \caption[Concept of a path and computations parameters scale transformation]{The concept of a path and computations parameters scale transformation. Without any battery constraints, the energy-aware coverage planning and scheduling select the highest configuration which respects the control constraint (admissible region) from \frefeq{eq:constraint-set}.}
  \label{fig:plot-6}
  \efr
\end{figure}

The scaling factors for the computations parameters from \frefeq{eq:scaling} are derived using {\small\tt{powprofiler}}, the open-source modeling tool from \fref{sec:powprof}{Section}. We estimate the energy cost of a given schedule (a given computations configuration) with the function $g$ from \fref{def:comp-ener}{Definition}. 
For instance, if the computation is the CNN ROS node, the computation parameter $c_{1,2}$ corresponds to the \Gls{acr:fps} rate. The tool then measures power according to the detection frequency.

The scaling factors add the computational energy component to the model in \frefeq{eq:state-perf}. They are derived similarly to \frefeq{eq:scale-traj}
\begin{subequations}\label{eq:scale-comp}\begin{align}
  \nu_{i,j}&=(g(\overline{c}_{i,j})-g(\underline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j}),\\
  \tau_{i,j}&=\underline{c}_{i,j}(g(\underline{c}_{i,j})-g(\overline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j})+g(\underline{c}_{i,j}),
\end{align}\end{subequations}
$\forall j\in[\rho+1,n]$. We then assume $g$ only returns the power metric (so we do not specify an additional parameter to numerate the metric) and, for ease of notation, assume all the values from $g(\underline{c}_{i,j})$ to $g(\underline{c}_{i,j})$ are distributed linearly. Moreover, let the factors be zero when the parameters $c_i^\sigma=\emptyset$.

The concept of a path and a computation parameter $(c_{i,1},c_{i,2})$ scale transformation is illustrated in \fref{fig:plot-6}{Figure}. 
The energy domain is bounded by the output of the \powprof{} tool, while the flight time domain is by the empirical data. The energy-aware coverage planning and scheduling select the highest possible configuration of parameters (control) in the admissible region\findex{admissible region} (under the constraints). 
\begin{figure}[h!]
  \sfr
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/plot7.tikz}
  \caption[Change in the admissible region]{Change in the admissible region in \fref{fig:plot-6}{Figure} due to a battery constraint.}
  \label{fig:plot-7}
  \efr
\end{figure}
Currently, the highest control corresponds to $(\overline{c}_{i,1},\overline{c}_{i,2})$. We will see in \fref{sec:output-mpc}{Section} the optimal control derivation over a time horizon $N$ under given battery constraints.
In \fref{fig:plot-7}{Figure} we briefly exemplify this latter case, where due to, e.g., a sudden battery drop, the energy and time domains are shrunk. The highest possible control is thus now different from the above scenario.

\subsection{\color{red}Aperiodic energy evolution}
\label{sec:non-perio}


%%%%%%%%%%%%%%%%%
\section{\color{red}Summary}

