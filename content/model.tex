
%%%%%%%%%%%%%%%%%%%
%                 %
% Energy Models   %
%                 %
\chapter{Energy Models}
\label{cp:model}

\begin{chapquote}{\cite{ondruska2015scheduled}}
  ``Robots require energy to operate. Yet they only have access to limited energy storage during missions.''
\end{chapquote}

\vspace*{1em}

\lettrine{E}{nergy is an essential aspect} of many autonomous mobile robotics scenarios~\citep{mei2005case} and often a limiting factor to improving computing performance~\citep{horowitz2014computing}. In the previous chapters, we emphasized the growing importance of both computations and motion energy components. Indeed, limited energy availability against high computing performance requirements of autonomous aerial robots is the motivation for the energy-aware coverage planning and scheduling for autonomous aerial robots in this work. For this purpose, we first need an accurate energy model that predicts future energy consumption. We derive such a model in this chapter, providing different energy models predicting the energy of the motion and computations and the battery state of an aerial robot. For the former two, we first derive a way to accurately predict the energy spent running a given set of computations on the computing hardware. We then merge the resulting computations energy model with a motion energy model using some properties of our autonomous scenario.  The energy output of the motion model is the input of the battery model, which predicts the battery evolution over time.

We saw in \fref{cp:model}{Chapter} some computations energy and battery models, and we discussed some energy-aware approaches for aerial robots (and mobile robots broadly) performing coverage path planning (\Gls{acr:cpp}) or motion planning generally. In this chapter, we then use the previous literature and derive the energy models for our scenario: an autonomous aerial robot employed in coverage planning, monitoring an agricultural field. Although applied to a given use case, the approach is general in terms of the proposed methodology. In \fref{sec:comp-ener-model}{Section}, we derive the model for the energy of computations based on regressional modeling. In \fref{sec:battery-model}{Section}, we provide a battery model based on an equivalent electrical circuit, and in \fref{sec:periodic-model}{Section}, we derive a model for the motion that incorporates the computations energy model. We then use the models in \fref{cp:dyn}{Chapter} to plan and schedule altogether.

This chapter connects to the remainder of this work as follows. We provided some energy implications of autonomous aerial robots in \fref{cp:intro}{Chapter} and formulated the basic constructs in \fref{cp:pb}{Chapter}, including the concepts of computations and motion energy. We discussed the past energy modeling and efficiency studies in \fref{cp:soa}{Chapter}, along with other literature. We then use all the information we discussed in the previous chapters for the energy models in this chapter. In \fref{cp:dyn}{Chapter}, we use the models to replan the coverage and schedule the computations in an energy-aware fashion. The replanning uses some optimal control techniques that we introduce in \fref{cp:opt}{Chapter}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy Model of the Computations}
\label{sec:comp-ener-model}

This section describes the computations energy model to predict the energy consumption of a given configuration of computations. In \fref{sec:definitions}{Section} and the precision agriculture example in \fref{sec:computation-wise}{Section}, we parametrized the computations by a set of $\sigma$ computations parameters $c_{i}^\sigma:=\{c_{i,\rho+1},\dots,c_{i,\rho+\sigma}\}$, where $\rho$ is the number of path parameters. We parametrize the computations that impact the overall energy consumption (as we described in \fref{def:comps}{Definition}). For instance, in the agricultural scenario, we parametrize the computation object detection. We mean by parametrization that we enable the computations to be dynamically replanned with an appropriate choice of the parameters, and run on, e.g., a lower/higher rate requiring lower/higher power. Practically, this means that if our system is composed of $\sigma$ computations, the configuration of computations parameters $c_i^\sigma(\mathcal{T})$ for each stage $i$ over time $\mathcal{T}:=[t_0,t_l]$ (where $t_0,t_l$ are respectively the first time instant and the time instant when the aerial robot reaches the final point $\mathbf{p}_{\Gamma_l}$ in \fref{def:trigs}{Definition}) is a schedule of the computations. In \fref{cp:dyn}{Chapter}, we will derive an energy-aware schedule via the model that we propose in this section.
In the remainder of this section, we derive an energy model that maps any choice of parameters $c_{i}^{\sigma}$ to the power at any $t\in\mathcal{T}$, extending the past work on energy modeling for heterogeneous computing hardware.

In \fref{sec:model-hete-elem}{Section}, we summarize the heterogeneous elements modeling from \fref{sec:soa-ene-hete}{Section} and outline our approach, which consists of two layers. We detail the layers in \fref{sec:measurement-layer}{Sections}\fref{sec:predictive-layer}{--\hspace{-.8ex}} and describe an automated modeling tool we developed in \fref{sec:powprof}{Section} along with its configuration specification in \fref{sec:conf-spec}{Section}. The tool works well for computing hardware equipped with internal power meters, yet, some computing hardware does not provide any. We discuss how to model such hardware also in \fref{sec:powprof}{Section}.


\subsection{Model for the heterogeneous elements}
\label{sec:model-hete-elem}

We saw in \fref{cp:pb}{Chapter} that traditionally, models for computing hardware focus on a specific computing element, such as CPU or GPU, or model the elements heterogeneously. The models provide a regression function (measuring the power consumption over time), analytical (using some architectural parameters), or other expressions to infer future energy consumption. The regression functions, analytical or other expressions might depend on low-level architectural parameters and be employed in an energy-efficient selection of such parameters, including voltage and frequency. Alternatively, they might depend on high-level parameters (such as the computations parameters $c_{i}^\sigma$ in this work) and be employed in an energy-aware configuration of software (and hardware), e.g., the tasks allocation on the CPU cores. An expression depending on a configuration is more common for heterogeneous models, as we summarized in \fref{tab:energy-models}{Table}. We focus on these models; in \fref{cp:intro}{Chapter} and formally in \fref{def:comps}{Definition}, we assumed the aerial robot caries heterogeneous computing hardware for energy-demanding computations. We refer to \fref{sec:comp-ener-model}{Section} for an extensive discussion of some energy modeling approaches in the literature for CPUs and GPUs powered and heterogeneous computing hardware. 

\begin{figure}[h!]
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6224}
  \caption[NVIDIA Jetson Nano heterogeneous computing hardware]{NVIDIA Jetson Nano heterogeneous computing hardware that we model the computations energy on. The hardware in the image includes the Jetson Developer Kit board that the Nano heterogeneous board is mounted on and has a total size of 100x80 millimeters and a weight of approx. 140 grams.}  
  \label{fig:nano}\findex{NVIDIA Jetson!Nano}
\end{figure}
\begin{figure}[h!]   
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6220}
  \caption[NVIDIA Jetson TX2 heterogeneous computing hardware]{NVIDIA Jetson TX2 heterogeneous computing hardware mounted on a Jetson Developer Kit\findex{NVIDIA Jetson!Developer Kit} board as Nano in \fref{fig:nano}{Figure} with a total size of 170x170 millimeters and a weight of approx. 512 grams.}   
  \label{fig:tx2}\findex{NVIDIA Jetson!TX2}
\end{figure}
\begin{figure}[h!]
  \centering
  \includegraphics[width=.7\textwidth]{pictures/_DSC6222}
  \caption[ODROID XU3 heterogeneous computing hardware]{ODROID XU3 heterogeneous computing hardware with a total size of 94x70 millimeters and a weight of 70 grams.}
  \label{fig:odroid}\findex{ODROID XU3}
\end{figure}

Our approach is based on our work~\citep{seewald2019coarse} on heterogeneous computing devices' energy modeling and generic, modeling virtually a wide range of heterogeneous computing hardware energy consumption in real use-cases with little users effort. We use statistical methods to derive a regression-based model segmented into two layers. In the first, the measurement layer\findex{measurement layer}, we map the time to the power, and in the second, the predictive layer\findex{predictive layer}, we map the computations configuration $c_{i}^\sigma(t)$ to the power. To generate a model, our approach inputs a user-defined configuration file, which simply specifies the computations along with the computation parameter constraint sets $\mathcal{S}_{i,k}$ in \fref{def:stage}{Definition}, per each computation $k\in[\sigma]_{>0}$ and stage $i\in[l]_{>0}$ (or $[n]_{>0}$ if the computations are specified along the primitive paths and reiterated when the aerial robot reaches $\mathbf{p}_{\Gamma_n}$ with a shift $\mathbf{d}$ in \fref{fig:state-machine}{Figure}). From the configuration, an automated modeling tool termed \powprof{} measures the energy consumption of a discrete set of configurations $c_{i,\rho+j}\in\mathcal{S}_{i,j}$, per each computation parameter $j\in[\sigma]_{>0}$ and derives the measurement layer. The tool allows merging then a set of measurement layers into a predictive layer via linear regression.
As heterogeneous computing hardware, we use different devices, such as NVIDIA Jetson Nano\findex{NVIDIA Jetson!Nano}, TX2\findex{NVIDIA Jetson!TX2}, and TK1\findex{NVIDIA Jetson!TK1} in \fref{fig:nano}{Figures}\fref{fig:tx2}{--\hspace*{-.8ex}} and \fref{fig:tk1}{} and ODROID XU3\findex{ODROID XU3} in \fref{fig:odroid}{Figure}. 
\begin{table}[h!]
  \footnotesize\fontfamily{phv}\selectfont
    \begin{tabularx}{\textwidth}{|X|*{4}{l|}}\hline
      Hardware & CPU & GPU & Memory & Sensors \\
      \hline
      NVIDIA Jetson Nano & -A57 & NVIDIA Maxwell & 4 GB LPDDR4 RAM & \cmark\\
      NVIDIA Jetson TX2 & -A57 & NVIDIA Pascal & 8 GB LPDDR4 RAM, 32 GB NV & \cmark\\
      NVIDIA Jetson TK1 & -A15 & NVIDIA Kepler & 1 GB DDR3L RAM, 16 GB NV & \xmark\\
      ODROID XU3 & -A15, -A7 & MALI & 2 GB LPDDR3 RAM & \cmark
      \\\hline
    \end{tabularx}
    \caption[Mobile computing hardware explicitly analyzed in this work]{Mobile computing hardware explicitly analyzed in this work. All the CPUs are ARM Cortex. The majority of the embedded boards provide random access memory (RAM)\findex{memory!random access}, and some a non-volatile (NV) memory\findex{memory!non-volatile}. All the boards have energy measuring capabilities except NVIDIA Jetson TK1.}
    \label{tab:hws}
\end{table}
We summarize the computing hardware that we explicitly consider in this work in \fref{tab:hws}{Table}. These devices are commonly employed in robotics literature to power complex computations. For instance, Jetson TX2 has been employed in path planning\findex{path planning}~\citep{dharmadhikari2020motion,ryou2018applying}, simultaneous localization and mapping\findex{simultaneous localization and mapping} (\Gls{acr:slam})~\citep{aldegheri2019data}, and object detection\findex{object detection} via convolutional neural networks\findex{convolutional neural network} (\Gls{acr:cnn}s)~\citep{william2019aerial}. Jetson Nano in SLAM and CNNs~\citep{peng2019evaluating,wang2020yolo,alexey2021autonomous}, and ODROID XU3~\citep{bhat2019power,papachristos2015aerial,giusti2016machine} and Jetson TK1~\citep{gong2016low,holper2017cyber} in similar applications. Although we report some in this paragraph, heterogeneous embedded boards power computations in many other mobile robots use-cases, thus possibly broadening the applicability of our work, which we further in \fref{cp:conc}{Chapter}. In the remainder of this section, we detail our energy model for the heterogeneous computing hardware.

\subsection{Measurement layer}\findex{measurement layer}
\label{sec:measurement-layer}

The measurement layer is the basic building block of the computations energy model: one or more measurement layers form the predictive layer--the model output--which we describe in \fref{sec:predictive-layer}{Section}. For a specific computations parameters configuration $c_i^\sigma(t)$, the measurement layer maps the time $t\in[t_0,t_f]:=\mathcal{T}\subset\mathbb{R}_{>0}$ (the final and initial time instants $t_0,t_f$ are given) to the power measured in watts\findex{watts}, the energy measured in joules\findex{joules} (watts per unit of time), and the battery state of charge (\Gls{acr:soc})\findex{state of charge} expressed in percentages. The measurement layer thus provides a primitive model for $c_i^\sigma$ of power, energy, and SoC over a given time interval. The derivation of the layer is automated with \powprof{}, the modeling tool that we describe in detail in \fref{sec:powprof}{Section}, which outputs the layer after executing $c_i^\sigma$ on $\mathcal{T}$. Additionally, the model (and the \powprof{} tool) can output the triplet of metrics from the measurement layer per each energy sensor: some computing hardware that we analyze indeed provide different sensors for different computing elements, i.e., NVIDIA Jetson TX2, Nano, and ODROID XU3 boards all provide energy-sensing capabilities for CPU, GPU, overall, and/or memory.

Let us define the measurement layer formally, assuming there are one or more energy sensors or other energy measuring devices (these include, e.g., internal power resistors or shunt resistors, amperometers, and multimeters) in \fref{def:measur-layer}{Definition}.

\begin{highlight}
  \begin{defn}[Measurement layer]\label{def:measur-layer}
    Given a specific energy measuring device, computations parameters configuration $c_i^\sigma(t)$, and an initial and final time instant $t_0,t_f$ such that $t\in\mathcal{T}:=[t_0,t_f]$, the \textit{measurement layer} is the function
    $\mathbf{g}:\mathbb{Z}_{>0}\times\mathbb{Z}^\sigma\times\mathcal{T}\rightarrow\mathbb{R}^3$.
    It returns the power in watts, energy in joules, and SoC in percentages of an energy measuring device, a configuration of computations parameters, and time interval.
  \end{defn}
\end{highlight}

The measurement layer physically samples the computing hardware for $\mathcal{T}$ and returns the metrics, but sampling-to-completion is also possible, where a configuration runs up until it terminates rather than for a given interval. In the latter eventuality, $\mathcal{T}$ is ${\emptyset}$.

As an instance of the measurement layer, let us return briefly to the precision agriculture example in \fref{sec:flight-plan}{Section}, which describes the agricultural use-case (the aerial robot detects ground hazards and communicates the detections to a ground station). The computations parameters in \fref{sec:computation-wise}{Section} are $c_{i,2}$, the frames per second (\Gls{acr:fps})\findex{frames per second} rate, and $c_{i,3}$, encryption or no encryption of the robot---ground station data link. The configurations $c_{i,2}(t)\in\mathcal{S}_{i,2}$, $c_{i,3}(t)\in\mathcal{S}_{i,3}$ have any value within the constraint sets in \frefeqM{eq:encr-comp-const}{eq:cnn-comp-const}. The constraint sets are the same in each stage  $i$ in the plan $\Gamma$ except for the circles where the aerial robot travels the turns out of the boundaries, and the detections are inhibited. To build the measurement layer, we can discretize the configurations with a given $\delta_1,\delta_2$ for parameters $c_{i,2}$ and $c_{i,3}$. The measurement layer is then built by sampling the power for $\mathcal{T}$, one for all the possible configurations
\begin{equation}\label{eq:meas-layer-lin-sampl}
  c_i^\sigma:=\{c_{i,2},c_{i,3}\mid\forall j,k\in\mathbb{Z},\, \underline{c}_{i,2}+j\delta_1\in\mathcal{S}_{i,2},\underline{c}_{i,3}+k\delta_2\in\mathcal{S}_{i,3}\}.
\end{equation}

A value can be, e.g, $\delta_1=\delta_2=2$, so that there are ten configurations and consequently ten measurement layers. The \powprof{} tool automatically builds the layers, storing the results in comma-separated values (\Gls{acr:csv})\findex{comma-separated values} files (we see further the tool in \fref{sec:powprof}{Section}).
\frefeq{eq:meas-layer-lin-sampl} provides a way to sample the search space linearly, but other sampling strategies are equally possible, such as exponential sampling
\begin{equation}\label{eq:meas-layer-exp-sampl}
  c_{i}^\sigma:=\{c_{i,2},c_{i,3}\mid\forall j,k\in\mathbb{Z},\, {\delta_1}^j\in\mathcal{S}_{i,2},{\delta_2}^k\in\mathcal{S}_{i,3}\},
\end{equation}
where $\delta_1,\delta_2$ are now bases, or random sampling with the condition merely $c_{i,j}\in\mathbb{Z}_{>0}$. Currently, the \powprof{} tool supports automated linear and exponential sampling and complex sampling formed by different sampling strategies~\citep{seewald2019coarse}, e.g.,
\begin{equation}
  c_{i}^\sigma:=\{\{c_{i,2}\mid\forall k\in\mathbb{Z},\, \underline{c}_{i,2}+k\delta_1\in\mathcal{S}_{i,2}\},\{c_{i,3}\mid\forall k\in\mathbb{Z},{\delta_2}^k\in\mathcal{S}_{i,3}\}\}.
\end{equation}
Parameter ranges ($\mathcal{S}_{i,2},\mathcal{S}_{i,3}$) choice is dictated by the range at which the computations run at runtime, whereas $\delta$s choice is made so that the modeling terminates in a reasonable amount of time~\citep{seewald2019coarse}.

With the measurement layer described in this section, we know the power and other energy metrics of the (measured) configurations. However, we want to predict the energy consumption for any configuration of parameters in the constraint sets (and not only the sampled ones). We address this latter requirement in the next section, merging the measurement layers with linear regression.

\subsection{Predictive layer}\findex{predictive layer}
\label{sec:predictive-layer}

The predictive layer describes coarse-grained metrics, such as the power over FPS rate, mapping them to the metrics from the measurement layer, thus providing energy data for each configuration of parameters (or for each scheduling policy). To this end, it uses the set of measurement layers, building a two-by-two linear regression between consecutive layers. In the precision agriculture example with ten measurement layers, the predictive layer consists of regression between data points $\{c_{i,2},c_{i,3}\}$ for all the possible computations parameters (recall that a measurement later corresponds to a sampled computations configuration), opposed to the sampled ones in \fref{sec:measurement-layer}{Section}. \fref{def:comp-ener}{Definition} details the resulting model.

\begin{highlight}
  \begin{defn}[Predictive layer]\label{def:comp-ener}
    Given a specific energy measuring device and computations parameters configuration $c_i^\sigma(t)$ \textit{predictive layer} is the function $g:\mathbb{Z}_{\geq 0}\times\mathbb{Z}^\sigma\rightarrow\mathbb{R}^3$. It returns the power in watts, energy in joules, and SoC in percentages of any configuration of parameters within the constraint sets.
  \end{defn}
\end{highlight}

Analogously to the measurement layer, there can be various energy measuring devices, resulting in multiple triples of energy, power, and SoC, one per device. The predictive layer returns the same metrics of the measurement layer in \fref{def:measur-layer}{Definition}, without physically sampling the computing hardware but using the stored measurement layers. Indeed due to a potentially large search space in computational energy modeling, it is critical to infer the energy properties of the entire search space from a subset of all the possible samples~\citep{lee2006statistically,lee2006accurate,bailey2014adaptive}. The linear regression to infer such properties utilizes a method that we term the approximation method\findex{approximation method}~\citep{seewald2019coarse}. It builds a linear regression between two adjacent data points rather than merely for all the data points. Indeed we do not assume an apriori knowledge of the computations energy evolution with explicit models for all the data points such as linear or exponential, but rather model the energy linearly on tuples of data points~\citep{seewald2019coarse}.

Given an (unsampled) configuration $c_i^\sigma$, the predictive layer is approximated with
\begin{equation}
  g(c_i^\sigma)=(\mathbf{g}(\lceil c_i^\sigma\rceil,\mathcal{T}_1)-\mathbf{g}(\lfloor c_i^\sigma\rfloor),\mathcal{T}_2)(c_i^\sigma-\lfloor c_i^\sigma\rfloor)/(\lceil c_i^\sigma\rceil-\lfloor c_i^\sigma\rfloor)+\mathbf{g}(\lfloor c_i^\sigma\rfloor,\mathcal{T}_2),
\end{equation}
where $\lceil c_i^\sigma\rceil,\lfloor c_i^\sigma\rfloor$ are the two adjacent measurement layers of the computations configuration $c_i^\sigma$ (e.g., if we use $\delta_1=2$ in \frefeq{eq:meas-layer-lin-sampl}, $c_i^\sigma$ with just the parameter $c_{i,2}$ has $\lfloor c_i^\sigma\rfloor$ equal to two and $\lceil c_i^\sigma\rceil$ to four), and $\mathcal{T}_1,\mathcal{T}_2$ are the two time intervals in the measurement layer for configurations $\lfloor c_i^\sigma\rfloor,\lceil c_i^\sigma\rceil$ respectively.
We illustrate the principle in \fref{}{Figure}. % todo the figure

\subsection{The {\tt powprofiler} tool}\findex{powprofiler@\texttt{powprofiler}}
\label{sec:powprof}

The \powprof{}\footnote{The tool can be retrieved from \url{https://github.com/adamseew/powprofiler}} tool is an automated profiling and modeling utility that generates the measurement layers for a discrete set of possible computations configurations (automated profiling) and merges these layers later, providing the predictive layer (modeling). We proposed an early version of the tool earlier in our work~\citep{teamplayd43,seewald2019coarse}, which we extended later to support per-component energy modeling in a dataflow computational network~\citep{seewald2019component}, and integrated~\citep{zamanakos2020energy} with Robot Operating System (ROS) middleware~\citep{quigley2009ros}\findex{Robot Operating System}. The tool is written in C++\findex{C++} and distributed under an MIT license\findex{MIT license}. It supports all the computing hardware explicitly mentioned in this work, i.e., NVIDIA Jetson TX2, Nano, and TK1 and ODROID XU3 in \fref{tab:hws}{Table}. It is predisposed further for extensibility supporting possibly any Linux-based\findex{Linux} computing hardware that provides energy measuring devices or that alternatively provide a mechanism to measure the energy with an external device.

The tool uses an object-oriented programming\findex{object-oriented programming} approach~\citep{stroustrup1988what,wegner1990concepts}, where each computing hardware has its own class that inherits from the class {\small\tt sampler}\findex{class!sampler@\texttt{sampler}} the functions {\small\tt get\_sample}\findex{function!getsample@\texttt{get\_sample}} and {\small\tt dryrun}\findex{function!dryrun@\texttt{dryrun}}. The former function returns a power measurement from all the measuring devices on specific computing hardware (power for the measurement layer in \fref{sec:measurement-layer}{Section} for, e.g., CPU, GPU, overall, etc\dots), and the latter simply attempts to read from the measuring devices returning a boolean value indicating if the attempt was successful. The tool contains classes {\small\tt sampler\_tx2}\findex{class!samplertx2@\texttt{sampler\_tx2}}, {\small\tt sampler\_nano}\findex{class!samplernano@\texttt{sampler\_nano}}, and {\small\tt sampler\_odroid}\findex{class!samplerodroid@\texttt{sampler\_odroid}} already implementing the necessary utilities to store the models from the computing hardware that we explicitly analyze.

The function {\small\tt get\_sample} further relies on a specific data type, which we term {\small\tt vectorn}\findex{data type!vectorn@\texttt{vectorn}}. Each value in {\small\tt vectorn} has its flag, indicating the metric and the measuring device. For instance {\small\tt power\_cpu}, {\small\tt soc\_gpu} are two flags indicating that the metric is for the power and the measuring device is of
the CPU and the SoC of the GPU respectively. The enumeration {\small\tt vectorn\_flags} contains all the flags. The tool stores a set of {\small\tt vectorn}s sampled at discrete intervals (\powprof{} is highly personalizable, allowing to change the frequency via the configuration specification in \fref{sec:conf-spec}{Section}) in another structure termed {\small\tt pathn}\findex{data type!pathn@\texttt{pathn}}. Each {\small\tt pathn} corresponds to a measurement layer in \fref{sec:measurement-layer}{Section}. The tool further provides mechanisms, such as the overload of the constructor, to automatically load the layers from a previously stored CSV file. Internally the tool stores {\small\tt pathn}s (the measurement layers) in a wrapper, {\small\tt model\_1layer}\findex{class!model1layer@\texttt{model\_1layer}}, which contains information such as the parameters configuration and the set $\mathcal{T}$; {\small\tt model\_2layer}\findex{class!model2layer@\texttt{model\_2layer}} is then another internal structure that returns the predictive layer in \fref{sec:predictive-layer}{Section}. 
\begin{figure}[h!]
  \centering 
  \includegraphics[width=.7\textwidth]{pictures/_DSC6228}
  \caption[NVIDIA Jetson TK1 heterogeneous computing hardware]{NVIDIA Jetson TK1 heterogeneous computing hardware mounted on a Toradex Ixora\findex{Toradex Ixora} carrier board with a total size of 125x95 millimeters and a weight of approx. 160 grams.} 
  \label{fig:tk1}\findex{NVIDIA Jetson!TK1}
\end{figure}
In this setting, NVIDIA Jetson TK1 computing hardware does not include any energy measuring device. \powprof{} allows an external device in the sense that it can import data in the model directly through the overload of the constructor into a measurement layer (and therefore a set of measurement layers into a predictive layer). An early instance of our work~\citep{seewald2019hlpgpu} consisted of three hardware units for the purpose of this latter energy modeling of the TK1 computing hardware, similarly to another study in the literature~\citep{calore2015energy}. The main hardware unit in the early instance was the computing hardware itself, whereas the others were a multimeter and a workstation that interprets the data from the multimeter for subsequent processing by the tool~\citep{seewald2019coarse}.

The tool further interoperates with ROS middleware, generating a measurement layer for configurations of computations implemented in the middleware. It can be imported in an existing project as a library; in C/C++ by simply adding the preprocessor's directive\findex{preprocessor} {\small\tt \#include} with {\small\tt <powprof/async.h>}. In a setting where an energy-expensive ROS node is a computation (we implement both the CNN detection and encryption in \fref{sec:computation-wise}{Section} as ROS nodes), the user simply instances {\small\tt model\_1layer} with a specific computations configuration and calls function {\small\tt start}\findex{function!start@\texttt{start}} to start profiling, and {\small\tt stop}\findex{function!stop@\texttt{stop}} to stop. The latter then returns a measurement layer. The modeling can, in this fashion, happen online by running different computations configurations and generating an appropriate computations energy model corresponding to a realistic run-time computations load.

Alternatively to ROS middleware, the tool runs from a configuration specification, detailing each computation, the constraints sets, and the $\delta$s, along with some other, model-specific details. We discuss such configuration specification in the next section.

\subsection{Configuration specification}
\label{sec:conf-spec}

The configuration specification is simply a way to communicate the plan $\Gamma$ to the \powprof{} tool, along with some other model-specific details. To run \powprof{} with a configuration specification, the user invokes the command {\small\tt powprofile}, followed by the path of the configuration. If, for instance, the configuration specification is stored in {\small\tt config.cfg} in the current directory, the user invokes {\small\tt powprofile config.cfg}. The tool then parses the configuration specification to reconstruct the computations configurations and the constraints sets, to  automatically generate measurement layers and consequently provide a predictive layer. The configuration specification starts with the line {\small\tt [settings]} that indicates to \powprof{} all the following lines are a configuration specification. In the lines that follow, it contains a set of key-value properties delimited by an equal char. The property {\small\tt frequency}\findex{frequency} indicates the frequency measured hertz the tools samples at (e.g., with ten seconds, the property is set as {\small\tt frequency=10}). The property {\small\tt h} is the integration step\findex{integration step} the battery model\findex{battery model} integrates at (we discuss further the battery model in \fref{sec:battery-model}{Section}). The property {\small\tt directory} indicates the path where the models are stored. Additionally, the tool allows an arbitrary number of commands and white spaces, and the parser does not require a specific indentation. Any data followed by char {\small\tt \#} are ignored up to the next line, allowing to write eventual comments.

The following set of lines specifies the configuration $c_i^\sigma$ for each computation parameter $c_{i,\rho+1},c_{i,\rho+2},\dots,c_{i,\rho+\sigma}$, starting with the line {\small\tt [components]}, followed by {\small\tt [component.computation]} where {\small\tt computation} is a string uniquely identifying each computation (there cannot be two computations with the same string, but the name is arbitrary). Per each computation, the configuration file then contains a set of key-values properties. The property {\small\tt src} indicates the executable source of the computation. If \powprof{} runs with a configuration specification rather than a library, we assume the source accepts as arguments the configurations, e.g., $c_{i,\rho+1},\dots$ along with other eventual arguments. The following properties then specify these arguments, ordered as they appear in the configuration specification. The property {\small\tt range} indicates that the argument is a computation parameter. Let us assume the parameter is $c_{i,\rho+1}$. If it is sampled linearly as in \frefeq{eq:meas-layer-lin-sampl}, the value contains $\underline{c}_{i,\rho+1}$, $\overline{c}_{i,\rho+1}$, and $\delta$ delimited by commas, where $\delta$ is the step to sample $c_{i,\rho+1}$ in a reasonable amount of time in \frefeq{eq:meas-layer-lin-sampl}. If it is sampled exponentially as in \frefeq{eq:meas-layer-exp-sampl}, the value contains the same data as before, but for $\delta$ that is expressed {\small\tt pow(}$\delta${\small\tt )} and $\delta$ is the base.
Additional properties are then: {\small\tt fixed} that indicates another eventual argument the computation might have (that is not a computation parameter), and {\small\tt runtime} the value $t_f-t_0$. If {\small\tt runtime} is not specified, the tool assumes $\mathcal{T}=\emptyset$.


%%%%%%%%%%%%%%%%%%%%%%%
\section{Battery Model}
\label{sec:battery-model}

The battery model is an abstraction that predicts how the draining power at future time instants--due to varying computations and motion load--affects the SoC of an aerial robot's battery. Generally, battery SoC is the most important measure for  battery management, yet, it cannot be directly measured~\citep{xia2015state}. There are numerous approaches to formulate its model, and we discuss the most common ones in the literature in \fref{sec:soa-ene-bat}{Section}, including physical, hybrid, empirical, mixed, and abstract models~\citep{rao2003battery}. In this section, we then use the past literature to derive a battery model of an aerial robot's battery. The model that we derive is an abstract model. Such models do not require detailed information about, e.g., battery chemistry; nonetheless, predict accurately future SoC at a relatively low computational complexity compared with complex and exhaustive models, such as physical models~\citep{rao2003battery}.

We detail the equivalent electrical circuit in \fref{sec:batmod-circuit}{Section}; it is the building block of our battery model. We then derive a differential expression to predict future battery SoC in \fref{sec:diff-model}{Section}.


---


\subsection{Equivalent electrical circuit}
\label{sec:batmod-circuit}

Equivalent electrical circuits are abstract models, often referred to as battery equivalent circuit models (\Gls{acr:ecm}s)\findex{equivalent circuit models}. They are common in the literature for battery SoC estimation~\citep{zhang2018online}, and involved in studies relative to Li-ion\findex{Lithium ion batteries} rechargeable battery cells~\citep{hinz2019comparison,hasan2018exogenous}. Although there are very accurate models to predict SoC for these batteries from a given power and time trajectories--namely physical or electrochemical models~\citep{rao2003battery}--for mobile robots and more in general for resource constrained systems it is usually required to balance the models' complexity and the accuracy~\citep{rao2003battery,hasan2018exogenous}. In these constrained systems, ECMs have been widely used in numerous application due to a relatively good modelling accuracy and an easy implementation~\citep{zhang2018online,zhang2012estimation,zhang2009battery,saeed2019electrical,hasan2018exogenous}.
Equivalent electrical circuits use different constructs to model the battery SoC from a number of parameters. These constructs includes RC (resistor-capacitor)\findex{resistor}\findex{capacitor} circuits for dynamic loads\findex{dynamic loads}, resistors for internal resistances\findex{resistance}, and other components~\citep{hamza2017forecasting}. Their complexity depends on the level of detail required and the parameters involved in modeling. The parameters are then usually estimated with empirical data~\citep{zhang2014battery}. 

For what concern the specific battery chemistries to be modeled, we focus on Li-ion batteries. These batteries are broadly employed in many applications involving electric vehicles, mobile, and aerial robots~\citep{shi2006application,xia2015state,hasan2018exogenous,zhang2014battery}, due to their characteristics including low self-discharge rate, absence of memory effect, and high power and energy density~\citep{zhang2014battery}.
Here, we propose a simplistic battery model for the purpose of modeling a Li-ion battery of an aerial robot in flight, focusing on lesser complexity rather than accuracy. The battery SoC changes--when computations and motion generate a current to be drawn from the battery--according to the equation~\citep{zhang2018online,hasan2018exogenous}
\begin{equation}\label{eq:socevol}
  \dot{b}(y(t))=-I(y(t))/Q_c,
\end{equation}
where $Q_c\in\mathbb{R}$ is the battery constant nominal capacity measured in amperes per hour, $I(y(t))\in\mathbb{R}$ is the internal current that we derive later in this section, and $y(t)\in\mathbb{R}_{\geq 0}$ is a power drawn, i.e., the power needed for the computations and the motion. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/circuit-rint.tikz}
  \caption[Equivalent electrical circuit for battery modeling with an internal resistance]{Equivalent electrical circuit for battery modeling with one resistor, representing the internal battery resistance.}
  \label{fig:rint}
\end{figure}
If we use the computations energy model in \fref{sec:comp-ener-model}{Section}, it is the the power metric in \fref{def:comp-ener}{Definition} or the value of the measurement layer in \fref{def:measur-layer}{Definition} for each time step.

We propose a simplistic equivalent electrical circuit with an internal resistance from the literature~\citep{mousavi2014various,hinz2019comparison,he2011evaluation} in \fref{fig:rint}{Figure}. The model is sometimes termed ``Rint'' model in the literature~\citep{hinz2019comparison,he2011evaluation}. The circuit models the battery simply as a perfect voltage source connected with a resistor $R_r\in\mathbb{R}$ measured in ohms, representing the internal battery resistance. The voltage $V\in\mathbb{R}$ measured in volts in the internal battery voltage, which depends on SoC~\citep{hasan2018exogenous} and can be retrieved from a battery data sheet~\citep{hinz2019comparison}, $I$ depends on the power requirements of the load.

The voltage on the extremes of the equivalent electrical circuit respects then 
\begin{equation}\label{eq:tocomb1}
  V_e=V-R_rI,
\end{equation}
where $V_e\in\mathbb{R}$ is the external battery voltage at the extremes of the circuit in \fref{fig:rint}{Figure}.
If we assume that the voltage needed by the computations and motion is stable, let's call it $V_s\in\mathbb{R}$ measured in volts, and that the current required by the load (computations and motion) is $I_l$, we can write
\begin{equation}\label{eq:tocomb2}
  V_sI_l=V_eI,
\end{equation}
using simply Kirchhoff's circuit laws (the power into the load should exactly match the power out). Combining the \frefeqM{eq:tocomb1}{eq:tocomb2}, we obtain the quadratic expression $R_rI^2-VI+V_sI_l=0$, which leads to
\begin{equation}\label{eq:internal_curr}
  I(y(t))=\left(V-\sqrt{V^2-4R_ry(t)}\right)/(2R_r),
\end{equation}
where $I_l:=y(t)/V_s$ the current of the load depends on the computations and motion power $y(t)$ at a given time instant $t$ in \frefeq{eq:socevol}. Furthermore we take the negative solution of the quadratic expression, because when $I_l$ is zero, $I$ should also be zero. 
With the internal current in \frefeq{eq:internal_curr} combined with the battery SoC in \frefeq{eq:socevol} we can model how an computations and motion power trajectory $y(t)$ on a $t\in\mathcal{T}:=[t_0,t_f]$ for given initial and final time instants ($t_0,t_f$ respectively) affects the battery. In one of ours earlier intuitions~\citep{seewald2019coarse}, we expected a constant energy load to result in a better overall SoC compared to, e.g., a spiked load, even if the two loads had the same overall energy. The model above confirms this intuition. In \fref{fig:}{Figure} we show the evolution of $I$ in \frefeq{eq:internal_curr} for a given linear load $I_l$ from zero to approximately one third, and assuming $V=V_s=R_r$ all one. The curve in the plot bend upwards for the plotted range: a line between two points will then always be above the curve, which implies that a constant load is to be preferred compared to a load that repeatedly changes from high to low. 

There are also more complex model in the literature~\citep{hinz2019comparison,hasan2018exogenous} add further elements to e.g., account for the changes in the load current. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/circuit-thevenin.tikz}
  \caption[Thevenin-based equivalent electrical circuit for battery modeling]{Thevenin-based equivalent electrical circuit for battery modeling with one resistor and two RC internal elements. The two elements add some complexity, making the model able to account for changes in the load current.}
  \label{fig:thevenin}
\end{figure}
One of such model that can be often encountered in the literature is the Thevenin model and the Thevenin-based model~\citep{chen2006accurate,hasan2018exogenous,hinz2019comparison,mousavi2014various,zhang2018online,salameh1992mathematical}, sometimes termed dual polarization model~\citep{he2011evaluation}, which we illustrate with the equivalent electrical circuit in \fref{fig:thevenin}{Figure}. This latter allows to model further details, by e.g., modeling the short-term transient behavior with the first RC element, and the long-term transient behavior with the second~\citep{hinz2019comparison}. It is particularly suitable to model the polarization characteristic of Li-ion battery cells~\citep{he2011evaluation}.


\subsection{Battery model in the {\tt powprofiler} tool}
\label{sec:batmod-circuit}

The \powprof{} tool allows automated battery modeling and directly derives battery SoC for each measurement layer that we described in \fref{sec:measurement-layer}{Section}. 
Indeed in \fref{def:measur-layer}{Definition}, the function $\mathbf{g}$ returns a triplet of values including the SoC. 
Similarly, the tool returns the SoC for a given configuration of parameters and energy sensor or other energy measuring device for the predictive layer in \fref{def:comp-ener}{Definition} in \fref{sec:predictive-layer}{Section}. 
To this end, it implements the simplistic equivalent electrical circuit in \fref{fig:rint}{Figure} from the literature~\citep{mousavi2014various,hinz2019comparison,he2011evaluation}. The tool thus implements the class {\small\tt soc\_1resistor}, which constructor accepts in input the parameters $I_l,V,R_r,V_s$ and $Q_c$ that we discussed in \fref{sec:batmod-circuit}{Section}. 
The current load $I_l$ is expressed via the data type {\small\tt pathn}, which we discussed in \fref{sec:powprof}{Section}. One can easily implement a similar battery model, e.g., the Thevenin-based equivalent electrical circuit in \fref{fig:thevenin}{Figure}, by simply inhereting from class {\small\tt first\_derivative} the function {\small\tt get\_value}. 
The function returns the value of the model from an independent variable, i.e., time, and dependent variable represented via the data type {\small\tt vectorn} in \fref{sec:powprof}{Section}. In {\small\tt soc\_1resistor} it is described in \frefeq{eq:socevol}.

Internally, the tool implements numerical simulator based on the Runge-Kutta methods for numerical integration in \fref{sec:rk4}{Section}. One can then personalize the size of the integration step $h\in\mathbb{R}_{>0}$ via the property {\small\tt h} in the configuration specification in \fref{sec:conf-spec}{Section} (a typical practical value of of such property is, e.g., one hundreth). The tool first derive a model for the power and energy and later numerically simulate the battery model via the equivalent electrical circuit in \fref{fig:rint}{Figure} adjoining the battery SoC.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Energy Model of the Motion}

Let us suppose the aerial robot is operating in an autonomous scenario, planning a coverage and scheduling some computations for detections and enctyption in \fref{sec:flight-plan}{Section}. Such a robot expectedly iterates the paths (the primitive paths over time) and schedules the computations periodically, as we outlined in \fref{sec:outline}{Section}. Since the paths and tasks are periodically iterated over time, we expect the energy to evolve similarly. This assumption is further backed by out earlier contributions on the topic~\citep{seewald2020mechanical}, showing that the aerial robot energy can be modeled with a Fourier series of a given order (in our earlier contribution, we used the order three).  We will ease the assumption of the periodic evolution in practice to periodic with disturbance or aperiodic evolutions in \fref{sec:non-perio}{Section}. 
\begin{figure}[h!]
  \begin{subfigure}[b]{0.52\textwidth}
    \centering
    \footnotesize\fontfamily{phv}
    \input{figures/energy_1.tikz}
    \caption{Energy evolution}
    \label{fig:energy-1}
  \end{subfigure}\hspace{2mm}
  \begin{subfigure}[b]{0.46\textwidth}
    \centering
    \footnotesize\fontfamily{phv}
    \input{figures/spectrum_1.tikz}
    \caption{Power spectrum}
    \label{fig:spectrum-1}
  \end{subfigure}
  \caption[Energy data of a fixed-wing aerial robot]{Empirical energy data collected flying a fixed-wing aerial robot's plan and covering the polygon in \fref{fig:plot2}{Figure}. The data shows that the energy signal is periodic over time as the fixed-wing aerial robot reiterates a set of paths.}
\end{figure}
We motivate the choice of a periodic energy model further with some empirical energy data of the Opterra fixed-wing aerial robot flying the agricultural scenario in \fref{fig:energy-1}{Figure} and \fref{fig:spectrum-1}{Figure}.
The data shows the power over time of the motion for the coverage, along its power spectrum. The frequency spectrum in \fref{fig:spectrum-1}{Figure} is centered at zero frequency, and peaks at four hundred kilo decibels. The peak depicts visually the shift on the power-axis in \fref{fig:energy-1}{Figure}. It further backs the choice of the Fourier series of third order in our earlier work~\citep{seewald2020mechanical}, illustrating that the power evolution needs approximately three frequencies to be modeled. To obtain the spectrum in frequency space, we computed the Fourier transform.

In the remainder of this section, we first derive a differential periodic energy model and provide a formal proof in \fref{sec:deriv}{Section}. This model server to model the motion. We enhance the model with the path and computations parameters in \fref{sec:nom-cont}{Section}, to predict the energy consumption of a given configuration of parameters. We explain how we convert the parameters into actual energy consumption in \fref{sec:merging}{Section}, and discuss the model's behavior for aperiodic energy evolutions in \fref{sec:non-perio}{Section}.

\subsection{Derivation of the differential periodic model}
\label{sec:deriv}

In the remainder of this section, we refer to the instantaneous energy consumption evolution simply as the energy signal. We model the energy using energy coefficients $\mathbf{q}\in\mathbb{R}^m$ that characterize such energy signal. The coefficients are derived from Fourier analysis (the size of the energy coefficients vector $m$ is related to the order of the Fourier series in \fref{sec:fourier}{Section}) and estimated using a state estimator in \fref{cp:est}{Chapter}. We prove a relation between the energy signal and the energy coefficients in \fref{lem:eqv}{Lemma}. %Later, we show how this approach allows us variability in terms of different evolutions, including aperiodic signals in \fref{sec:non-perio}{Section}. After illustrating the energy model, we enhance it with the energy contribution of the path and computations in \fref{sec:merging}{Section}. 

Let us consider a periodic energy signal of period $T$, and a Fourier series of an arbitrary order $r\in\mathbb{Z}_{\geq 0}$ for the purpose of modeling of the energy signal
\begin{equation}\label{eq:fourier}
  h(t)=a_0/T+(2/T)\sum_{j=1}^{r}{\left(a_j\cos{\omega jt}+b_j\sin{\omega jt}\right)},
\end{equation}
where $h:\mathbb{R}_{\geq 0}\rightarrow\mathbb{R}$ maps time to the instantaneous energy consumption, $\omega:=2\pi/T$ is the angular frequency, and $a_0,a_j,b_j\in\mathbb{R}$ the Fourier series coefficients $\forall j\in[r]_{>0}$.

The energy signal can be modeled by \frefeq{eq:fourier} and by the output of a linear model
\begin{subequations}\label{eq:state-perf}\begin{align}
  \dot{\mathbf{q}}(t)&=A\mathbf{q}(t)+B\mathbf{u}(t),\\
  y(t)&=C\mathbf{q}(t)\label{eq:state-perf-output},
\end{align}\end{subequations}
where $y(t)\in\mathbb{R}$ is the instantaneous energy consumption. We discuss matrices $A,C,$ and $B$ in \frefeq{eq:mat_A}, \frefeq{eq:mat_C}, and \frefeq{eq:mat_B} respectively.

The state $\mathbf{q}(t)$ contains the energy coefficients
\begin{equation}\label{eq:state-details}
  \mathbf{q}(t)=\left[\begin{array}{cccccc}
    \alpha_0(t) & \alpha_1(t) & \beta_1(t) & \cdots & \alpha_r(t) & \beta_r(t)
  \end{array}\right]',\\
\end{equation}
where $\mathbf{q}(t)\in\mathbb{R}^m$ with $m=2r+1$. The state transition matrix
\begin{equation}\label{eq:mat_A}
  A=\left[\begin{array}{ccccc}
    0            & 0^{1\times 2}& 0^{1\times 2}& \dots& 0^{1\times 2} \\
    0^{2\times 1}& A_1          & 0^{2\times 2}& \dots& 0^{2\times 2} \\
    0^{2\times 1}& 0^{2\times 2}& A_2          & \dots& 0^{2\times 2} \\
    \vdots       & \vdots       & \vdots       &\ddots& \vdots        \\
    0^{2\times 1}& 0^{2\times 2}& 0^{2\times 2}& \dots& A_r 
  \end{array}\right],
\end{equation}
where $A\in\mathbb{R}^{m\times m}$. In matrix $A$, the top left entry is zero, the diagonal entries are $A_1,\dots,A_r$, the remaining entries are zeros. Matrix $0^{i\times j}$ is a zero matrix of $i$ rows and $j$ columns. The submatrices $A_1,A_2,\dots,A_r$ are defined
\begin{equation}
  A_j:=\begin{bmatrix}0 & \omega j \\ -\omega j & 0\end{bmatrix},
\end{equation}
$\forall j\in[r]_{>0}$. The output matrix
\begin{equation}\label{eq:mat_C}
  C=(1/T)\left[\begin{array}{cccccc}
    1 & 1 & 0 &\cdots & 1 & 0
  \end{array}\right],
\end{equation}
where $C\in\mathbb{R}^m$.

The linear model in \frefeq{eq:state-perf} allows us to include the control in the model of \frefeq{eq:fourier} as described in \fref{sec:nom-cont}{Section}. In the remainder we formally proof the equivalence and equality of the models in \frefeq{eq:fourier} and \frefeq{eq:state-perf}.

\begin{highlight}
\begin{lem}[Signal, output equality]\label{lem:eqv}Suppose control $\mathbf{u}$ is a zero vector, matrices $A,C$ are described by \frefeqM{eq:mat_A}{eq:mat_C}, and the initial guess $\mathbf{q}_0$ is 
  \begin{equation*}
  \mathbf{q}_0=\begin{bmatrix}a_0 & a_1/2 & b_1/2 & \cdots & a_r/2 & b_r/2\end{bmatrix}'.
  \end{equation*} 
  Then, the signal $h$ in \frefeq{eq:fourier} is equal to the output $y$ in \frefeq{eq:state-perf}.
\end{lem}
\end{highlight}

\begin{proof}
The proof justifies the choice of the items of the matrices $A,C$ and of the initial guess $\mathbf{q}_0$ in \frefeqM{eq:state-details}{eq:mat_C}. We write these elements such that the coefficients of the series $a_0,\dots,b_r$ are the same as the coefficients of the state $\alpha_0,\dots,\beta_r$.

Let us re-write the Fourier series expression in \frefeq{eq:fourier} in its complex form with the well-known Euler's formula 
\begin{equation}
  e^{it}=\cos{t}+i\sin{t},
\end{equation} 
where $i$ is the imaginary unit.

With $t=\omega jt$, we find the expression for 
\begin{subequations}\begin{align}
  \cos{\omega jt}&=(e^{i\omega jt}+e^{-i\omega jt})/2,\\  
  \sin{\omega jt}&=(e^{i\omega jt}-e^{-i\omega jt})/(2i),
\end{align}\end{subequations}
by substitution of $\sin{\omega jt}$ and $\cos{\omega jt}$ respectively. This leads~\citep{kuo1967automatic}
\begin{equation}\begin{split}\label{eq:proof-complex}
  h(t)=a_0/T+&(1/T)\sum_{j=1}^{r}{e^{i\omega jt}(a_j-ib_j)}+\\&(1/T)\sum_{j=1}^{r}{e^{-i\omega jt}(a_j+ib_j)}.
 \end{split}\end{equation} 

The solution at time $t$ of the model in \frefeq{eq:state-perf} under the assumptions in in the lemma (the control is a zero vector) can be expressed
\begin{equation}
  \mathbf{q}(t)=e^{At}\mathbf{q}_0.
\end{equation}

Both the solution and the system in \frefeq{eq:state-perf} are well-established expressions derived using standard textbooks~\citep{kuo1967automatic, ogata2002modern}. 

To solve the matrix exponential $e^{At}$, we use the eigenvectors matrix decomposition method~\citep{moler2003nineteen}.

The method works on the similarity transformation 
\begin{equation}
  A=VDV^{-1}.
\end{equation}
The power series definition of $e^{At}$ implies~\citep{moler2003nineteen}
\begin{equation}
  e^{At}=Ve^{Dt}V^{-1}.
\end{equation} 

We consider the non-singular matrix $V$, whose columns are eigenvectors of $A$ 
\begin{equation}
  V:=\begin{bmatrix}v_0 & v_1^0 & v_1^1 & \dots & v_r^0 & v_r^1\end{bmatrix}.
\end{equation}

We then consider the diagonal matrix of eigenvalues 
\begin{equation}
  D=\mathrm{diag}{(\lambda_0,\lambda_1^0,\lambda_1^1,\dots,\lambda_r^0,\lambda_r^1)}.
\end{equation}
$\lambda_0$ is the eigenvalue associated to the first item of $A$. $\lambda_j^0,\lambda_j^1$ are the two eigenvalues associated with the block $A_j$. We can write 
\begin{equation}
AV=VD.
\end{equation}

We apply the approach in terms of \frefeq{eq:state-perf} (under the assumptions made in the lemma) 
\begin{equation}
  \dot{\mathbf{q}}(t)=A\mathbf{q}(t).
\end{equation}
The linear combination of the initial guess and the generic solution
\begin{subequations}\begin{align}
  F\mathbf{q}(0)&=\gamma_0 v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j v_j^k}},\\
  F\mathbf{q}(t)&=\gamma_0 e^{\lambda_0 t} v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j e^{\lambda_j t} v_j^k}},\label{eq:proof-comb}
\end{align}\end{subequations}
where 
\begin{equation}
  F=\begin{bmatrix}1 & \cdots & 1\end{bmatrix},
\end{equation} 
$F\in\mathbb{R}^m$ is a column vector of ones. 

Let us consider the expression in \frefeq{eq:proof-comb}. It represents the linear combination of all the coefficients of the state at time $t$. It can also be expressed in the following form
\begin{equation}\label{eq:proof-output}\begin{split}
  F\mathbf{q}(t)/T=\gamma_0 e^{\lambda_0t}v_0/T+&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^0t}v_j^0}+\\&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^1t}v_j^1}.
\end{split}\end{equation}

We prove that the eigenvalues $\mathbf{\lambda}$ and eigenvectors $V$ are such that \frefeq{eq:proof-output} is equivalent to \frefeq{eq:proof-complex}.

The matrix $A$ is a block diagonal matrix, so we can express its determinant as the multiplication of the determinants of its blocks
\begin{equation}
  \det{(A)}=\det{(0)}\det{(A_1)}\det{(A_2)}\cdots\det{(A_r)}.
\end{equation}

We now conclude the proof by computing the first determinant and the others separately.

By computing the first determinant, we prove that the first terms in \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. We find the eigenvalue from $\det(0)=0$, which is $\lambda_0=0$. The corresponding eigenvector can be chosen arbitrarily
\begin{equation}\label{eq:proof-first-det}
  (0-\lambda_0)v_0=\begin{bmatrix} 0 & \cdots & 0 \end{bmatrix},
\end{equation}
$\forall v_0$, thus we choose
\begin{equation}\label{eq:proof-v0}
  v_0=\begin{bmatrix}1 & 0 & \cdots & 0\end{bmatrix}.
\end{equation}
The sizes of the zero vector and of $v_0$ in \frefeqM{eq:proof-first-det}{eq:proof-v0} are both $\mathbb{R}^m$.

We find the value $\gamma_0$ in \frefeq{eq:proof-output} so that the terms are equal 
\begin{equation}
  \gamma_0=\begin{bmatrix}a_0 & 0 & \cdots & 0\end{bmatrix},
\end{equation} 
where $\gamma_0\in\mathbb{R}^m$.

Then, we prove the other determinants. In this way, we prove that all the terms in the sum of both \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. 

By computing the second determinant, we prove that the first terms in both summaries in \frefeq{eq:proof-complex} and \frefeq{eq:proof-output} match. We thus focus on the first block $A_1$, and find the eigenvalues from 
\begin{equation}
  \det(A_1-\lambda I)=0.
\end{equation}
The polynomial $\lambda^2+\omega^2$, gives two complex roots--the two eigenvalues
\begin{subequations}\begin{align}
  \lambda_1^0&=i\omega,\\
  \lambda_1^1&=-i\omega.
\end{align}
\end{subequations}

The eigenvector associated with the eigenvalue $\lambda_1^0$ is 
\begin{equation}
  v_1^0=\begin{bmatrix}0 & -i&1&0&\cdots&0\end{bmatrix}'.  
\end{equation}

The eigenvector associated with the eigenvalue $\lambda_1^1$ is 
\begin{equation}
  v_1^1=\begin{bmatrix}0&i&1&0&\cdots&0\end{bmatrix}'. 
\end{equation}
Both eigenvectors are equally sized $v_1^0,v_1^1\in\mathbb{R}^m$.

Again, we find the values $\gamma_1$ in \frefeq{eq:proof-output} such that the equivalences 
\begin{equation}\begin{cases}    
  e^{i\omega t}(a_1-ib_1)&=\gamma_1 e^{i\omega t}v_1^0\\
  e^{-i\omega t}(a_1+ib_1)&=\gamma_1 e^{i\omega t}v_1^1
\end{cases},\end{equation}
hold. They hold for 
\begin{equation}
  \gamma_1=\begin{bmatrix}0&b_1&a_1&0&\cdots&0\end{bmatrix}.
\end{equation} 

The proof for the remaining $r-1$ blocks is equivalent.

The initial guess $\mathbf{q}_0$ is build such that the sum of the coefficients is the same in both the signals. In the output matrix, the frequency $1/T$ accounts for the period in \frefeq{eq:proof-complex}, \frefeq{eq:proof-output}, and~\frefeq{eq:fourier}. At time instant zero, the coefficients $b_j$ are not present and the coefficients $a_j$ are doubled for each $j=1,2,\dots,r$ (thus we multiply by a half the corresponding coefficients in $\mathbf{q}_0$). To match the outputs $h(t)=y(t)$, or equivalently 
\begin{equation}
  F\mathbf{q}(t)/T=C\mathbf{q}(t), 
\end{equation}
we define 
\begin{equation}
  C:=(1/T)\begin{bmatrix}1 & 1 & 0 & \cdots & 1 & 0\end{bmatrix}.
\end{equation}

We thus conclude that the signal and the output are equal and that the lemma holds.

\end{proof}

We note for practical reasons that the signal would still be periodic with another linear combination of coefficients. For instance
\begin{equation}\label{eq:mat_C_generic}
  C:=d\begin{bmatrix}1 & 1 & 0 & \cdots & 1 & 0\end{bmatrix},
\end{equation} 
equivalent to
\begin{equation}
  C:=d\begin{bmatrix}1 & 0 & 1 & \cdots & 0 & 1\end{bmatrix},
\end{equation} 
or 
\begin{equation}
  C:=d\begin{bmatrix}1 & \cdots & 1\end{bmatrix},
\end{equation} 
for a constant value $d\in\mathbb{R}$.

\subsection{Nominal control}
\label{sec:nom-cont}

Let us suppose that at time instant $t$ the plan in \fref{def:plan}{Definition} reached the $i$th stage $\Gamma_i$ and the control contains the configuration of path and computations parameters 
\begin{equation}\label{eq:state-control2}
  c_i(t)=\begin{bmatrix}c_i^\rho(t) & c_i^\sigma(t)\end{bmatrix}',
\end{equation}
where $c_i(t)\in\mathbb{R}^n$ with $n=\rho+\sigma$ differs from the nominal control $\mathbf{u}(t)$ in \frefeq{eq:state-perf}. We include the control in the nominal control exploiting the following observation. 

\begin{highlight}
  \begin{obs}
    We observe that:
    \begin{itemize}
      \item A change in path parameters affects the energy indirectly. It alters the time when the aerial robot reaches the final point $\mathbf{p}_{\Gamma_l}$, and enters the accepting stage $\Gamma_f$.
      \item A change in computation parameters affects the energy directly. It alters the instantaneous energy consumption as more computations require more power (and vice versa).
    \end{itemize}
  \end{obs}
\end{highlight}

%\begin{figure}[p]
%  \centering
%  \fontfamily{phv}\selectfont
%  \input{figures/plot8.tikz}
%  \caption[Trajectory of the aerial robot flying the highest path configuration]{The trajectory of the aerial robot flying paths $\varphi_1,\varphi_2,\dots,\varphi_l$ from \fref{sec:flight-plan}{Section} with the highest configuration of the path parameter $c_{4,1}=\overline{c}_{4,1}$. This configuration of path parameter has the longest time but the shortest distance between the lines and thus the highest quality of the coverage in \fref{fig:plot2}{Figure}.}
%  \label{fig:plot-8}
%\end{figure}
%\begin{figure}[p]
%  \centering
%  \fontfamily{phv}\selectfont
%  \input{figures/plot9.tikz}
%  \caption[Trajectory of the aerial robot flying the lowest path configuration]{The trajectory of the aerial robot similarly as in \fref{fig:plot-8}{Figure} but with the lowest configuration of the path parameter $c_{4,1}=\underline{c}_{4,1}$. This configuration has the longest distance between the lines and thus the lowest quality of the coverage in \fref{fig:plot2}{Figure}.}
%  \label{fig:plot-9}
%\end{figure}

The second bullet point in the observation is easily verified. The \powprof{} profiling tool models the energy consumption of the heterogeneous computing hardware the mobile robot is caring. A variation in the computation parameter affects the schedule (as the schedule is parametrized by the computation parameter in \fref{def:comp-mot-energy}{Definition}) and hence the instantaneous energy consumption of the mobile robot.

The first bullet point in the observation can be verified by inspection of the example in \fref{sec:flight-plan}{Section}. It is clear that if we decrease the parameter $c_{4,1}$, which is relative to the radius of the circle, the flying time decreses. This is further shown in \fref{fig:zambo1}{Figure} and \fref{fig:zambo2}{Figure}. \fref{fig:zambo1}{Figure} illustrates the trajectory of the aerial robot (composed of all the paths $\varphi_1,\varphi_2\,\dots$) flying at the highest configuration of the path parameter $c_{i,1}=\overline{c}_{4,1}$. \fref{fig:zambo2}{Figure} then illustrate the trajectory flying at the lowest configuration $c_{i,1}=\underline{c}_{4,1}$. The flying time differs significantly, along with the quality of the coverage of the polygon (the agricultural field in \fref{fig:plot2}{Figure}). In \fref{fig:zambo2}{Figure}, the parameter $c_{4,1}$ that alters the radius and center of the upper circle (defined originally in \fref{sec:flight-plan}{Section}) is replanned as, e.g., averse atmospheric conditions do not allow to terminate the original plan in \fref{fig:zambo1}{Figure}.

We use the observation later in \fref{sec:opt-cont-gener}{Section} to check that the time to completely discharge the battery is greater than the flight time and replan the path parameters accordingly.  We replan the computation parameters to maximize the instantaneous energy consumption against the maximum battery discharge rate.

The nominal control is
\begin{equation}\label{eq:state-control}
  \mathbf{u}(t):=\hat{\mathbf{u}}(t)-\hat{\mathbf{u}}(t-\Delta t),
\end{equation}
where $\hat{\mathbf{u}}(t)$ is defined as the energy estimate of a given control sequence at time instant $t$, $\hat{\mathbf{u}}(t-\Delta t)$ at the previous time instant $t-\Delta t$
\begin{equation}\label{eq:estimate-control}
  \hat{\mathbf{u}}(t):=\mathrm{diag}(\nu_i)c_i(t)+\tau_i,
\end{equation}
where $\mathrm{diag}(\nu_i)$ is a diagonal matrix with the parameters
$\nu_{i,j}\in\nu_i,\,\forall j\in[n]_{>0}$.

The input matrix is then
\begin{equation}\label{eq:mat_B}
  B=\begin{bmatrix} 
    0^{1\times\rho} & 1      & \cdots & 1      \\
    0^{1\times\rho} & 0      & \cdots & 0      \\ 
    \vdots          & \vdots & \ddots & \vdots \\
    0^{1\times\rho} & 0      & \cdots & 0      \end{bmatrix},
\end{equation}
where $B\in\mathbb{R}^{m\times n}$ contains zeros except the first row where the first $\rho$ columns are still zeros and the remaining $\sigma$ are ones. 

$\hat{\mathbf{u}}(t)$ is a stage-dependent scale transformation with 
\begin{subequations}\label{eq:scaling}\begin{align}
\nu_i&=\begin{bmatrix}\nu_i^\rho & \nu_i^\sigma\end{bmatrix}',\\ 
\tau_i&=\begin{bmatrix}\tau_i^\rho & \tau_i^\sigma\end{bmatrix}',
\end{align}\end{subequations}
scaling factors. They quantify the contribution to the plan of a given parameter in terms of time for the first $\rho$ parameters, and instantaneous energy consumption for the remaining $\sigma$ (we use the same notation for the path and computation scaling factors as for the parameters). 

The nominal control $\mathbf{u}(t)$ is then the difference of these contributions of two consecutive controls $c_i(t-\Delta t),c_i(t)$ applied to the system. 

$B\mathbf{u}(t)$ merely includes the difference in the instantaneous energy consumption into the model in \frefeq{eq:state-perf}. Matrix $B$ ignores the time contribution of the path parameters in $c_i$. We use them to verify that the flying time is lower than the battery time in \fref{sec:algo}{Section}.

\subsection{Parameters scale transformation}
\label{sec:merging}

%\begin{figure}[h]
%  \centering
%  \input{figures/traj4.tikz}
%  \caption[Path parameter in the flight of an aerial robot]{A path parameter in the flight of an aerial robot can be used to alter the overall energy consumption}
%  \label{fig:tee1}
%\end{figure}
%\begin{figure}[h]
%  \centering
%  \input{figures/traj2.tikz}
%  \caption[Alteration of the path parameter]{The alteration of the path parameter $c_{1,1}$, the radius of the circle.}
%  \label{fig:tee2}
%\end{figure}

%Equation~(\ref{eq:state-control}) accounts for the energy due to the change of parameters $\mathbf{u}_k-\mathbf{u}_{k-1}$. For instance, when the trajectory $\varphi_1$ is a circle (see Figure~\ref{fig:tee1}), a decrement in the trajectory parameter $c_{1,1}$--the radius of the circle--adds a negative contribution. It thus simulates the lowering of instantaneous energy consumption ($\nu_{1,1}c_{1,1}>\nu_{1,1}c_{1,1}^-$) for a given $\nu_{1,1}$, that is then summed to the first coefficient $\alpha_0$ in Equation~(\ref{eq:state-details}), shifting the modeled energy.

To transform the control $c_i(t)$ at $i$th stage and time instant $t$ we use different approaches for the path and computation scaling factors.

The scaling factors for the path parameters from \frefeq{eq:scaling} are derived empirically. For example, we can obtain the scaling factor $\nu_{4,1}$ relative to the alteration $c_{4,1}$ of the upper circle $\varphi_4$ from \fref{sec:flight-plan}{Section} by measuring the time needed to compute the path with the lowest configuration $\underline{c}_{4,1}$, $\underline{t}$ in \fref{fig:zambo2}{Figure}, and the highest $\overline{t}$ in \fref{fig:zambo1}{Figure}. 

The variation of the control hence results in an approximate measure of the plan's time variation with factors
\begin{subequations}\label{eq:scale-traj}\begin{align}
  \nu_{i,j}&=\left((\overline{t}-\underline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})\right)/\rho,\\
  \tau_{i,j}&=\left(\underline{c}_{i,j}(\underline{t}-\overline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})+\underline{t}\right)/\rho,
\end{align}\end{subequations} 
$\forall j\in[\rho]^+$. Moreover, let the factors be zero when the parameters set $c_i^\rho=\{\emptyset\}$. We use the latter to initialize the algorithm in \fref{sec:algo}{Section}.

%Whenever the trajectory parameters are not equally distributed, one can define $(y_{\overline{c}_i}-y_{\underline{c}_i})$ as a the highest (and lowest) levels of specific trajectory parameters. 

The scaling factors for the computations parameters from \frefeq{eq:scaling} are derived using {\small\tt{powprofiler}}, the open-source modeling tool from \fref{sec:powprof}{Section}. We estimate the energy cost of a given schedule (a given computations configuration) with the function $g$ from \fref{def:comp-ener}{Definition}. 
%adapted from earlier work on computational energy analysis~\citep{seewald2019coarse, seewald2019component}, and energy estimation of a fixed-wing UAV~\citep{seewald2020mechanical}. 
%For this purpose, we assume the mobile robot carries an embedded board that runs the computations. Our
%In both cases, with ROS~\citep{zamanakos2020energy} or with generic software components system~\citep{seewald2019component}, the tool performs automatic modeling. 
For instance, if the computation is the CNN ROS node, the computation parameter $c_{1,2}$ corresponds to the \Gls{acr:fps} rate. The tool then measures power according to the detection frequency.

The scaling factors add the computational energy component to the model in \frefeq{eq:state-perf}. They are derived similarly to \frefeq{eq:scale-traj}
\begin{subequations}\label{eq:scale-comp}\begin{align}
  \nu_{i,j}&=(g(\overline{c}_{i,j})-g(\underline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j}),\\
  \tau_{i,j}&=\underline{c}_{i,j}(g(\underline{c}_{i,j})-g(\overline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j})+g(\underline{c}_{i,j}),
\end{align}\end{subequations}
$\forall j\in[\rho+1,n]$. Moreover, let the factors be zero when the parameters set $c_i^\sigma=\{\emptyset\}$.

The concept of a path and a computation parameter scale transformation is illustrated in \fref{fig:plot-6}{Figure}. 
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/plot6.tikz}
  \caption[Concept of a path and computation parameter scale transformation]{The concept of a path and computation parameter scale transformation. Without any battery constraints, the dynamic energy planning selects the highest configuration which respects the control constraint (inner rectangle) from \frefeq{eq:constraint-set}.}
  \label{fig:plot-6}
\end{figure}
The energy domain is bounded by the output of \powprof{}, while the flight time domain by the empirical data. The dynamic energy planning selects the highest possible configuration under the constraints. Currently, the highest configuration of parameters corresponds to the highest configuration of parameters $(\overline{c}_{i,1},\overline{c}_{i,2})$ (blue point in the figure). We will show in \fref{sec:output-mpc}{Section} the optimal control derivation over a time horizon $N$ under given battery constraints.
\begin{figure}[h]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/plot7.tikz}
  \caption[.]{.}
  \label{fig:plot-7}
\end{figure}
%todo explain a bit plot7 

\subsection{\color{red}Aperiodic energy evolution}
\label{sec:non-perio}


%%%%%%%%%%%%%%%%%
\section{\color{red}Results}


%%%%%%%%%%%%%%%%%
\section{\color{red}Summary}

