%%%%%%%%%%%%%%%%%%%
%                 %
% Energy Models   %
%                 %
\chapter{Energy Models}
\label{cp:model}

\begin{highlight}
    \begin{st}
        Started filling the model from~\citep{seewald202Xenergy} (\fref{cp:model:periodic:diff-model}{Subsection}), rest is dummy text.
    \end{st} 
\end{highlight}

\lettrine{A}{a}


\section{Models Classification}


\section{Energy Model of the Computations}

\subsection{Computational energy of the UAV}

\subsection{Measurement layer}

\subsection{Hardware platforms and benchmarks}

\subsection{Power measurements for embedded boards}

\subsection{The {\tt powprofiler} tool}

\subsection{Energy-aware design of algorithms}

\subsection{ROS middleware}

\subsection{Experimental methodology}


\section{Battery Model}

\subsection{UAV batteries}

\subsection{Derivation of differential battery model}


\section{Energy Model of the Motion}

\subsection{Mechanical energy of the UAV}

\subsection{Experimental methodology}


\section{Periodic Energy Model}

\subsection{Furier series of empirical data}

\subsection{Derivation of differential periodic model}
\label{cp:model:periodic:diff-model}

We refer to the instantaneous energy consumption evolution simply as the energy signal. We model the energy using energy coefficients $\mathbf{q}\in\mathbb{R}^m$ that characterize such energy signal. The coefficients are derived from Fourier analysis (the size of the energy coefficients vector $m$ is related to the order of a Fourier series) and estimated using a state estimator. 

We prove a relation between the energy signal and the energy coefficients in \fref{lem:eqv}{Lemma}. We show after the main results how this approach allows us variability in terms of non-periodic signals.

After having illustrated the energy model, we enhance it with the energy contribution of the path in and of the computations in \fref{cp:model:periodic:merging}{Subsection}. 

Let us consider a periodic energy signal of period $T$, and a Fourier series of an arbitrary order $r\in\mathbb{Z}_{\geq 0}$ for the purpose of modeling of the energy signal
\begin{equation}\label{eq:fourier}
  h(t)=a_0/T+(2/T)\sum_{j=1}^{r}{\left(a_j\cos{\omega jt}+b_j\sin{\omega jt}\right)},
\end{equation}
where $h:\mathbb{R}_{\geq 0}\rightarrow\mathbb{R}$ maps time to the instantaneous energy consumption, $\omega:=2\pi/T$ is the angular frequency, and $a,b\in\mathbb{R}$ the Fourier series coefficients.

The energy signal can be modeled by \frefeq{eq:fourier} and by the output of a linear model
\begin{subequations}\label{eq:state-perf}\begin{align}
  \dot{\mathbf{q}}(t)&=A\mathbf{q}(t)+B\mathbf{u}(t),\\
  y(t)&=C\mathbf{q}(t),
\end{align}\end{subequations}
where $y(t)\in\mathbb{R}$ is the instantaneous energy consumption. 

The state $\mathbf{q}(t)$ contains the energy coefficients
\begin{equation}\label{eq:state-details}
  \mathbf{q}(t)=\left[\begin{array}{cccccc}
    \alpha_0(t) & \alpha_1(t) & \beta_1(t) & \cdots & \alpha_r(t) & \beta_r(t)
  \end{array}\right]^T,\\
\end{equation}
where $\mathbf{q}(t)\in\mathbb{R}^m$ with $m=2r+1$. The state transition matrix
\begin{equation}
  A=\left[\begin{array}{ccccc}
    0            & 0^{1\times 2}& 0^{1\times 2}& \dots& 0^{1\times 2} \\
    0^{2\times 1}& A_1          & 0^{2\times 2}& \dots& 0^{2\times 2} \\
    0^{2\times 1}& 0^{2\times 2}& A_2          & \dots& 0^{2\times 2} \\
    \vdots       & \vdots       & \vdots       &\ddots& \vdots        \\
    0^{2\times 1}& 0^{2\times 2}& 0^{2\times 2}& \dots& A_r 
  \end{array}\right],
\end{equation}
where $A\in\mathbb{R}^{m\times m}$. In matrix $A$, the top left entry is zero, the diagonal entries are $A_1,\dots,A_r$, the remaining entries are zeros. Matrix $0^{i\times j}$ is a zero matrix of $i$ rows and $j$ columns. The submatrices $A_1,A_2,\dots,A_r$ are defined
\begin{equation}
  A_j:=\begin{bmatrix}0 & \omega j \\ -\omega j & 0\end{bmatrix},
\end{equation}
The output matrix
\begin{equation}
  C=(1/T)\left[\begin{array}{cccccc}
    1 & 1 & 0 &\cdots & 1 & 0
  \end{array}\right],
\end{equation}
where $C\in\mathbb{R}^m$.

The linear model in \frefeq{eq:state-perf} allows us to include the control in the model of \frefeq{eq:fourier}.

\begin{highlight}
\begin{lem}[Signal, output equality]\label{lem:eqv}Suppose control $\mathbf{u}$ is a zero vector, matrices $A,C$ are described by \frefeq{eq:state-details}, and the initial guess $\mathbf{q}_0$ is 
  \begin{equation*}
  \mathbf{q}_0=\begin{bmatrix}a_0 & a_1/2 & b_1/2 & \cdots & a_r/2 & b_r/2\end{bmatrix}^T.
  \end{equation*} 
  Then, the signal $h$ in \frefeq{eq:fourier} is equal to the output $y$ in \frefeq{eq:state-perf}.
\end{lem}
\end{highlight}

\begin{proof}
We propose a formal proof of the lemma. The proof justifies the choice of the items of the matrices $A,C$ and of the initial guess $\mathbf{q}_0$ in \frefeq{eq:state-details}. We write these elements such that the coefficients of the series $a_0,\dots,b_r$ are the same as the coefficients of the state $\alpha_0,\dots,\beta_r$.

Let us re-write the Fourier series expression in \frefeq{eq:fourier} in its complex form with the well-known Euler's formula 
\begin{equation}
  e^{it}=\cos{t}+i\sin{t}.
\end{equation} 

With $t=\omega jt$, we find the expression for 
\begin{subequations}\begin{align}
  \cos{\omega jt}&=(e^{i\omega jt}+e^{-i\omega jt})/2\\  
  \sin{\omega jt}&=(e^{i\omega jt}-e^{-i\omega jt})/(2i)
\end{align}\end{subequations}
by substitution of $\sin{\omega jt}$ and $\cos{\omega jt}$ respectively. This leads~\cite{kuo1967automatic}
\begin{equation}\begin{split}\label{eq:proof-complex}
  h(t)=a_0/T+&(1/T)\sum_{j=1}^{r}{e^{i\omega jt}(a_j-ib_j)}+\\&(1/T)\sum_{j=1}^{r}{e^{-i\omega jt}(a_j+ib_j)},
 \end{split}\end{equation}
where $i$ is the imaginary unit. 

The solution at time $t$ can be expressed
\begin{equation}
  \mathbf{q}(t)=e^{At}\mathbf{q}_0.
\end{equation}
Both the solution and the system in \frefeq{eq:state-perf} are well established expressions derived using standard textbooks~\cite{kuo1967automatic, ogata2002modern}. To solve the matrix exponential $e^{At}$, we use the eigenvectors matrix decomposition method~\cite{moler2003nineteen}.

The method works on the similarity transformation 
\begin{equation}
  A=VDV^{-1}.
\end{equation}
The power series definition of $e^{At}$ implies~\cite{moler2003nineteen}
\begin{equation}
  e^{At}=Ve^{Dt}V^{-1}.
\end{equation} 

We consider the non-singular matrix $V$, whose columns are eigenvectors of $A$ 
\begin{equation}
  V:=\begin{bmatrix}v_0 & v_1^0 & v_1^1 & \dots & v_r^0 & v_r^1\end{bmatrix}.
\end{equation}

We then consider the diagonal matrix of eigenvalues 
\begin{equation}
  D=\mathrm{diag}{(\lambda_0,\lambda_1^0,\lambda_1^1,\dots,\lambda_r^0,\lambda_r^1)}.
\end{equation}
$\lambda_0$ is the eigenvalue associated to the first item of $A$. $\lambda_j^0,\lambda_j^1$ are the two eigenvalues associated with the block $A_j$. We can write 
\begin{equation}
  Av_j=\lambda_jv_j\,\,\,\forall j=\{1,\dots,m\}, 
\end{equation}
and 
\begin{equation}
AV=VD.
\end{equation}

We apply the approach in terms of \frefeq{eq:state-perf}, under the assumptions made in the lemma (the control is a zero vector) 
\begin{equation}
  \dot{\mathbf{q}}(t)=A\mathbf{q}(t).
\end{equation}
The linear combination of the initial guess and the generic solution
\begin{subequations}\label{eq:proof-comb}\begin{align}
  F\mathbf{q}(0)&=\gamma_0 v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j v_j^k}},\\
  F\mathbf{q}(t)&=\gamma_0 e^{\lambda_0 t} v_0+\sum_{k=0}^{1}{\sum_{j=1}^{r}{\gamma_j e^{\lambda_j t} v_j^k}},
\end{align}\end{subequations}
where 
\begin{equation}
  F=\begin{bmatrix}1 & \cdots & 1\end{bmatrix}
\end{equation} 
is a $F\in\mathbb{R}^m$ column vector of ones. 

Let us consider the second expression in \frefeq{eq:proof-comb}. It represents the linear combination of all the coefficients of the state at time $t$. It can also be expressed in the following form
\begin{equation}\label{eq:proof-output}\begin{split}
  F\mathbf{q}(t)/T=\gamma_0 e^{\lambda_0t}v_0/T+&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^0t}v_j^0}+\\&(1/T)\sum_{j=1}^r{\gamma_j e^{\lambda_j^1t}v_j^1}.
\end{split}\end{equation}

We proof that the eigenvalues $\mathbf{\lambda}$ and eigenvectors $V$ are such that \frefeq{eq:proof-output} is equivalent to \frefeq{eq:proof-complex}.

The matrix $A$ is a block diagonal matrix, so we can express its determinant as the multiplication of the determinants of its blocks
\begin{equation}
  \det{(A)}=\det{(0)}\det{(A_1)}\det{(A_2)}\cdots\det{(A_r)}.
\end{equation}
We proof the first determinant and the others separately.

Thereby we start by proofing that the first terms of the \frefeqM{eq:proof-complex}{eq:proof-output} match. We find the eigenvalue from $\det(0)=0$, which is $\lambda_0=0$. The corresponding eigenvector can be chosen arbitrarily
\begin{equation}
  (0-\lambda_0)v_0=\begin{bmatrix} 0 & \cdots & 0 \end{bmatrix},
\end{equation}
$\forall v_0$, thus we choose
\begin{equation}
  v_0=\begin{bmatrix}1 & 0 & \cdots & 0\end{bmatrix}.
\end{equation} 
We find the value $\gamma_0$ of the vector $\gamma$ so that the terms are equal 
\begin{equation}
  \gamma_0=\begin{bmatrix}a_0 & 0 & \cdots & 0\end{bmatrix}.
\end{equation} 

Then, we proof that all the terms in the sum of both the \frefeqM{eq:proof-complex}{eq:proof-output} match. 

For the first block $A_1$, we find the eigenvalues from 
\begin{equation}
  \det(A_1-\lambda I)=0.
\end{equation}
The polynomial $\lambda^2+\omega^2$, gives two complex roots--the two eigenvalues
\begin{subequations}\begin{align}
  \lambda_1^0&=i\omega,\\
  \lambda_1^1&=-i\omega.
\end{align}
\end{subequations}

The eigenvector associated with the eigenvalue $\lambda_1^0$ is 
\begin{equation}
  v_1^0=\begin{bmatrix}0 & -i&1&0&\cdots&0\end{bmatrix}^T.  
\end{equation}

The eigenvector associated with the eigenvalue $\lambda_1^1$ is 
\begin{equation}
  v_1^1=\begin{bmatrix}0&i&1&0&\cdots&0\end{bmatrix}^T. 
\end{equation}
Again, we find the values $\gamma_1$ of the vector $\gamma$ such that the equivalences 
\begin{equation}\begin{cases}    
  e^{i\omega t}(a_1-ib_1)&=\gamma_1 e^{i\omega t}v_1^0\\
  e^{-i\omega t}(a_1+ib_1)&=\gamma_1 e^{i\omega t}v_1^1
\end{cases}\end{equation}
hold. They hold for 
\begin{equation}
  \gamma_1=\begin{bmatrix}b_1&a_1\end{bmatrix}.
\end{equation} 

The proof for the remaining $r-1$ blocks is equivalent.

The initial guess is build such that the sum of the coefficients is the same in both the signals. In the output matrix, the frequency $1/T$ accounts for the period in \frefeqM{eq:proof-complex}{eq:proof-output} and~\frefeq{eq:fourier}. At time instant zero, the coefficients $b_j$ are not present and the coefficients $a_j$ are doubled for each $j=1,2,\dots,r$ (thus we multiply by a half the corresponding coefficients in $\mathbf{q}_0$). To match the outputs $h(t)=y(t)$, or equivalently 
\begin{equation}
  F\mathbf{q}(t)/T=C\mathbf{q}(t), 
\end{equation}
we define 
\begin{equation}
  C:=(1/T)\begin{bmatrix}1 & 1 & 0 & \cdots & 1 & 0\end{bmatrix}.
\end{equation}

We thus conclude that the signal and the output are equal, hence the lemma holds.

\end{proof}

We note for practical reasons that the signal would still be periodic with another linear combination of coefficients. For instance, 
\begin{equation}
  C:=d\begin{bmatrix}1 & 0 & 1 & \cdots & 0 & 1\end{bmatrix},
\end{equation} 
or 
\begin{equation}
  C:=d\begin{bmatrix}1 & \cdots & 1\end{bmatrix},
\end{equation} 
for a constant value $d\in\mathbb{R}$.

\subsection{Derivation of the nominal control}

Let us suppose that at time instant $t$ the plan reached the $i$-th stage $\Gamma_i$ and the control
\begin{equation}\label{eq:state-control2}
  \mathbf{c}_i(t)=\begin{bmatrix}c_i^\rho(t) & c_i^\sigma(t)\end{bmatrix}^T,
\end{equation}
where $\mathbf{c}_i(t)\in\mathbb{R}^n$ with $n:=\rho+\sigma$ differs from the nominal control $\mathbf{u}(t)$ in \frefeq{eq:state-perf}. We include the control in the nominal control exploiting the following observation. 

\begin{highlight}
  \begin{obs}
    We observe that:
    \begin{itemize}
      \item A change in path parameters affects the energy indirectly. It alters the time when the UAV reaches the final point $\mathbf{p}_{\Gamma_l}$.
      \item A change in computation parameters affects the energy directly. It alters the instantaneous energy consumption as more computations require more power (and vice versa).
    \end{itemize}
  \end{obs}
\end{highlight}


We use this information later in the algorithm to check that the battery discharge time is greater and replan the path parameters accordingly.  We replan the computation parameters to maximize the instantaneous energy consumption against the maximum battery discharge rate.

The nominal control is
\begin{equation}\label{eq:state-control}
  \mathbf{u}(t):=\hat{\mathbf{u}}(t)-\hat{\mathbf{u}}(t-1),
\end{equation}
where $\hat{\mathbf{u}}(t)$ is defined as the energy estimate of a given control sequence at time instant $t$, $\hat{\mathbf{u}}(t-1)$ at the previous time instant $t-1$
\begin{equation}
  \hat{\mathbf{u}}(t):=\mathrm{diag}(\nu_i)\mathbf{c}_i(t)+\tau_i.
\end{equation}

The input matrix is then
\begin{equation}
  B=\begin{bmatrix} 
    0^{1\times\rho} & 1      & \cdots & 1      \\
    0^{1\times\rho} & 0      & \cdots & 0      \\ 
    \vdots          & \vdots & \ddots & \vdots \\
    0^{1\times\rho} & 0      & \cdots & 0      \end{bmatrix},
\end{equation}
where $B\in\mathbb{R}^{m\times n}$ contains zeros except the first row where the first $\rho$ columns are still zeros and the remaining $\sigma$ are ones. 

$\hat{\mathbf{u}}(t)$ is a stage-dependent scale transformation with 
\begin{subequations}\begin{align}
\nu_i&=\begin{bmatrix}\nu_i^\rho & \nu_i^\sigma\end{bmatrix}^T,\\ 
\tau_i&=\begin{bmatrix}\tau_i^\rho & \tau_i^\sigma\end{bmatrix}^T,
\end{align}\end{subequations}
scaling factors quantifying the contribution to the plan of a given parameter in terms of time for the first $\rho$ parameters, and power for the remaining $\sigma$ (we use the same notation for the path and computation scaling factors as for the parameters). 

The nominal control $\mathbf{u}(t)$ is then the difference of these contributions of two consecutive controls $\mathbf{u}(t-1),\mathbf{u}(t)$ applied to the system. 

$B\mathbf{u}(t)$ merely includes the difference in power into the model in \frefeq{eq:state-perf}.

\subsection{Merging computations and motion}
\label{cp:model:periodic:merging}

\begin{figure}[h]
  \centering
  \input{figures/traj2.tikz}
  \caption{The alteration of the path parameter $c_{1,1}$, the radius of the circle (it corresponds to the alteration of the plan in Figure~\ref{fig:il-abs}).}
  \label{fig:tee1}
\end{figure}

%Equation~(\ref{eq:state-control}) accounts for the energy due to the change of parameters $\mathbf{u}_k-\mathbf{u}_{k-1}$. For instance, when the trajectory $\varphi_1$ is a circle (see Figure~\ref{fig:tee1}), a decrement in the trajectory parameter $c_{1,1}$--the radius of the circle--adds a negative contribution. It thus simulates the lowering of instantaneous energy consumption ($\nu_{1,1}c_{1,1}>\nu_{1,1}c_{1,1}^-$) for a given $\nu_{1,1}$, that is then summed to the first coefficient $\alpha_0$ in Equation~(\ref{eq:state-details}), shifting the modeled energy.

The set
\begin{equation}\label{eq:area}
  \mathcal{P}_i:=\{\mathbf{p}_k\mid\varphi_i(\mathbf{p}_k,c_{i}^\rho)\in\mathcal{C}_i\},
\end{equation}
delimits the area where the $i$-th path $\varphi_i$ is free to evolve using the path parameters $c_i^\rho$ (the gray area in Figure~\ref{fig:tee1}). $\varphi_i$ is a function of the two coordinates and the path parameters, and is equal to zero when a point $\mathbf{p}_k$ is on the path. Physically, this means the UAV is flying exactly over the nominal trajectory. The path parameters allows to change the path. They are a way to alter the nominal trajectory in the initial plan and thus alter the energy by changing the flying time in the example in Figure~\ref{fig:il-abs}.
In fact, the algorithm uses the set from Equation~(\ref{eq:area}) to find the path parameters such that the plan consisting of flying $\varphi_i$ has the highest energy, while still respecting the constraints. In Figure~\ref{fig:tee1}, the parameter radius of the circle $c_{1,1}$ is replanned as, e.g., averse atmospheric conditions do not allow to terminate the plan.

We derive the new position $\mathbf{p}_{k+1}$ computing the vector field $\nabla\varphi_i:=\begin{bmatrix}\partial\varphi_i/\partial x & \partial\varphi_i/\partial y\end{bmatrix}^T$, and the direction to follow in the form of velocity vector~\cite{de2017guidance}
\begin{equation}\label{eq:pd}
  \dot{\mathbf{p}}_d(\mathbf{p}_k):=E\nabla\varphi_i-k_e\varphi_i\nabla\varphi_i,\,\,\,E=\begin{bmatrix}
    0&1\\-1&0
  \end{bmatrix},
\end{equation}
where $E$ specifies the rotation (it influence the tracking direction), and $k_e\in\mathbb{R}_{\geq 0}$ the gain to adjusts the speed of convergence. The direction the velocity vector $\dot{\mathbf{p}}_d$ is pointing at is generally different from the course heading $\dot{\mathbf{p}}$ due to the atmospheric interferences (wind $w\in\mathbb{R}$ in the top of Figure~\ref{fig:tee1}).

The scaling factors for the path parameters from Equation~(\ref{eq:state-control}) are derived empirically. For the example in Figure~\ref{fig:tee1}, we can obtain the scaling factor $\nu_{1,1}$ measuring the time needed to compute the path with the lowest configuration $\underline{c}_1$, $\underline{t}$ and the highest $\overline{t}$. The variation of the control hence results in an approximate measure of the plans' time variation with factors
\begin{equation}\label{eq:scale-traj}\begin{split}
  \nu_{i,j}&=\left((\overline{t}-\underline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})\right)/\rho,\\
  \tau_{i,j}&=\left(\underline{c}_{i,j}(\underline{t}-\overline{t})/(\overline{c}_{i,j}-\underline{c}_{i,j})+\underline{t}\right)/\rho,
\end{split}\end{equation} 
%Whenever the trajectory parameters are not equally distributed, one can define $(y_{\overline{c}_i}-y_{\underline{c}_i})$ as a the highest (and lowest) levels of specific trajectory parameters. 
$\forall j\in[\rho]^+$. Moreover, let the factors be zero when the parameters set $c_i^\rho=\{\emptyset\}$.

Let us recall from Definition~\ref{def:mission} that the $i$-th stage $\Gamma_i$ of the plan $\Gamma$ contains the computation parameters which characterize the computations. We estimate the energy cost of these computations using {\small\tt{powprofiler}}, the open-source modeling tool adapted from earlier work on computational energy analysis~\cite{seewald2019coarse, seewald2019component}, and energy estimation of a fixed-wing UAV~\cite{seewald2020mechanical}. 

For this purpose, we assume the UAV carries an embedded board that runs the computations. Our tool measures the instantaneous energy consumption of a subset of possible computation parameters within the computation constraint sets and builds an energy model: a linear interpolation, one per each computation. 

The computations are implemented by software components, e.g., Robot Operating System (ROS) nodes in a ROS-based system~\cite{quigley2009ros}. The user implements these nodes such that they change the computational load according to node-specific ROS parameters--the computation parameters. In a generic software component system, the user maps the computational load to the arguments~\cite{seewald2019component}. In both cases, with ROS~\cite{zamanakos2020energy} or with generic software components system~\cite{seewald2019component}, the tool performs automatic modeling. For instance, if the computation is an object detector, a computation parameter $c_{1,2}$ might correspond to frames-per-second (fps) rate. The tool then measures power according to the detection frequency.

We note that while the path can differ for each stage, the tasks remain the same. However, the user can inhibit or enable a computation varying its computation constraint set.

Let us define $g:\mathbb{Z}_{\geq 0}\rightarrow\mathbb{R}_{\geq 0}$ as the instantaneous computational energy consumption value obtained using the tool.

The scaling factors add the computational energy component to the model in Equation~(\ref{eq:state-perf}). They are derived similarly to Equation~(\ref{eq:scale-traj})
\begin{subequations}\begin{align}
  \nu_{i,j}&=(g(\overline{c}_{i,j})-g(\underline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j}),\\
  \tau_{i,j}&=\underline{c}_{i,j}(g(\underline{c}_{i,j})-g(\overline{c}_{i,j}))/(\overline{c}_{i,j}-\underline{c}_{i,j})+g(\underline{c}_{i,j}),
\end{align}\end{subequations}
$\forall j\in[\rho+1,\rho+\sigma]$. Moreover, let the factors be zero when the parameters set $c_i^\sigma=\{\emptyset\}$.



\section{Results}


\section{Summary}

