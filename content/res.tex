
%
%%%%%%%%%%%%%
%           %
% Results   %
%           %
%%%%%%%%%%%%%
%
% Brief abstract: wraps up the results from the previous chapters
%
% Completion (1-10): 1
% Missing: -
%
\chapter{Results}
\label{cp:res}

\begin{chapquote}{\cite{sudhakar2020balancing}}
  ``[Computing energy included motion planning] shows improved performance over the baseline and looks to be promising solution to the low-power motion planning problem.''
\end{chapquote}

\vspace*{1em}

\lettrine{I}{n this chapter}, we report some results both published in our early studies~\citep{seewald2019hlpgpu,seewald2019coarse,seewald2019component,seewald2020mechanical,zamanakos2020energy} and to appear in a forthcoming study~\citep{seewald202Xenergy}, validating our overall approach towards energy-aware dynamic planning and scheduling for autonomous aerial robots. The chapter thus connects to the remainder of the work by describing our experimental setup and results. We describe the latter for \fref{cp:model}{Chapters} and \fref{cp:dyn}{}, which contains our most notable contribution: the energy models for both the computation and motion of an aerial robot and a coverage planning and scheduling technique that uses the models. \fref{cp:pb}{Chapter} is limitedly involved as well: we extensively use the agricultural scenario we introduced in \fref{sec:flight-plan}{Section} to showcase our approach, along with other formalities we proposed in the chapter.

The remainder of this chapter is structured as follows. In \fref{sec:res-ene-comps}{Section}, we describe our experimental setup and results for the computations energy model obtained with the \powprof{} tool from \fref{sec:powprof}{Section}. We then detail similarly the energy of the motion of an aerial robot flying a path similar to \fref{sec:flight-plan}{Section} independently and along with the computing hardware in \fref{sec:res-ene-mot}{Section}. In both \fref{sec:res-ene-comps}{Sections}\fref{sec:res-ene-mot}{--\hspace*{-.8ex}}, we describe our experimental setup for a batter of the computing hardware, aerial robot, and computing hardware with the aerial robot, detailing for each the results. In \fref{sec:res-dyn}{Section}, we then describe the coverage planning and scheduling in \matlab and Paparazzi autopilots and thus, validate our work experimentally.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computations Energy Modeling}
\label{sec:res-ene-comps}

In this section, we describe the experimental setup to obtain computations energy models with the \powprof{} tool. We report how we derive both the measurement and predictive layers from \fref{sec:measurement-layer}{Sections}\fref{sec:predictive-layer}{--\hspace*{-.8ex}} and the battery models from \fref{sec:battery-model}{Section} to integrate the two layers with the energy contribution of a battery for the computing hardware.

\subsection{The {\tt darknet-gpu} computation}\findex{computations!darknet-gpu@\texttt{darknet-gpu}}

In \fref{fig:darknet-layer1}{Figure}, we illustrate a concrete example of four different measurement layers from our early contribution~\citep{seewald2019coarse}: the power evolution in the function of time for three measuring devices, CPU, GPU, and overall of the NVIDIA Jetson TX2 board\findex{NVIDIA Jetson!TX2}. 
\begin{figure}[h!]
  \begin{minipage}{.93\textwidth}
  \centering
  \fontfamily{phv}\selectfont
  \hspace*{20ex}
  \input{figures/darknet-layer1.tikz}
  \end{minipage}
  \caption[The \stt{darknet-gpu} computation measurement layer models]{The \stt{darknet-gpu} computation measurement layer models, featuring the GPU implementation of the YOLO~\citep{redmon2016you} deep neural network library modified to introduce delays between detections. From top left in horizontal order to bottom right, the figure shows the schedules from approximately six up to thirty-two FPS.
  }
  \label{fig:darknet-layer1}
\end{figure}
The model is relative to one computation with four different schedules where we observed notable differences in instantaneous and overall energies. The computation consists of an object detection algorithm that we term darknet-gpu, a neural network-based pattern recognition utility. It is a standard computer vision computation, built upon the darknet~\citep{redmond2017yolo,redomnd2013darknet}\findex{darknet} GPU implementation of a deep neural network library termed YOLO~\citep{redmon2016you}\findex{YOLO}. The library detects the objects on some pre-trained networks, as well as with a  trained network to detect a personalized set of objects.

In an initial iteration of our work~\citep{teamplayd43}, we trained the network for a search and rescue aerial robot that detects vessels on the sea, using images of different shapes and colors. We benchmarked the corresponding computation on a video stream of vessels in an offshore area, simulating an aerial robot flying the scenario with a camera. We further modified the {\small\tt darknet-gpu} computation to simulate different scheduling options, such that the computation can be altered with a given parameter, which we call $c_{i,1}$ in accordance to \fref{def:stage}{Definition} $\forall\,i\in[l]$  (with the plan lasting assigned $l$ stages). The parameter indicates the delay between two invocations of the detection, simulating different frames per second (\Gls{acr:fps}) rates. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/darknet-layer2.tikz}
  \caption[Per-minute energy consumption and SoC of the \stt{darknet-gpu} computation]{Per-minute energy consumption and SoC of the \stt{darknet-gpu} computation in terms of CPU, GPU, and overall energies. On the right is the resulting predictive layer that shows the energy and battery SoC in the function of any possible configuration.}
  \label{fig:darknet-layer2}
\end{figure}
We schedule the computation with the parameter $c_{i,1}$ to assess the energy evolution in the predictive layer in \fref{fig:darknet-layer2}{Figure}. On the right of the figure, we further illustrate the battery state of charge (\Gls{acr:soc}) in the function of varying FPS for the overall power measuring device of the TX2 board (dashed line). Similarly, the predictive layer provides the evolution of the energy also in the function of varying FPS (continuous line).

We used a frequency of ten hertz and a running time of one minute to derive all the measurement layers. The energy measure in \fref{fig:darknet-layer2}{Figure} is then relative to the energy needed to run the computation for a minute and the correspondent remaining SoC. For the latter, we used an integration step of one hundredth, internal battery voltage $V$ of 14.8 volts, internal resistance $R_r$ of 1.2 milliohms, stabilized voltage $V_s$ of twelve volts, and battery capacity $Q_c$ of five amperes per hour in \frefeqM{eq:socevol}{eq:internal_curr} in \fref{sec:batmod-circuit}{Section}. The parameters that correspond to such configurations are {\small\tt frequency=10}, {\small\tt frequency=0.01}, and {\small\tt runtime=60000} in the specification in \fref{sec:conf-spec}{Section}, whereas the battery values are specified while invoking the constructor of the {\small\tt soc\_1resistor} class. Both \fref{fig:darknet-layer1}{Figures}\fref{fig:darknet-layer2}{--\hspace*{-.8ex}} show the parameter $c_{i,1}$ within $\mathcal{S}_{i,1}$ constructed so that the resulting FPS is between 5.8 and thirty-two.

---


\subsection{The {\tt matrix-gpu} computation}\findex{computations!matrix-gpu@\texttt{matrix-gpu}}

We then derived a set of measurement layers and the predictive layers of another computations that we call {\small\tt matrix-gpu}, also related to our early contribution~\citep{seewald2019coarse}. 
We use the NVIDIA Jetson TX2 computing hardware as with the {\small\tt darknet-gpu} where we utilize the overall power measuring device (the computing hardware supports measuring the power of CPU and GPU separately, as well as overall power; see \fref{fig:darknet-layer1}{Figure} or further information in \fref{sec:model-hete-elem}{Section}). 
{\small\tt matrix-gpu} computes the matrix exponentiation on the GPU of various matrix sizes using parameter $c_{i,1}$, with different exponents using $c_{i,2}$, and delaying the intermediate steps of the exponentiation with different times using $c_{i,3}$ (here we again assume that the parameters are the same for all the $l$ stages). The exponentiation occurs on the GPU, and is meant to  simulate heavy computational load of, e.g., an algorithm related to computer vision. Indeed these algorithms often rely on various operations with matrix representations of images where, for instance, color balancing (i.e., incandescent lighting compensation) occurs by multiplication with a scale factor~\citep{szeliski2011computer}.
\begin{figure}[ht!]
  \centering
  \begin{subfigure}[t]{0.405\textwidth}
      \centering
      \fontfamily{phv}\selectfont
      \input{figures/matrix-gpu-exponent-power.tikz}
      \caption{Average power}
      \label{fig:matrix-exponent:power}
      \vskip\baselineskip
      \input{figures/matrix-gpu-exponent-energy.tikz}
      \caption{Overall energy}
      \label{fig:matrix-exponent:energy}
  \end{subfigure}
  \quad
  \begin{subfigure}[c]{0.475\textwidth}   
      \centering 
      \fontfamily{phv}\selectfont
      \vspace{14.8ex}
      \input{figures/matrix-gpu-exponent-battery.tikz}
      \caption{Remaining battery capacity}  
      \label{fig:matrix-exponent:battery}
  \end{subfigure}
  \caption{Execution of GPU exponentiation, average total power~\ref{fig:matrix-exponent:power}, overall energy consumption~\ref{fig:matrix-exponent:energy}, and battery depletion~\ref{fig:matrix-exponent:battery} as a function of size and exponent parameters. The plot shows how the choice between specific configurations impacts the energy performance of the system under analysis.}
  \label{fig:matrix-exponent}
\end{figure}
We illustrate the predictive layers for the computation varying the parameter $c_{i,1}$ from 256 to 4096 and $c_{i,2}$ from twenty to sixty in \fref{fig:matrix-exponent}{Figure} (these values enclose the sets $\mathcal{S}_{i,1}$ and $\mathcal{S}_{i,2}$ respectively).
Particularly, \fref{fig:matrix-exponent:power}{Figure} shows the average power, \fref{fig:matrix-exponent:energy}{Figure} the overall energy, and \fref{fig:matrix-exponent:battery}{Figure} the battery SoC as a function of matrix size and exponent. 
We report the average power consumption independently of the running time of the {\small\tt matrix-gpu}, whereas the overall energy measures are measured up until a given configuration of the two parameters $c_{i}=\{c_{i,1},c_{i,2}\}$ evaluated the exponentiation, as well as for the battery state of charge. The computation might evaluate the exponentiation with no notable effect on the total power consumption for values of $c_{i}$ close to $\underline{c}_{i,1}$ and $\underline{c}_{i,2}$ for parameters $c_{i,1},c_{i,2}$. An effect that we observed early and that is reflected also in \fref{fig:darknet-layer1}{Figure}, meaning that the computation terminates before reaching the maximal power level~\citep{seewald2019coarse}. It is the reason why there is notable difference in average power for configurations close to the two opposite configurations.
\begin{figure}[ht!]
  \centering
  \begin{subfigure}[t]{0.475\textwidth}
      \centering
      \fontfamily{phv}\selectfont
      \input{figures/matrix-gpu-sleep-power.tikz}
      \caption{Average power}
      \label{fig:matrix-sleep:power}
      \vskip\baselineskip
      \input{figures/matrix-gpu-sleep-energy.tikz}
      \caption{Overall energy}
      \label{fig:matrix-sleep:energy}
  \end{subfigure}
  \quad
  \begin{subfigure}[c]{0.475\textwidth}   
      \centering 
      \fontfamily{phv}\selectfont
      \vspace{14.8ex}
      \input{figures/matrix-gpu-sleep-battery.tikz}
      \caption{Remaining battery capacity}  
      \label{fig:matrix-sleep:battery}
  \end{subfigure}
  \caption{Execution of GPU matrix exponentiation, average total power~\ref{fig:matrix-sleep:power}, overall energy consumption~\ref{fig:matrix-sleep:energy} and battery depletion~\ref{fig:matrix-sleep:battery} as a function of the matrix size and simulated scheduling in the form of sleep between iterations.} 
  \label{fig:matrix-sleep}
\end{figure}
In \fref{fig:matrix-sleep}{Figure} we illustrate the predictive layers by varying the parameter $c_{i,1}$ and $c_{i,3}$ relative to the delay--or ``sleep''--between iterations of the matrix exponentiation from none to ten seconds. Here again \fref{fig:matrix-sleep:power}{Figure} shows the average power, \fref{fig:matrix-sleep:energy}{Figure} the overall energy, and \fref{fig:matrix-sleep:battery}{Figure} the battery SoC as a function of matrix size and the duration of the delay. We observe that the latter directly affects the overall power consumption, hence, the higher the delay, the lower the remaining battery SoC (conversely the higher the overall energy). In both set of \fref{fig:matrix-exponent:energy}{Figures}\fref{fig:matrix-exponent:battery}{--\hspace*{-.8ex}} and \fref{fig:matrix-sleep:energy}{Figures}\fref{fig:matrix-sleep:battery}{--\hspace*{-.8ex}} we thus observe a relation between overall energy and battery SoC.

We used the same configuration parameters as with the {\small\tt darknet-gpu} computation, but for the running time. In \fref{fig:matrix-exponent}{Figures}\fref{fig:matrix-sleep}{--\hspace*{-.8ex}} the runtime is not bounded, the average power, overall energy, and battery SoC are relative to the entire exponentiation. The battery parameters are likewise the same. To define the constraint sets $\mathcal{S}_{i,1}$, we used the configuration {\small\tt pow}, e.g., {\small\tt range=256,4096,pow(2)}, meaning $c_{i,1}$ utilize exponential sampling in \frefeq{eq:meas-layer-exp-sampl}. 

\subsection{The {\tt darknet-cpu}, {\tt matrix-cpu}, {\tt nvidia-} {\tt matrix} and {\tt quicks} computations}\findex{computations!darknet-cpu@\texttt{darknet-cpu}}\findex{computations!matrix-cpu@\texttt{matrix-cpu}}\findex{computations!nvidia-matrix@\texttt{nvidia-matrix}}\findex{computations!nvidia-quicks@\texttt{nvidia-quicks}}

We deployed the computations energy model on additional computations and computing hardware. 

These include {\small\tt matrix-cpu} and {\small\tt darknet-cpu}, similar to {\small\tt matrix-gpu} and {\small\tt darknet-gpu} computations except that the operations run on the CPU rather than GPU. We used all the computing hardware described in \fref{sec:model-hete-elem}{Section} for the {\small\tt matrix-cpu} computation, and NVIDIA Jetson TX2 for the {\small\tt darknet-cpu} computation. On NVIDIA Jetson TX2 we further interfaced some already existing benchmarks with the \powprof{} tool. These were modified to run for several instance over a time interval and implement a quicksort of a given size--the {\small\tt nvidia-quicks}, and a matrix multiplication {\small\tt nvidia-matrix}. We summarize the overall energy contribution of all the computations from this section in \fref{tab:benchmark-components}{Table}. 
\begin{table}[h]
  \footnotesize\fontfamily{phv}\selectfont
  \begin{tabularx}{\textwidth}{|l|*{3}{X|}X|}
    \hline
    \multirow{2}{*}{Computation} & ODROID & \multicolumn{3}{c|}{NVIDIA} \\
    & XU3 & TK1 & TX2 & Nano \\
    \hline
    \stt{matrix-cpu}    & 528.4 J & 406.7 J & 241.3 J & 273.6 J \\
    \stt{matrix-gpu}    & - & 8.1 J & 4.5 J & 3.9 J \\
    \stt{darknet-cpu}   & (-) & (-) & 240 J & (-) \\
    \stt{darknet-gpu}   & - & - & 525.5 J & (-) \\
    \stt{nvidia-matrix} & - & (-) & 405.4 J & (-) \\
    \stt{nvidia-quicks} & - & (-) & 199.5 J & (-) \\
    \hline
  \end{tabularx}
  \caption{The overall energy consumption for each benchmark. Unsupported platforms are indicated by `-' and `(-)' indicates supported but not included in this paper.}
  \label{tab:benchmark-components}
\end{table}
The table shows the performance of different computations while running on different elements. We expected the computations {\small\tt matrix-cpu} to require a considerably more energy compared to {\small\tt matrix-gpu}. Indeed it is known that there is a large performance gap between GPUs and general-purpose multicore CPUs~\citep{kirk2016programming}, and we thus expected the time needed to compute on the CPU to be considerably larger than on the GPU,  the average power might be greater: the {\small\tt matrix-cpu} requires 4.5 joules, whereas {\small\tt matrix-gpu} 241.3 joules for the same operation on the NVIDIA Jetson TX2 computing hardware~\citep{seewald2019coarse}. The battery SoC evolves accordingly, with the difference between {\small\tt matrix-gpu} and {\small\tt matrix-cpu} in terms of battery SoC being 16\%. In our early work~\citep{seewald2019coarse,seewald2019component} we further observe the parallelization effect on the overall energy: we can conserve energy by running computations in parallel on the CPU and GPU compared to a sequential schedule even if we substract the base power. Indeed a sequential schedule (e.g., scheduling computations sequentially on CPU and GPU in some order) results in 20\% larger overall energy consumption than running them in parallel~\citep{seewald2019coarse}.

In \fref{tab:benchmark-components}{Table} we additionally compare the {\small\tt darknet-gpu} computation to the {\small\tt darknet-cpu} computation, which is similar to its GPU equivalent but runs merely on the CPU. Although the {\small\tt darknet-cpu} computation requires less energy per-minute compared to the {\small\tt darknet-gpu} computation, but runs for considerably longer; the energy cost per frame is then higher on the CPU than on GPU implementation~\citep{seewald2019coarse}.
We further show the energy effect of the {\small\tt nvidia-matrix} and {\small\tt nvidia-quicks} computations on the NVIDIA Jetson TX2 computing hardware. The {\small\tt nvidia-matrix} computation runs a significant portion on the CPU to check whenever the result of the GPU matrix multiplication matches the one on the CPU. Nonetheless, we observe that the problem size affects the overall energy consumption and battery SoC in both the {\small\tt nvidia-matrix} and {\small\tt nvidia-quicks} computations~\citep{seewald2019coarse}. One notable difference between the two latter computation is the nature of the problem they solve; {\small\tt nvidia-quicks} uses random data that are being sorted, and has thus a lower predictability in terms of overall energy~\citep{seewald2019coarse}.

\subsection{Validation}

To validate the computations energy model from \fref{sec:comp-ener-model}{Section} illustrated in this chapter via the output of the \powprof{} tool, we demonstrated that the model (and the tool) can be used on numerous heterogeneous computing hardware and various computations. In \fref{tab:benchmark-components}{Table}, we empirically evaluate the {\small\tt matrix-cpu} computation on the ODROID XU3, NVIDIA Jetson TK1, TX2, and Nano\findex{ODROID XU3}\findex{NVIDIA Jetson!TK1}\findex{NVIDIA Jetson!TX2}\findex{NVIDIA Jetson!Nano} computing hardware. The {\small\tt matrix-gpu} on the NVIDIA Jetson computing hardware, and the rest of the computations in this section on the NVIDIA Jetson TX2 computing hardware. Some computations that are not explicitly evaluated in our work can be potentially extended in future instances of our approach (hyphen in parenthesis in \fref{tab:benchmark-components}{Table}), while other are not supported (hyphen in \fref{tab:benchmark-components}{Table}), which we describe further in \fref{cp:conc}{Chapter}.
Cross-platform comparison shows than energy efficiency of different computing hardware executing the same computation. The {\small\tt matrix-cpu} computation is most efficient on NVIDIA Jetson TX2 computing hardware, followed by Nano, TK1 and ODROID XU3. 

We then evaluate the \powprof{} tool by means of comparison with an external measuring device, i.e., a multimeter connected to the power source of the NVIDIA Jetson TX2 board. We observe close relation between external and internal power measuring devices. The error is then less than 3\% over one minute, with the external exceeding the internal measuring device, possibly due to the energy impact of the carrier board~\citep{seewald2019coarse}. Indeed the NVIDIA Jetson TX2 computing hardware we use is mounted on the Jetson Developer Kit board in \fref{fig:tx2}{Figure}. We further observe that the internal measurements of the overall power include the energy impact of the tool itself, allowing us to conclude that the tool has a marginal effect on power~\citep{seewald2019coarse}.

We further validate our model against a more fine-grained model in the literature~\cite{nunez2013enabling,nikov2015evaluation} on the ODROID XU3 computing hardware, using the {\small\tt matrix-cpu} computation. We described this furhter validation step in our early work~\citep{seewald2019coarse}, and report it in the remainder of this paragraph. The fine-grained model requires some apriori training, which we performed by evaluating the computation configuration with parameter $c_{i,1}$ 512, and $c_{i,2}$ 30 (meaning the thrtyeth power of square matrix of size 512). The model returns an expected energy value, which we compared by subsequently running the operation, obtaining an error of 3.42\%~\citep{seewald2019coarse}. In our model, we similarly used the \powprof tool by varying only $c_{i,2}$ with a step to exclude the configuration thrity. We then obtained an expected energy value for the configuration thrity, which we again evaluated against running the configuration subsequently, obtaining an error of 2.25\%~\citep{seewald2019coarse}, justifying ours against another model in the literature. 

\section{Motion Energy Modeling}
\label{sec:res-ene-mot}

\section{Coverage Planning and Scheduling}
\label{sec:res-dyn}



%\lettrine{I}{n the previous chapters}, we introduced progressively the research questions we are interested in addressing. We then provided some preliminaries with basic terminology, formulated the problem formally, detailed the available literature, and derived various energy models. Once we detailed all these basic constructs, we are ready to describe their interaction to solve \fref{pb:cov-pb}{Problem} and \fref{pb}{Problem} and thus provide an energy-aware coverage planning and scheduling for autonomous aerial robots.

%This chapter describes the main contribution of our work. Here we generate the coverage plan $\Gamma$ that we defined in \fref{def:plan}{Definition} solving \fref{pb:cov-pb}{Problem}, replan $\Gamma$ energy-wise with the models from \fref{cp:model}{Chapter} solving \fref{pb}{Problem} in case of, e.g., sudden battery drops, and guide the aerial robot on $\Gamma$. In particular, we first detail how we guide the aerial robot on the plan in \fref{sec:gvf}{Section}, recalling some constructs in \fref{cp:pb}{Chapter}. These include path functions\findex{path functions}, stages\findex{stage}, triggering points\findex{triggering points}, and primitive paths\findex{primitive paths}. In \fref{sec:cov-path-plan}{Section}, we discuss the generation of the coverage plan with a union of path functions and triggering points in \fref{sec:path-functions}{Sections}\fref{sec:defs-stages-triggs}{--\hspace*{-.8ex}} (it is on this coverage that we are interested in guiding the aerial robot). In \fref{sec:mpc}{Section}, we then discuss how to replan the coverage energy-wise. Although we already described most of the concepts in preliminaries in \fref{cp:opt}{Chapter} and literature in \fref{cp:soa}{Chapter}, we still need some additional notions. To guide the aerial robot, we use the theory of vector fields that point to the path functions. To generate the coverage path, a class of methods under the name of cellular decomposition, generating a coverage motion that respects the nonholonomic\findex{nonholonomic constraints} and other constraints of a fixed-wing aerial robot (such as the Opterra craft\findex{Opterra fixed-wing aerial robot} in \fref{fig:opterra}{Figure} that we have discussed extensively in this work), including requirements on the turning radius\findex{turning radius}. To replan the coverage path, we use an optimal control\findex{optimal control} approach termed model predictive control (\Gls{acr:mpc})\findex{model predictive control} along with the periodic model in \fref{cp:model}{Chapter} (which we proved formally and motivated empirically in \fref{sec:periodic-model}{Section}). We describe all these concepts and contextualize them in the solution to the problems in this chapter. 

%This chapter connects to the remainder of this work as follows. Here we provide the solution to the problems in \fref{cp:pb}{Chapter}. To this end, we use the available literature on planning in \fref{cp:soa}{Chapter} and the energy models in \fref{cp:model}{Chapter}. We provided the motivation and discussed why it is important to solve these problems in \fref{cp:intro}{Chapter}. We use the model in the cost and constraints of an optimal control problem (\Gls{acr:ocp})\findex{optimal control problem} using the preliminaries in \fref{cp:opt}{Chapter}. Although we provide an algorithm for energy-aware coverage planning and scheduling for autonomous aerial robots, some research questions remain open. We discuss these questions in \fref{cp:conc}{Chapter}.






  
  \begin{figure}[p]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize
    \begin{subfigure}[c]{0.475\textwidth}
      \centering
      \input{figures/path-plot-take-off.tikz}
      \caption{Take-off phase path}
      \label{fig:takeoff-path}
      \vspace{3ex}
    \end{subfigure}
    \begin{subfigure}[c]{0.475\textwidth}
      \centering
      \input{figures/path-plot-landing.tikz}
      \vspace*{3ex}
      \caption{Landing phase path}
      \label{fig:landing-path}
      \vspace{3ex}
    \end{subfigure}
    \quad
    \begin{subfigure}[t]{0.34\textwidth}
      \centering
      \input{figures/takeoff.tikz}
      \caption{Take-off energy evolution}
      \label{fig:takeoff-energy}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\textwidth}
      \centering
      \input{figures/cruise.tikz}
      \caption{Cruise energy evolution}
      \label{fig:cruise-energy}
    \end{subfigure}
    \begin{subfigure}[t]{0.30\textwidth}
      \centering
      \input{figures/landing.tikz}
      \caption{Landing energy evolution}
      \label{fig:landing-energy}
    \end{subfigure}
    \caption{The evolution in time of energy and paths for three different flight phases. take-off, cruise, and landing}
    \label{fig:path-energy}
  \end{figure}

  \begin{figure}[p]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize
    \begin{subfigure}[t]{0.31\textwidth}
      \centering
      \input{figures/soc-configuration.tikz}
      \vspace*{-2.5ex}
      \caption{SoC as a function of time for different configurations}
      \label{fig:soc-configuration}
    \end{subfigure}
    \begin{subfigure}[t]{0.29\textwidth}
      \centering
      \input{figures/soc-schedule.tikz}
      \caption{Two examples of the evolution of SoC-aware schedules}
      \label{fig:soc-schedule}
    \end{subfigure}
    \begin{subfigure}[t]{0.36\textwidth}
      \centering
      \input{figures/soc-plot.tikz}
      \vspace*{-2.6ex}
      \caption{SoC in the function of FPS rate and key-size}
      \label{fig:soc-plot}
    \end{subfigure}
    \caption{Different SoC evolutions in time}
    \label{fig:soc-evolution1}
  \end{figure}

  \begin{figure}[p]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize    
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/max-qos.tikz}
      \vspace*{-1.25ex}
      \caption{Max QoS for mission of length {\footnotesize $t$} QoS for mission of length {\footnotesize $t$}}
      \label{fig:max-qos}
    \end{subfigure}
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/computational-mobilenet.tikz}
      \caption{Estimated SoC as a function of frames-per-second rate and key%-size QoS ranges% after completing a missio
      }
      \label{fig:pednet}
    \end{subfigure}
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/computational-pednet.tikz}
      \caption{Max QoS for mission of length {\footnotesize $t$} QoS for mission of length {\footnotesize $t$}}
      \label{fig:mobilenet}
    \end{subfigure}
    \caption{Different SoC evolutions in time}
    \label{fig:computational}
  \end{figure}
  
