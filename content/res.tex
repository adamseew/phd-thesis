
%
%%%%%%%%%%%%%
%           %
% Results   %
%           %
%%%%%%%%%%%%%
%
% Brief abstract: wraps up the results from the previous chapters
%
% Completion (1-10): 1
% Missing: -
%
\chapter{Results}
\label{cp:res}

\begin{chapquote}{\cite{sudhakar2020balancing}}
  ``[Computing energy included motion planning] shows improved performance over the baseline and looks to be promising solution to the low-power motion planning problem.''
\end{chapquote}

\vspace*{1em}

\lettrine{I}{n this chapter}, we report some results both published in our early studies~\citep{seewald2019hlpgpu,seewald2019coarse,seewald2019component,seewald2020mechanical,zamanakos2020energy} and to appear in a forthcoming study~\citep{seewald202Xenergy}, validating our overall approach towards energy-aware dynamic planning and scheduling for autonomous aerial robots. The chapter thus connects to the remainder of the work by describing our experimental setup and results. We describe the latter for \fref{cp:model}{Chapters}\fref{cp:dyn}{--\hspace*{-.8ex}}, which contains our most notable contribution: the energy models for both the computation and motion of an aerial robot and a coverage planning and scheduling technique that uses the models. \fref{cp:pb}{Chapter} is limitedly involved as well: we extensively use the agricultural scenario we introduced in \fref{sec:flight-plan}{Section} to showcase our approach, along with other formalities we proposed in the chapter.

The remainder of this chapter is structured as follows. In \fref{sec:res-ene-comps}{Section}, we describe our experimental setup and results for the computations energy model obtained with the \powprof{} tool from \fref{sec:powprof}{Section}. We then detail similarly the energy of the motion of an aerial robot flying a path similar to \fref{sec:flight-plan}{Section} independently and along with the computing hardware in \fref{sec:res-ene-mot}{Section}. In both \fref{sec:res-ene-comps}{Sections}\fref{sec:res-ene-mot}{--\hspace*{-.8ex}}, we describe our experimental setup for a batter of the computing hardware, aerial robot, and computing hardware with the aerial robot, detailing for each the results. In \fref{sec:res-dyn}{Section}, we then describe the coverage planning and scheduling in \matlab and Paparazzi autopilots and thus, validate our work experimentally.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Computations Energy Modeling}
\label{sec:res-ene-comps}

In this section, we describe the results and the experimental setup to obtain computations energy models with the \powprof{} tool. We report how we derive both the measurement and predictive layers from \fref{sec:measurement-layer}{Sections}\fref{sec:predictive-layer}{--\hspace*{-.8ex}} and the battery models from \fref{sec:battery-model}{Section} to integrate the two layers with the battery energy contribution for the computing hardware.

\subsection{The {\tt darknet-gpu} computation}\findex{computations!darknet-gpu@\texttt{darknet-gpu}}

In \fref{fig:darknet-layer1}{Figure}, we illustrate a concrete example of four different measurement layers from our early contribution~\citep{seewald2019coarse}: the power evolution in the function of time for three measuring devices, CPU, GPU, and overall of the NVIDIA Jetson TX2 board\findex{NVIDIA Jetson!TX2}. 
\begin{figure}[h!]
  \begin{minipage}{.93\textwidth}
  \centering
  \fontfamily{phv}\selectfont
  \hspace*{20ex}
  \input{figures/darknet-layer1.tikz}
  \end{minipage}
  \caption[The {\tt darknet-gpu} computation measurement layer models]{The {\tt darknet-gpu} computation measurement layer models, featuring the GPU implementation of the YOLO~\citep{redmon2016you} deep neural network library modified to introduce delays between detections. From top left in horizontal order to bottom right, the figure shows the schedules from approximately six up to thirty-two FPS. The figure appeared in our early study~\citep{seewald2019coarse}.}
  \label{fig:darknet-layer1}
\end{figure}
The model is relative to one computation with four different schedules where we observed notable differences in instantaneous and overall energies. The computation consists of an object detection algorithm that we term {\small\tt darknet-gpu}, a neural network-based pattern recognition utility. It is a standard computer vision computation, built upon the darknet~\citep{redmond2017yolo,redomnd2013darknet}\findex{darknet} GPU implementation of a deep neural network library YOLO~\citep{redmon2016you}\findex{YOLO}, which detects the objects on some pre-trained as well as trained networks (the latter to detect a personalized set of objects).

In an initial iteration of our work~\citep{teamplayd43}, we trained the network using images of different shapes and colors for a search and rescue aerial robotics scenario where the robot detects vessels on the sea. We benchmarked the corresponding computation on a video stream of vessels in an offshore area, simulating an aerial robot flying the scenario with a camera. We further modified the {\small\tt darknet-gpu} computation to simulate different scheduling options, such that the computation can be altered with a given parameter, which we call $c_{i,1}$ in accordance to \fref{def:stage}{Definition} $\forall\,i\in[l]$  (with the plan lasting assigned $l$ stages). The parameter indicates the delay between two invocations of the detection, simulating different frames per second (\Gls{acr:fps}) rates. 
\begin{figure}[h!]
  \centering
  \fontfamily{phv}\selectfont
  \input{figures/darknet-layer2.tikz}
  \caption[Per-minute energy consumption and SoC of the object detection computation]{Per-minute energy consumption and SoC of the {\tt darknet-gpu} computation in terms of CPU, GPU, and overall energies. On the right is the resulting predictive layer that shows the energy and battery SoC in the function of any possible configuration. The figure appeared in our early study~\citep{seewald2019coarse}.}
  \label{fig:darknet-layer2}
\end{figure}
We schedule the computation with the parameter $c_{i,1}$ to assess the predictive layer in \fref{fig:darknet-layer2}{Figure}. On the right of the figure, we further illustrate the battery state of charge (\Gls{acr:soc}) in the function of varying FPS for the overall power measuring device of the TX2 board (dashed line). Similarly, the predictive layer provides the evolution of the energy also in the function of varying FPS (continuous line).

We used a frequency of ten hertz and a running time of one minute to derive all the measurement layers. The energy measure in \fref{fig:darknet-layer2}{Figure} is then relative to the energy needed to run the computation for a minute and the correspondent remaining SoC. For the latter, we used an integration step of one hundredth, internal battery voltage $V$ of 14.8 volts, internal resistance $R_r$ of 1.2 milliohms, stabilized voltage $V_s$ of twelve volts, and battery capacity $Q_c$ of five amperes per hour in \frefeqM{eq:socevol}{eq:internal_curr} in \fref{sec:batmod-circuit}{Section}. The parameters that correspond to such configurations are {\small\tt frequency=10}, {\small\tt h=0.01}, and {\small\tt runtime=60000} in the specification in \fref{sec:conf-spec}{Section}, whereas the battery values are specified while invoking the constructor of the {\small\tt soc\_1resistor} class. Both \fref{fig:darknet-layer1}{Figures}\fref{fig:darknet-layer2}{--\hspace*{-.8ex}} show the parameter $c_{i,1}$ within $\mathcal{S}_{i,1}$ constructed so that the resulting FPS is between 5.8 and thirty-two.

\subsection{The {\tt matrix-gpu} computation}\findex{computations!matrix-gpu@\texttt{matrix-gpu}}

We then derived a set of measurement and predictive layers of another computation, {\small\tt matrix-gpu}, also related to our early study~\citep{seewald2019coarse}. Here we use again the NVIDIA Jetson TX2 computing hardware and its overall power measuring device (the computing hardware supports measurements of the power for CPU and GPU separately, as well as overall; see \fref{fig:darknet-layer1}{Figure} or \fref{sec:model-hete-elem}{Section}). {\small\tt matrix-gpu} computes the matrix exponentiation on the GPU of various matrix sizes using parameter $c_{i,1}$, with different exponents using $c_{i,2}$ and delaying the intermediate steps of the exponentiation with different times using $c_{i,3}$ (we assume that the parameters are the same for all the $l$ stages). The exponentiation is meant to  simulate the heavy computational load of, e.g., an algorithm related to computer vision. Indeed these algorithms often rely on various operations with matrix representations of images where, for instance, color balancing (i.e., incandescent lighting compensation) occurs by multiplication with a scale factor~\citep{szeliski2011computer}.
\begin{figure}[ht!]
  \centering
  \begin{subfigure}[t]{0.405\textwidth}
      \centering
      \fontfamily{phv}\selectfont
      \input{figures/matrix-gpu-exponent-power.tikz}
      \caption{Average power}
      \label{fig:matrix-exponent:power}
      \vskip\baselineskip
      \input{figures/matrix-gpu-exponent-energy.tikz}
      \caption{Overall energy}
      \label{fig:matrix-exponent:energy}
  \end{subfigure}
  \quad
  \begin{subfigure}[c]{0.475\textwidth}   
      \centering 
      \fontfamily{phv}\selectfont
      \vspace{14.8ex}
      \input{figures/matrix-gpu-exponent-battery.tikz}
      \caption{Remaining battery capacity}  
      \label{fig:matrix-exponent:battery}
  \end{subfigure}
  \caption[Predictive layers of the matrix exponentiation computation in the function of varying exponent and matrix size]{Predictive layers with the power in \fref{fig:matrix-exponent:power}{Figure}, energy in \fref{fig:matrix-exponent:energy}{Figure}, and battery SoC power in \fref{fig:matrix-exponent:battery}{Figure} of the {\small\tt matrix-gpu} component in the function of varying matrix size and exponent. The figure appeared in our early study~\citep{seewald2019coarse}.}
  \label{fig:matrix-exponent}
\end{figure}
We illustrate the predictive layers for the computation varying the parameter $c_{i,1}$ from 256 to 4096 and $c_{i,2}$ from twenty to sixty in \fref{fig:matrix-exponent}{Figure} (these values enclose the sets $\mathcal{S}_{i,1}$ and $\mathcal{S}_{i,2}$ respectively). Particularly, \fref{fig:matrix-exponent:power}{Figure} shows the average power, \fref{fig:matrix-exponent:energy}{Figure} the overall energy, and \fref{fig:matrix-exponent:battery}{Figure} the battery SoC as a function of matrix size and exponent. We report the average power consumption independently of the running time of the {\small\tt matrix-gpu}, whereas the overall energy measures are measured up until a given configuration of the two parameters $c_{i}=\{c_{i,1},c_{i,2}\}$ evaluated the exponentiation, as well as for the battery state of charge. The computation might pose no notable effect on the total power consumption for values of $c_{i}$ close to $\underline{c}_{i,1}$ and $\underline{c}_{i,2}$ for parameters $c_{i,1},c_{i,2}$. An effect indicating the computation terminated before reaching the maximal power level~\citep{seewald2019coarse}, also visible in \fref{fig:darknet-layer1}{Figure}. It is the reason why there is a notable difference in average power for two opposite configurations.

\begin{figure}[ht!]
  \centering
  \begin{subfigure}[t]{0.475\textwidth}
      \centering
      \fontfamily{phv}\selectfont
      \input{figures/matrix-gpu-sleep-power.tikz}
      \caption{Average power}
      \label{fig:matrix-sleep:power}
      \vskip\baselineskip
      \input{figures/matrix-gpu-sleep-energy.tikz}
      \caption{Overall energy}
      \label{fig:matrix-sleep:energy}
  \end{subfigure}
  \quad
  \begin{subfigure}[c]{0.475\textwidth}   
      \centering 
      \fontfamily{phv}\selectfont
      \vspace{14.8ex}
      \input{figures/matrix-gpu-sleep-battery.tikz}
      \caption{Remaining battery capacity}  
      \label{fig:matrix-sleep:battery}
  \end{subfigure}
  \caption[Predictive layers in the function of varying exponent and schedules]{Predictive layers with the power in \fref{fig:matrix-exponent:power}{Figure}, energy in \fref{fig:matrix-exponent:energy}{Figure}, and battery SoC power in \fref{fig:matrix-exponent:battery}{Figure} of the {\small\tt matrix-gpu} component in the function of varying matrix size and delays between consecutive iterations, simulating different schedules. The figure appeared in our early study~\citep{seewald2019coarse}.}
  \label{fig:matrix-sleep}
\end{figure}
In \fref{fig:matrix-sleep}{Figure}, we illustrate the predictive layers by varying the parameter $c_{i,1}$ and $c_{i,3}$ relative to the delay--or ``sleep''--between iterations of the matrix exponentiation from none to ten seconds. \fref{fig:matrix-sleep:power}{Figure} shows the average power, \fref{fig:matrix-sleep:energy}{Figure} the overall energy, and \fref{fig:matrix-sleep:battery}{Figure} the battery SoC as a function of matrix size and the sleep. We observe that the latter directly affects the overall power consumption hence, the higher the delay, the lower the remaining battery SoC (conversely, the higher the overall energy). In both set of \fref{fig:matrix-exponent:energy}{Figures}\fref{fig:matrix-exponent:battery}{--\hspace*{-.8ex}} and \fref{fig:matrix-sleep:energy}{Figures}\fref{fig:matrix-sleep:battery}{--\hspace*{-.8ex}}, we thus observe a relation between overall energy and battery SoC.

We used the same configuration parameters as with the {\small\tt darknet-gpu} computation but for the running time. In \fref{fig:matrix-exponent}{Figures}\fref{fig:matrix-sleep}{--\hspace*{-.8ex}}, the runtime is unbounded: the average power, overall energy, and battery SoC are relative to the entire exponentiation. The battery parameters are likewise the same. To define the constraint sets $\mathcal{S}_{i,1}$, we used the configuration {\small\tt pow}, e.g., {\small\tt range=256,4096,pow(2)}, meaning $c_{i,1}$ utilize exponential sampling in \frefeq{eq:meas-layer-exp-sampl}. 

\subsection{The {\tt darknet-cpu}, {\tt matrix-cpu}, {\tt nvidia-} {\tt matrix} and {\tt quicks} computations}\findex{computations!darknet-cpu@\texttt{darknet-cpu}}\findex{computations!matrix-cpu@\texttt{matrix-cpu}}\findex{computations!nvidia-matrix@\texttt{nvidia-matrix}}\findex{computations!nvidia-quicks@\texttt{nvidia-quicks}}

We deployed the computations energy model on additional computations and computing hardware, including {\small\tt matrix-cpu} and {\small\tt darknet-cpu}, similar to {\small\tt matrix-gpu} and {\small\tt darknet-gpu} computations except that the operations run on the CPU rather than GPU. We used all the computing hardware described in \fref{sec:model-hete-elem}{Section} for {\small\tt matrix-cpu}, and NVIDIA Jetson TX2 for {\small\tt darknet-cpu}. On NVIDIA Jetson TX2, we further interfaced some already existing benchmarks with the \powprof{} tool. 
These were modified to run for several instances over a time interval and implement a quicksort ({\small\tt nvidia-quicks}) and a matrix multiplication ({\small\tt nvidia-matrix}), both with a given problem size (parameter $c_{i,4}$). We summarize the overall energy contribution of all the computations from this section in \fref{tab:benchmark-components}{Table}. 
\begin{table}[h]
  \footnotesize\fontfamily{phv}\selectfont
  \begin{tabularx}{\textwidth}{|l|*{3}{X|}X|}
    \hline
    \multirow{2}{*}{Computation} & ODROID & \multicolumn{3}{c|}{NVIDIA} \\
    & XU3 & TK1 & TX2 & Nano \\
    \hline
    {\small\tt matrix-cpu}    & 528.4 J & 406.7 J & 241.3 J & 273.6 J \\
    {\small\tt matrix-gpu}    & - & 8.1 J & 4.5 J & 3.9 J \\
    {\small\tt darknet-cpu}   & (-) & (-) & 240 J & (-) \\
    {\small\tt darknet-gpu}   & - & - & 525.5 J & (-) \\
    {\small\tt nvidia-matrix} & - & (-) & 405.4 J & (-) \\
    {\small\tt nvidia-quicks} & - & (-) & 199.5 J & (-) \\
    \hline
  \end{tabularx}
  \caption[Overall energy per computation on different computing hardware]{Overall energy per computation on different computing hardware. Unsupported hardware are indicated by ``-'', whereas possible future support by ``(-)'' as it appeared in our early study~\citep{seewald2019coarse}.}
  \label{tab:benchmark-components}
\end{table}
The table shows the performance while running on different computing hardware and heterogeneous elements. For instance, {\small\tt matrix-gpu} requires considerably more energy compared to {\small\tt matrix-cpu}; indeed, there is a large performance gap between GPUs and general-purpose multicore CPUs in terms of heavily parallelizable computations~\citep{kirk2016programming}: {\small\tt matrix-gpu} requires only 4.5 joules, whereas {\small\tt matrix-cpu} 241.3 joules for the same operation on the NVIDIA Jetson TX2 computing hardware~\citep{seewald2019coarse}. The battery SoC evolves accordingly, with the difference between {\small\tt matrix-gpu} and {\small\tt matrix-cpu} in terms of battery SoC being 16\%. In our early work~\citep{seewald2019coarse,seewald2019component}, we further observe the parallelization effect on the overall energy. We can conserve energy by running computations parallel on the CPU and GPU compared to a sequential schedule (e.g., scheduling computations sequentially on CPU and GPU in some order) even if we subtract the base power. This latter results in a 20\% larger overall energy consumption than a parallel schedule~\citep{seewald2019coarse}.

In \fref{tab:benchmark-components}{Table} we additionally compare {\small\tt darknet-gpu} to {\small\tt darknet-cpu}, which is similar to its GPU equivalent but runs merely on the CPU. Although {\small\tt darknet-cpu} requires less energy per minute compared to {\small\tt darknet-gpu}, it runs for considerably longer; the energy cost per frame is then higher on the CPU than on GPU implementation~\citep{seewald2019coarse}. We further show the energy effect of the {\small\tt nvidia-matrix} and {\small\tt nvidia-quicks} computations on the NVIDIA Jetson TX2 computing hardware. The {\small\tt nvidia-matrix} computation runs a significant portion on the CPU to check whenever the result of the GPU matrix multiplication matches the one on the CPU. Nonetheless, we observe that the problem size affects the overall energy consumption and battery SoC in both the {\small\tt nvidia-matrix} and {\small\tt nvidia-quicks} computations~\citep{seewald2019coarse}. One notable difference between the two latter computations is the nature of the problem they solve; {\small\tt nvidia-quicks} uses random data that are being sorted and has thus lower predictability in terms of overall energy~\citep{seewald2019coarse}.

\subsection{Validation}

To validate the computations energy model from \fref{sec:comp-ener-model}{Section} illustrated in this chapter via the output of the \powprof{} tool, we demonstrated that the model and the tool function on numerous heterogeneous computing hardware and various computations. In \fref{tab:benchmark-components}{Table}, we empirically evaluate the {\small\tt matrix-cpu} computation on the ODROID XU3, NVIDIA Jetson TK1, TX2, and Nano computing hardware\findex{ODROID XU3}\findex{NVIDIA Jetson!TK1}\findex{NVIDIA Jetson!TX2}\findex{NVIDIA Jetson!Nano}. The {\small\tt matrix-gpu} on the NVIDIA Jetson computing hardware, and the rest of the computations in this section on the NVIDIA Jetson TX2 computing hardware. A cross-platform comparison shows the energy efficiency of different computing hardware: the {\small\tt matrix-cpu} computation is most efficient on NVIDIA Jetson TX2 computing hardware, followed by Nano, TK1, and ODROID XU3. Some computations not explicitly evaluated here can be potentially extended in future instances of our approach (hyphen in parenthesis in \fref{tab:benchmark-components}{Table}--future work is then in \fref{cp:conc}{Chapter}) conversely to others that are not supported (hyphen in \fref{tab:benchmark-components}{Table}). 

We then evaluate the \powprof{} tool through comparison with an external measuring device, i.e., a multimeter connected to the power source of the NVIDIA Jetson TX2 hardware. We observe a close co-relation between external and internal power measures. The error is less than 3\% over one minute, with the external exceeding the internal measuring device, possibly due to the energy impact of the carrier board~\citep{seewald2019coarse}. Indeed the NVIDIA Jetson TX2 computing hardware we use is mounted on the Jetson Developer Kit board in \fref{fig:tx2}{Figure}. We further observe that the internal measurements of the overall power include the energy impact of the tool itself, and we thus conclude that \powprof{} has a marginal effect on power~\citep{seewald2019coarse}. We later saw such a marginal effect with other auxiliary libraries, such as the Robot Operating System (ROS) middleware\findex{Robot Operating System}~\citep{zamanakos2020energy}.

We further validate our model against a more fine-grained model in the literature~\cite{nunez2013enabling,nikov2015evaluation}, using the ODROID XU3 computing hardware with the {\small\tt matrix-cpu} computation. We described this further validation step in our early work~\citep{seewald2019coarse}. The fine-grained model requires some apriori training, which we performed by evaluating the computation configuration with parameters $c_{i,1}$ 512, and $c_{i,2}$ 30 (meaning the thirtieth power of square matrix of size 512). The model returns an expected energy value, which we compared by subsequently running the computation, obtaining an error of 3.42\%~\citep{seewald2019coarse}. Similarly, we used the \powprof{} tool by varying $c_{i,2}$ with a step that excludes the configuration $c_{i,2}$ 30. We then obtained an expected energy value for configuration 30, which we again evaluated against running the configuration subsequently, obtaining an error of 2.25\%~\citep{seewald2019coarse}, justifying ours against another model in the literature. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motion Energy Modeling}
\label{sec:res-ene-mot}

In this section, we derive motions energy models from \fref{sec:mot-ener-model}{Section} of an aerial robot flying the agricultural scenario doing static coverage path planning (\Gls{acr:cpp})\findex{coverage path planning}. We use the computations energy and battery models from \fref{sec:comp-ener-model}{Sections}\fref{sec:battery-model}{--\hspace*{-.8ex}} to integrate the static CPP with computing hardware and the effect of the battery. The coverage is static and decided offline, with no dynamic replanning when unexpected events occur (for instance, sudden battery drops). We will then replan such coverage in \fref{sec:res-dyn}{Section} along with the scheduling of the computations. Particularly, in \fref{sec:res-perio}{Section}, we derive an energy model using the expression in \frefeq{eq:fourier}, relying on the periodicity of the energy signal; we use NVIDIA Jetson TX2 as computing hardware~\citep{seewald2020mechanical}. In \fref{sec:res-diff}{Section}, we derive a differential energy model based on expressions in \frefeq{eq:state-perf} and \fref{lem:eqv}{Lemma}; we use NVIDIA Jetson NANO and ROS middleware. The former is a static model where we cannot predict, e.g., future energy consumption with varying schedules or flight time with varying coverage; whereas the latter allows such operation. Indeed we will use a similar approach later in \fref{sec:res-dyn}{Section} for energy-aware coverage planning and scheduling.

---

\subsection{Periodic modeling}
\label{sec:res-perio}


\subsection{Differential modeling}
\label{sec:res-diff}


\section{Coverage Planning and Scheduling}
\label{sec:res-dyn}







  
  \begin{figure}[p!]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize
    \begin{subfigure}[c]{0.475\textwidth}
      \centering
      \input{figures/path-plot-take-off.tikz}
      \caption{Take-off phase path}
      \label{fig:takeoff-path}
      \vspace{1.4ex}
    \end{subfigure}
    \begin{subfigure}[c]{0.475\textwidth}
      \centering
      \input{figures/path-plot-landing.tikz}
      \vspace*{3ex}
      \caption{Landing phase path}
      \label{fig:landing-path}
      \vspace{1.4ex}
    \end{subfigure}
    \quad
    \begin{subfigure}[t]{0.35\textwidth}
      \centering
      \input{figures/takeoff.tikz}
      \caption{Take-off energy evolution}
      \label{fig:takeoff-energy}
    \end{subfigure}
    \begin{subfigure}[t]{0.31\textwidth}
      \centering
      \input{figures/cruise.tikz}
      \caption{Cruise energy evolution}
      \label{fig:cruise-energy}
    \end{subfigure}
    \begin{subfigure}[t]{0.30\textwidth}
      \centering
      \input{figures/landing.tikz}
      \caption{Landing energy evolution}
      \label{fig:landing-energy}
    \end{subfigure}
    \caption[Paths and modeled energy evolutions in time for different flight phases]{Paths and modeled energy evolutions in time for different flight phases as they appeared in our early study~\citep{seewald2020mechanical}.}
    \label{fig:path-energy}
  \end{figure}
  \begin{figure}[p!]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize
    \begin{subfigure}[t]{0.31\textwidth}
      \centering
      \input{figures/soc-configuration.tikz}
      \caption{Static schedules}
      \label{fig:soc-configuration}
    \end{subfigure}
    \begin{subfigure}[t]{0.26\textwidth}
      \centering
      \input{figures/soc-schedule.tikz}
      \caption{SoC-aware schedules}
      \label{fig:soc-schedule}
    \end{subfigure}
    \begin{subfigure}[t]{0.41\textwidth}
      \centering
      \input{figures/soc-plot.tikz}
      \caption{SoC in the function of parameters}
      \label{fig:soc-plot}
    \end{subfigure}
    \caption[The effect of different schedules on the battery SoC]{The effect of different schedules on the battery SoC. The figure appeared in our early study~\citep{seewald2020mechanical}.}
    \label{fig:soc-evolution1}
  \end{figure}

  \begin{figure}[p]
    \centering
    \fontfamily{phv}\selectfont
    \footnotesize    
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/max-qos.tikz}
      \vspace*{-1.25ex}
      \caption{Max QoS for mission of length {\footnotesize $t$} QoS for mission of length {\footnotesize $t$}}
      \label{fig:max-qos}
    \end{subfigure}
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/computational-mobilenet.tikz}
      \caption{Estimated SoC as a function of frames-per-second rate and key%-size QoS ranges% after completing a missio
      }
      \label{fig:pednet}
    \end{subfigure}
    \begin{subfigure}[c]{0.32\textwidth}
      \centering
      \input{figures/computational-pednet.tikz}
      \caption{Max QoS for mission of length {\footnotesize $t$} QoS for mission of length {\footnotesize $t$}}
      \label{fig:mobilenet}
    \end{subfigure}
    \caption{Different SoC evolutions in time}
    \label{fig:computational}
  \end{figure}
  
